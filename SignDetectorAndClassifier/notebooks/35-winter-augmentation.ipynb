{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import albumentations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path('./../..').resolve()\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'SignDetectorAndClassifier' / 'data'\n",
    "DATASET_DIR = DATA_DIR / 'YOLO_DATASET'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winter photo example for `classifier`\n",
    "\n",
    "![](./../data/winter_traffic_signs_example/2_cut.png)\n",
    "![](./../data/winter_traffic_signs_example/1_cut.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\n",
    "    str(DATA_DIR / 'STOCK_SIGNS' / '1.8.png')\n",
    ")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGBA)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Winterize(albumentations.ImageOnlyTransform):\n",
    "    def __init__(self, contrast_limit=0.8, tiles_count=5, tiles_size=5, tiles_relative=True, always_apply=False, p=0.5):\n",
    "        super(Winterize, self).__init__(always_apply, p)\n",
    "        self.contrast_limit = contrast_limit\n",
    "        self.tiles_count = tiles_count\n",
    "        self.tiles_size = tiles_size,\n",
    "        self.tiles_relative = tiles_relative\n",
    "        \n",
    "    # TODO: implement white noise + gaussian on alpha channel of input image\n",
    "    # TODO: implement while-gray random cuts from image\n",
    "    def _transform(self, img):\n",
    "        self.noise = np.random.normal(1, 1, img.shape)\n",
    "        img = albumentations.brightness_contrast_adjust(img)\n",
    "        return self.noise \n",
    "\n",
    "    def apply(self, img, clip_limit=2, **params):\n",
    "        if albumentations.get_num_channels(img) != 4:\n",
    "            raise TypeError(\"Winterize transformation expects RGBA image\")\n",
    "\n",
    "        return self._transform(img)\n",
    "\n",
    "    def get_params(self):\n",
    "        return {'contrast_limit': self.contrast_limit, 'tiles_count': self.tiles_count, 'tiles_size': self.tiles_size, 'tiles_relation': self.tiles_relative}\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return (\"contrast_limit\", \"tiles_count\", \"tiles_size\", \"tiles_relative\")\n",
    "\n",
    "a = Winterize()\n",
    "\n",
    "img_t = a.apply(img)\n",
    "plt.imshow(img_t)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winter photo example for `detector`\n",
    "![](./../data/winter_traffic_signs_example/1_full.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import albumentations\n",
    "\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path('./../../').resolve()\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'SignDetectorAndClassifier' / 'data'\n",
    "DATASET_DIR = DATA_DIR / 'YOLO_DATASET'\n",
    "DATASET_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_FULL_FRAMES = DATASET_DIR / 'USER_FULL_FRAMES' \n",
    "SAMPLE_IMG = USER_FULL_FRAMES / 'autosave01_02_2012_09_13_36.jpg'\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "class Season(Enum): \n",
    "    Winter = 1\n",
    "    Fall = 2\n",
    "    Summer = 3\n",
    "    Autumn = 4\n",
    "    \n",
    "def extract_season_from_name(filepath: pathlib.Path) -> Season:\n",
    "    name = filepath.stem \n",
    "    month = int(\n",
    "        name.replace('autosave', '').replace('_', ' ').split(' ')[1]\n",
    "    )\n",
    "    if month in [12, 1, 2]:\n",
    "        return Season.Winter\n",
    "    if month in [3, 4, 5]:\n",
    "        return Season.Autumn\n",
    "    if month in [6, 7, 8]:\n",
    "        return Season.Summer\n",
    "    if month in [9, 10, 11]:\n",
    "        return Season.Fall\n",
    "    \n",
    "    raise ValueError(f'Invalid month {month}')\n",
    "\n",
    "files = USER_FULL_FRAMES.iterdir()\n",
    "seasons = list(map(extract_season_from_name, files))\n",
    "print(*[f'\\t{x} count {seasons.count(x)}\\n' for x in Season])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def read_yolo_dataset(csv_path: pathlib.Path, filepath_prefix: str):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    data['filepath'] = data['filepath'].apply(lambda x: pathlib.Path(filepath_prefix) / x)\n",
    "    data['size'] = data['size'].apply(lambda x: ast.literal_eval(x))\n",
    "    data['coords'] = data['coords'].apply(lambda x: ast.literal_eval(x))\n",
    "    return data\n",
    "\n",
    "yolo_dataset = read_yolo_dataset(DATASET_DIR / 'USER_FULL_FRAMES.csv', DATASET_DIR)\n",
    "yolo_dataset['season'] = yolo_dataset['filepath'].apply(lambda x: extract_season_from_name(x))\n",
    "yolo_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do I realy need season in dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per season split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "\n",
    "hist_data = []\n",
    "set_ = list(set(yolo_dataset['set']))\n",
    "for idx, x in enumerate(set_):\n",
    "    count_data = dict(\n",
    "        Counter(map(extract_season_from_name, yolo_dataset[yolo_dataset['set'] == x]['filepath'].to_list())\n",
    "        )\n",
    "    )\n",
    "    count_data = {str(x).split('.')[-1]: y for x, y in count_data.items()}\n",
    "    hist_data.append(sorted([key for key, val in count_data.items() for _ in range(val)])) #, bins=set(count_data.keys()))\n",
    "\n",
    "    # sns.countplot(data=df, x='Season')\n",
    "plt.hist(hist_data, bins=len(set_), align='mid')\n",
    "plt.legend(set_)\n",
    "plt.show()\n",
    "\n",
    "# TODO: fix x axis labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maddrive_adas.utils.transforms import ConvertCenterXYWH2CV2Rectangle, UnmakeRel\n",
    "from maddrive_adas.utils.general import xywh2xyxy\n",
    "from maddrive_adas.utils.fs import imread_rgb\n",
    "\n",
    "from albumentations import CoarseDropout, Compose\n",
    "\n",
    "import random \n",
    "\n",
    "import torch\n",
    "\n",
    "def put_outer_circle_mask(img: np.ndarray, abs_xywh):\n",
    "    raise NotImplementedError\n",
    "    rectangle_coords = ConvertCenterXYWH2CV2Rectangle(abs_xywh)\n",
    "    center = (abs_xywh[0], abs_xywh[1]) # x, y\n",
    "    radius = abs_xywh[2] // 2   # width // 2\n",
    "    print(radius)\n",
    "    print(center)\n",
    "    outer_mask = np.ones_like(img)\n",
    "    # outer_mask = cv2.rectangle(outer_mask, (rectangle_coords[0], rectangle_coords[1]), (rectangle_coords[2], rectangle_coords[3]), (0, 0, 0), -1)\n",
    "    # inner_mask = cv2.circle(outer_mask, center, radius, color=(255, 255, 255), thickness=-1)\n",
    "    # total_mask = cv2.bitwise_and(outer_mask, inner_mask)\n",
    "    return outer_mask\n",
    "    img = cv2.bitwise_and(img.copy(), total_mask)\n",
    "    return img\n",
    "\n",
    "def _put_crops(img: np.ndarray, rectangle_coords: list[int], color: list[int], p=0.5):\n",
    "    sub_img = img[rectangle_coords[1]:rectangle_coords[3], rectangle_coords[0]:rectangle_coords[2], :]\n",
    "    h, w, d = sub_img.shape\n",
    "    # print(h, w, d)\n",
    "    aug_compose = Compose(\n",
    "        CoarseDropout(\n",
    "            max_height=h // 5,\n",
    "            max_width=w // 5,\n",
    "            min_holes=1,\n",
    "            max_holes=10,\n",
    "            fill_value=color,\n",
    "            p=p),\n",
    "    )\n",
    "    coarsed_sub_img = aug_compose(image=sub_img)['image']\n",
    "    img[rectangle_coords[1]:rectangle_coords[3], rectangle_coords[0]:rectangle_coords[2], :] = coarsed_sub_img\n",
    "    return img\n",
    "\n",
    "def put_shieeet_on_img_like_winter(img: np.ndarray, sign_coordinates_xywh_rel: list[list[int]]):\n",
    "    h, w, d = img.shape\n",
    "    for coords in sign_coordinates_xywh_rel:\n",
    "        abs_coords = UnmakeRel(coords, w, h)\n",
    "        rectangle_coords =  ConvertCenterXYWH2CV2Rectangle(abs_coords)\n",
    "        # print(rectangle_coords)\n",
    "        color_const = random.randrange(80, 256)\n",
    "        color = [color_const] * 3\n",
    "        img = _put_crops(img, rectangle_coords, color=color, p=1)\n",
    "\n",
    "    return img\n",
    "\n",
    "def put_rectangle(img, p1, p2, color):\n",
    "    \"\"\"Usage example:\n",
    "    ```for i in data['coords']:\n",
    "        abs_coords = UnmakeRel(i, w, h)\n",
    "        rectangle_coords =  ConvertCenterXYWH2CV2Rectangle(abs_coords)\n",
    "        p1, p2 = (rectangle_coords[0], rectangle_coords[1]), (rectangle_coords[2], rectangle_coords[3]), \n",
    "        img = put_rectangle(img, p1, p2, (0, 0, 0))\n",
    "    ```\n",
    "    \"\"\"\n",
    "    return cv2.rectangle(\n",
    "        img, \n",
    "        p1, p2,\n",
    "        color, \n",
    "        thickness=5\n",
    "    )\n",
    "\n",
    "def get_all_rectangle_points(two_rectangle_points: list[int]) -> list[tuple[int]]:\n",
    "    \"\"\"Return TL, TR, BR, BL points.\"\"\"\n",
    "    p1 = (two_rectangle_points[0], two_rectangle_points[1])\n",
    "    p2 = (two_rectangle_points[0], two_rectangle_points[3])\n",
    "    p3 = (two_rectangle_points[2], two_rectangle_points[3])\n",
    "    p4 = (two_rectangle_points[2], two_rectangle_points[1])\n",
    "    return [p1, p2, p3, p4]\n",
    "\n",
    "def resize_triangle(triangle_pts: list[int], k_limit=0.5, randomize_k=True) -> list[int]:\n",
    "    \"\"\"Resize trianble.\n",
    "\n",
    "    Args:\n",
    "        triangle_pts (list[int]): Array of triangle points.\n",
    "        k_limit (float, optional): Triangle border scale limit. If randomize k, apply scale [0; k), else apply k. Defaults to 0.5.\n",
    "        randomize_k (bool, optional): Apply random k scale from range [0; k]. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        list[int]: _description_\n",
    "    \"\"\"\n",
    "    xs, ys = [x[0] for x in triangle_pts], [x[1] for x in triangle_pts]\n",
    "\n",
    "    base_x, base_y = None, None\n",
    "    offset_x, offset_y = None, None\n",
    "\n",
    "    for x in xs: \n",
    "        if xs.count(x) == 2:\n",
    "            base_x = x\n",
    "        else: \n",
    "            offset_x = x\n",
    "    offset_x -= base_x\n",
    "\n",
    "    for x in ys: \n",
    "        if ys.count(x) == 2:\n",
    "            base_y = x\n",
    "        else:\n",
    "            offset_y = x\n",
    "    offset_y -= base_y\n",
    "    \n",
    "    if base_x is None and base_y is None:\n",
    "        raise ValueError('Unable to get base triangle point. Is it right triangle?')\n",
    "        \n",
    "    x_scale = k_limit * random.random() if randomize_k else k_limit\n",
    "    y_scale = k_limit * random.random() if randomize_k else k_limit\n",
    "    return [(base_x, base_y), (int(base_x + offset_x * x_scale), base_y), (base_x, int(base_y + offset_y * y_scale))]\n",
    "\n",
    "\n",
    "def hide_corner(img: np.ndarray, sign_coordinates_xywh_rel: list[list[int]], p=0.9, k_limit=1., randomize_k=True):\n",
    "    \"\"\"_summary_ TODO:\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): _description_\n",
    "        sign_coordinates_xywh_rel (list[list[int]]): _description_\n",
    "        p (float, optional): _description_. Defaults to 0.9.\n",
    "        k_limit (_type_, optional): _description_. Defaults to 1..\n",
    "        randomize_k (bool, optional): _description_. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    h, w, _ = img.shape\n",
    "    for coords in sign_coordinates_xywh_rel: \n",
    "        if random.random() > p: \n",
    "            continue\n",
    "        abs_coords = UnmakeRel(coords, w, h)\n",
    "        rectangle_coords =  ConvertCenterXYWH2CV2Rectangle(abs_coords)\n",
    "        triangle_coordinates: list[int] = random.sample(get_all_rectangle_points(rectangle_coords), 3)\n",
    "        triangle_coordinates = resize_triangle(triangle_coordinates,  k_limit=k_limit, randomize_k=randomize_k)\n",
    "        # print(triangle_coordinates)\n",
    "        pts = np.array(triangle_coordinates, np.int32)\n",
    "        # color_const = random.randrange(80, 256)\n",
    "        color = [random.randrange(80, 256), random.randrange(80, 256), random.randrange(80, 256)] # [color_const] * 3\n",
    "        cv2.drawContours(img, [pts], 0, color, -1)\n",
    "    return img\n",
    "\n",
    "def get_item(df: pd.DataFrame, idx: int):\n",
    "    data = df.iloc[idx]\n",
    "    img = imread_rgb(data['filepath'])\n",
    "    img = put_shieeet_on_img_like_winter(img.copy(), data['coords'])\n",
    "    img = hide_corner(img.copy(), data['coords'])\n",
    "    return img\n",
    "\n",
    "img = get_item(yolo_dataset, 5140)\n",
    "plt.figure(figsize=(20,6))\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from maddrive_adas.utils.augmentations import (\n",
    "    Albumentations,\n",
    "    augment_hsv,\n",
    "    letterbox,\n",
    "    random_perspective,\n",
    ")\n",
    "\n",
    "from maddrive_adas.utils.general import (\n",
    "    xywh2xyxy,\n",
    "    xywhn2xyxy,\n",
    "    xyxy2xywhn,\n",
    ")\n",
    "\n",
    "class WinterizedYoloDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        set_label: str,\n",
    "        hyp_arg: dict,\n",
    "        img_size=640,\n",
    "        augment=False,\n",
    "        hide_corner_chance=0.5\n",
    "    ):\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "        self.hyp = hyp_arg\n",
    "        self.df = df[df[\"set\"] == set_label]\n",
    "        self._hide_corner_chance = hide_corner_chance\n",
    "        self.albumentations = Albumentations() if augment else None\n",
    "\n",
    "    def load_image(self, instance):\n",
    "        path, (w0, h0) = instance[\"filepath\"], instance[\"size\"]\n",
    "        img = cv2.imread(str(path))\n",
    "        assert img is not None, f\"Image Not Found {path}\"\n",
    "        img = hide_corner(img, instance['coords'], p=self._hide_corner_chance, k_limit=1)\n",
    "        img = put_shieeet_on_img_like_winter(img, instance['coords'])\n",
    "\n",
    "        r = self.img_size / max(h0, w0)  # ratio\n",
    "\n",
    "        if r != 1:  # if sizes are not equal\n",
    "            img = cv2.resize(\n",
    "                img,\n",
    "                (int(w0 * r), int(h0 * r)),\n",
    "                interpolation=cv2.INTER_AREA\n",
    "                if r < 1 and not self.augment\n",
    "                else cv2.INTER_LINEAR,\n",
    "            )\n",
    "        return img, (h0, w0), img.shape[:2]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # locate img info from DataFrame\n",
    "        instance = self.df.iloc[index]\n",
    "\n",
    "        # get Img, src height, width and resized height, width\n",
    "        try:\n",
    "            img, (h0, w0), (h, w) = self.load_image(instance)\n",
    "        except ValueError as e:\n",
    "            raise ValueError(f'VE for {e}: index is {index}. {instance}')\n",
    "            \n",
    "        shape = self.img_size\n",
    "\n",
    "        # make img square\n",
    "        img, ratio, pad = letterbox(img, shape, auto=False, scaleup=self.augment)\n",
    "\n",
    "        # store core shape info\n",
    "        shapes = (h0, w0), ((h / h0, w / w0), pad)  # for COCO mAP rescaling\n",
    "\n",
    "        # add class to labels. We have 1 class, so just add zeros into first column\n",
    "        labels = np.array(instance[\"coords\"])\n",
    "        labels = np.c_[np.zeros(labels.shape[0]), labels]\n",
    "\n",
    "        # fix labels location caused by letterbox\n",
    "        labels[:, 1:] = xywhn2xyxy(\n",
    "            labels[:, 1:], ratio[0] * w, ratio[1] * h, padw=pad[0], padh=pad[1]\n",
    "        )\n",
    "\n",
    "        if self.augment:\n",
    "            img, labels = random_perspective(\n",
    "                img,\n",
    "                labels,\n",
    "                degrees=self.hyp[\"degrees\"],\n",
    "                translate=self.hyp[\"translate\"],\n",
    "                scale=self.hyp[\"scale\"],\n",
    "                shear=self.hyp[\"shear\"],\n",
    "                perspective=self.hyp[\"perspective\"],\n",
    "            )\n",
    "\n",
    "        labels[:, 1:5] = xyxy2xywhn(\n",
    "            labels[:, 1:5], w=img.shape[1], h=img.shape[0], clip=False, eps=1e-3\n",
    "        )\n",
    "\n",
    "        # YOLO augmentation technique (!copy-paste!)\n",
    "        if self.augment:\n",
    "            # Albumentations\n",
    "            img, labels = self.albumentations(img, labels)\n",
    "            nl = len(labels)  # update after albumentations\n",
    "\n",
    "            # HSV color-space\n",
    "            augment_hsv(\n",
    "                img,\n",
    "                hgain=self.hyp[\"hsv_h\"],\n",
    "                sgain=self.hyp[\"hsv_s\"],\n",
    "                vgain=self.hyp[\"hsv_v\"],\n",
    "            )\n",
    "\n",
    "            # Remove random flip\n",
    "            # # Flip up-down\n",
    "            # if random.random() < self.hyp[\"flipud\"]:\n",
    "            #     img = np.flipud(img)\n",
    "            #     if nl:\n",
    "            #         labels[:, 2] = 1 - labels[:, 2]\n",
    "\n",
    "            # # Flip left-right\n",
    "            # if random.random() < self.hyp[\"fliplr\"]:\n",
    "            #     img = np.fliplr(img)\n",
    "            #     if nl:\n",
    "            #         labels[:, 1] = 1 - labels[:, 1]\n",
    "\n",
    "        nl = len(labels)\n",
    "\n",
    "        # why out size (?, 6)??\n",
    "        labels_out = torch.zeros((nl, 6))\n",
    "        if nl:\n",
    "            labels_out[:, 1:] = torch.from_numpy(labels)\n",
    "\n",
    "        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "        img = np.ascontiguousarray(img)\n",
    "\n",
    "        return torch.from_numpy(img), labels_out, instance[\"filepath\"], shapes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        img, label, path, shapes = zip(*batch)  # transposed\n",
    "        for i, l in enumerate(label):\n",
    "            l[:, 0] = i  # add target image index for build_targets()\n",
    "        return torch.stack(img, 0), torch.cat(label, 0), path, shapes\n",
    "\n",
    "import yaml\n",
    "hyps_file = DATA_DIR / \"hyp.scratch.yaml\"\n",
    "with open(hyps_file, errors='ignore') as f:\n",
    "    hyp = yaml.safe_load(f)\n",
    "    \n",
    "a = WinterizedYoloDataset(yolo_dataset, set_label='train', hyp_arg=hyp, augment=True, hide_corner_chance=1.)\n",
    "res = a[2]\n",
    "print(res[0].numpy().shape)\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.imshow(res[0].permute(1, 2, 0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WinterizedYoloDataset(yolo_dataset, set_label='train', hyp_arg=hyp, augment=True, hide_corner_chance=1.)\n",
    "valid_dataset = WinterizedYoloDataset(yolo_dataset, set_label='valid', hyp_arg=hyp, augment=False, hide_corner_chance=0.)\n",
    "test_dataset = WinterizedYoloDataset(yolo_dataset, set_label='test', hyp_arg=hyp, augment=False, hide_corner_chance=0.)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "nw = 0\n",
    "train_loader = DataLoader(\n",
    "        train_dataset,  # InfiniteDataLoader ?\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=nw,  # doesnt work in Windows\n",
    "        sampler=None,\n",
    "        pin_memory=True,\n",
    "        collate_fn=WinterizedYoloDataset.collate_fn,\n",
    "    )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "        test_dataset,  # InfiniteDataLoader ?\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=nw,  # doesnt work in Windows\n",
    "        sampler=None,\n",
    "        pin_memory=True,\n",
    "        collate_fn=WinterizedYoloDataset.collate_fn,\n",
    "    )\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "        valid_dataset,  # InfiniteDataLoader ?\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=nw,  # doesnt work in Windows\n",
    "        sampler=None,\n",
    "        pin_memory=True,\n",
    "        collate_fn=WinterizedYoloDataset.collate_fn,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD, lr_scheduler\n",
    "from torch.cuda import amp\n",
    "from maddrive_adas.utils.general import one_cycle, LOGGER\n",
    "from maddrive_adas.utils.loss import ComputeLoss\n",
    "from maddrive_adas.utils.torch_utils import ModelEMA, de_parallel\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "from maddrive_adas.models.yolo import Model\n",
    "\n",
    "def train(epochs, model: Model, train_loader: DataLoader, valid_loader: DataLoader, device: torch.device, opt=None, imgsz=640):       \n",
    "    print('Train called')\n",
    "    start_epoch = 0\n",
    "    nc = 1\n",
    "    model.float()\n",
    "    cuda = device.type == 'cuda'\n",
    "    nb = len(train_loader)\n",
    "    nw = max(round(hyp['warmup_epochs'] * nb), 1000)\n",
    "    nbs = 64  # nominal batch size\n",
    "    batch_size = train_loader.batch_size\n",
    "    last_opt_step = -1\n",
    "        \n",
    "    g0, g1, g2 = [], [], []  # optimizer parameter groups\n",
    "    for v in model.modules():\n",
    "        if hasattr(v, 'bias') and isinstance(v.bias, torch.nn.Parameter):  # bias\n",
    "            g2.append(v.bias)\n",
    "        if isinstance(v, torch.nn.BatchNorm2d):  # weight (no decay)\n",
    "            g0.append(v.weight)\n",
    "        elif hasattr(v, 'weight') and isinstance(v.weight, torch.nn.Parameter):  # weight (with decay)\n",
    "            g1.append(v.weight)\n",
    "    \n",
    "    optimizer = SGD(g0, lr=hyp['lr0'], momentum=hyp['momentum'], nesterov=True)\n",
    "    \n",
    "    optimizer.add_param_group({'params': g1, 'weight_decay': hyp['weight_decay']})  # add g1 with weight_decay\n",
    "    optimizer.add_param_group({'params': g2})  # add g2 (biases)\n",
    "    del g0, g1, g2\n",
    "    \n",
    "    lf = one_cycle(1, hyp['lrf'], epochs)  # cosine 1->hyp['lrf']\n",
    "    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
    "    \n",
    "    ema = ModelEMA(model)\n",
    "    \n",
    "    nl = de_parallel(model).model[-1].nl  # number of detection layers (to scale hyps)\n",
    "    hyp['box'] *= 3 / nl  # scale to layers\n",
    "    hyp['cls'] *= nc / 80 * 3 / nl  # scale to classes and layers\n",
    "    hyp['obj'] *= (imgsz / 640) ** 2 * 3 / nl  # scale to image size and layers\n",
    "    hyp['label_smoothing'] = opt.label_smoothing if opt else 0.\n",
    "    \n",
    "    model.nc = nc  # attach number of classes to model\n",
    "    model.hyp = hyp  # attach hyperparameters to model\n",
    "    model.names = ['sign']\n",
    "    \n",
    "    scaler = amp.GradScaler(enabled=cuda)\n",
    "    compute_loss = ComputeLoss(model)\n",
    "    print('Pre epoch print')\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "        mloss = torch.zeros(3, device=device)\n",
    "        print('Epoch started')\n",
    "        pbar = enumerate(train_loader)\n",
    "        LOGGER.info(('\\n' + '%10s' * 7) % ('Epoch', 'gpu_mem', 'box', 'obj', 'cls', 'labels', 'img_size'))\n",
    "        pbar = tqdm(pbar, total=nb, bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')  # progress bar\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        for i, (imgs, targets, paths, _) in pbar:\n",
    "            ni = i + nb * epoch  # number integrated batches (since train start)\n",
    "            imgs = imgs.to(device, non_blocking=True).float() / 255  # uint8 to float32, 0-255 to 0.0-1.0\n",
    "            \n",
    "            # Warmup\n",
    "            if ni <= nw:\n",
    "                xi = [0, nw]  # x interp\n",
    "                # compute_loss.gr = np.interp(ni, xi, [0.0, 1.0])  # iou loss ratio (obj_loss = 1.0 or iou)\n",
    "                accumulate = max(1, np.interp(ni, xi, [1, nbs / batch_size]).round())\n",
    "                for j, x in enumerate(optimizer.param_groups):\n",
    "                    # bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0\n",
    "                    x['lr'] = np.interp(ni, xi, [hyp['warmup_bias_lr'] if j == 2 else 0.0, x['initial_lr'] * lf(epoch)])\n",
    "                    if 'momentum' in x:\n",
    "                        x['momentum'] = np.interp(ni, xi, [hyp['warmup_momentum'], hyp['momentum']])\n",
    "\n",
    "            # Forward\n",
    "            with amp.autocast(enabled=cuda):\n",
    "                pred = model(imgs.half())  # forward\n",
    "                loss, loss_items = compute_loss(pred, targets.float().to(device))  # loss scaled by batch_size\n",
    "                \n",
    "            # Backward\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            # Optimize\n",
    "            if ni - last_opt_step >= accumulate:\n",
    "                scaler.step(optimizer)  # optimizer.step\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                if ema:\n",
    "                    ema.update(model)\n",
    "                last_opt_step = ni\n",
    "            \n",
    "            mloss = (mloss * i + loss_items) / (i + 1)  # update mean losses\n",
    "            mem = f'{torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0:.3g}G'  # (GB)\n",
    "            pbar.set_description(('%10s' * 2 + '%10.4g' * 5) % (\n",
    "                f'{epoch}/{epochs - 1}', mem, *mloss, targets.shape[0], imgs.shape[-1]))\n",
    "        \n",
    "        ###\n",
    "        # every 5 epochs check mAP\n",
    "        if False and (epoch + 1) % 5 == 0:\n",
    "            ema.update_attr(model, include=['yaml', 'nc', 'hyp', 'names', 'stride', 'class_weights'])\n",
    "            map = valid_epoch()\n",
    "        ###\n",
    "\n",
    "        # Scheduler\n",
    "        lr = [x['lr'] for x in optimizer.param_groups]  # for loggers\n",
    "        scheduler.step()\n",
    "                \n",
    "        now = datetime.now()\n",
    "        model_save_name = DATA_DIR / f'YoloV5_{now.strftime(\"%d.%m_%H.%M\")}_lbox{mloss[0]}_lobj{mloss[1]}.pt'\n",
    "        \n",
    "        torch.save(model.state_dict(), model_save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg_file = DATA_DIR / 'yolov5l_custom_anchors.yaml'\n",
    "model = Model(cfg=model_cfg_file, ch=3, nc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "restore= DATA_DIR / 'WinterizedYoloV5.pt'\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(restore, map_location=device))\n",
    "    model.eval()\n",
    "    print('Model successfully loaded!')\n",
    "except FileNotFoundError as exc_obj:\n",
    "    print(f'[!] File [{restore}] not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_loader:\n",
    "    sample_data = i\n",
    "    \n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[5140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 640\n",
    "train(50, model, train_loader, valid_loader, device, imgsz=IMG_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "984aa5e2a995156e35edb7585281b3914fa5d1af0440f85bd60b2ec0c79e66ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
