{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import albumentations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path('./../..').resolve()\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'SignDetectorAndClassifier' / 'data'\n",
    "DATASET_DIR = DATA_DIR / 'YOLO_DATASET'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winter photo example for `classifier`\n",
    "\n",
    "![](./../data/winter_traffic_signs_example/2_cut.png)\n",
    "![](./../data/winter_traffic_signs_example/1_cut.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\n",
    "    str(DATA_DIR / 'STOCK_SIGNS' / '1.8.png')\n",
    ")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGBA)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Winterize(albumentations.ImageOnlyTransform):\n",
    "    def __init__(self, contrast_limit=0.8, tiles_count=5, tiles_size=5, tiles_relative=True, always_apply=False, p=0.5):\n",
    "        super(Winterize, self).__init__(always_apply, p)\n",
    "        self.contrast_limit = contrast_limit\n",
    "        self.tiles_count = tiles_count\n",
    "        self.tiles_size = tiles_size,\n",
    "        self.tiles_relative = tiles_relative\n",
    "        \n",
    "    # TODO: implement white noise + gaussian on alpha channel of input image\n",
    "    # TODO: implement while-gray random cuts from image\n",
    "    def _transform(self, img):\n",
    "        self.noise = np.random.normal(1, 1, img.shape)\n",
    "        img = albumentations.brightness_contrast_adjust(img)\n",
    "        return self.noise \n",
    "\n",
    "    def apply(self, img, clip_limit=2, **params):\n",
    "        if albumentations.get_num_channels(img) != 4:\n",
    "            raise TypeError(\"Winterize transformation expects RGBA image\")\n",
    "\n",
    "        return self._transform(img)\n",
    "\n",
    "    def get_params(self):\n",
    "        return {'contrast_limit': self.contrast_limit, 'tiles_count': self.tiles_count, 'tiles_size': self.tiles_size, 'tiles_relation': self.tiles_relative}\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return (\"contrast_limit\", \"tiles_count\", \"tiles_size\", \"tiles_relative\")\n",
    "\n",
    "a = Winterize()\n",
    "\n",
    "img_t = a.apply(img)\n",
    "plt.imshow(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winter photo example for `detector`\n",
    "![](./../data/winter_traffic_signs_example/1_full.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import albumentations\n",
    "\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path('./../../').resolve()\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'SignDetectorAndClassifier' / 'data'\n",
    "DATASET_DIR = DATA_DIR / 'YOLO_DATASET'\n",
    "DATASET_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_FULL_FRAMES = DATASET_DIR / 'USER_FULL_FRAMES' \n",
    "SAMPLE_IMG = USER_FULL_FRAMES / 'autosave01_02_2012_09_13_36.jpg'\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "class Season(Enum): \n",
    "    Winter = 1\n",
    "    Fall = 2\n",
    "    Summer = 3\n",
    "    Autumn = 4\n",
    "    \n",
    "def extract_season_from_name(filepath: pathlib.Path) -> Season:\n",
    "    name = filepath.stem \n",
    "    month = int(\n",
    "        name.replace('autosave', '').replace('_', ' ').split(' ')[1]\n",
    "    )\n",
    "    if month in [12, 1, 2]:\n",
    "        return Season.Winter\n",
    "    if month in [3, 4, 5]:\n",
    "        return Season.Autumn\n",
    "    if month in [6, 7, 8]:\n",
    "        return Season.Summer\n",
    "    if month in [9, 10, 11]:\n",
    "        return Season.Fall\n",
    "    \n",
    "    raise ValueError(f'Invalid month {month}')\n",
    "\n",
    "files = USER_FULL_FRAMES.iterdir()\n",
    "seasons = list(map(extract_season_from_name, files))\n",
    "print(*[f'\\t{x} count {seasons.count(x)}\\n' for x in Season])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def read_yolo_dataset(csv_path: pathlib.Path, filepath_prefix: str):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    data['filepath'] = data['filepath'].apply(lambda x: pathlib.Path(filepath_prefix) / x)\n",
    "    data['size'] = data['size'].apply(lambda x: ast.literal_eval(x))\n",
    "    data['coords'] = data['coords'].apply(lambda x: ast.literal_eval(x))\n",
    "    return data\n",
    "\n",
    "yolo_dataset = read_yolo_dataset(DATASET_DIR / 'USER_FULL_FRAMES.csv', DATA_DIR)\n",
    "yolo_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per season split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "\n",
    "hist_data = []\n",
    "set_ = list(set(yolo_dataset['set']))\n",
    "for idx, x in enumerate(set_):\n",
    "    count_data = dict(\n",
    "        Counter(map(extract_season_from_name, yolo_dataset[yolo_dataset['set'] == x]['filepath'].to_list())\n",
    "        )\n",
    "    )\n",
    "    count_data = {str(x).split('.')[-1]: y for x, y in count_data.items()}\n",
    "    hist_data.append(sorted([key for key, val in count_data.items() for _ in range(val)])) #, bins=set(count_data.keys()))\n",
    "\n",
    "    # sns.countplot(data=df, x='Season')\n",
    "plt.hist(hist_data, bins=len(set_), align='mid')\n",
    "plt.legend(set_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# TODO: write dataset with winter augmentation\n",
    "class WinterizeYoloDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        set_label,\n",
    "        hyp_arg,\n",
    "        img_size=640,\n",
    "        batch_size=16,\n",
    "        augment=False,\n",
    "        hyp=None,\n",
    "    ):\n",
    "\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "        self.hyp = hyp_arg\n",
    "\n",
    "        self.df = df[df[\"set\"] == set_label]\n",
    "        self.albumentations = Albumentations() if augment else None\n",
    "\n",
    "    def loadImage(self, instance):\n",
    "        path, (w0, h0) = instance[\"filepath\"], instance[\"size\"]\n",
    "        im = cv2.imread(path)\n",
    "        assert im is not None, f\"Image Not Found {path}\"\n",
    "\n",
    "        r = self.img_size / max(h0, w0)  # ratio\n",
    "\n",
    "        if r != 1:  # if sizes are not equal\n",
    "            im = cv2.resize(\n",
    "                im,\n",
    "                (int(w0 * r), int(h0 * r)),\n",
    "                interpolation=cv2.INTER_AREA\n",
    "                if r < 1 and not self.augment\n",
    "                else cv2.INTER_LINEAR,\n",
    "            )\n",
    "        return im, (h0, w0), im.shape[:2]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # locate img info from DataFrame\n",
    "        instance = self.df.iloc[index]\n",
    "\n",
    "        # get Img, src height, width and resized height, width\n",
    "        img, (h0, w0), (h, w) = self.loadImage(instance)\n",
    "\n",
    "        shape = self.img_size\n",
    "\n",
    "        # make img square\n",
    "        # print('>', (img>1).sum())\n",
    "        # print('<=', (img<=1).sum())\n",
    "        img, ratio, pad = letterbox(img, shape, auto=False, scaleup=self.augment)\n",
    "        # print(pad)\n",
    "        # store core shape info\n",
    "        shapes = (h0, w0), ((h / h0, w / w0), pad)  # for COCO mAP rescaling\n",
    "\n",
    "        # add class to labels. We have 1 class, so just add zeros into first column\n",
    "        labels = np.array(instance[\"coords\"])\n",
    "        labels = np.c_[np.zeros(labels.shape[0]), labels]\n",
    "        # print(labels)\n",
    "\n",
    "        # fix labels location caused by letterbox\n",
    "        labels[:, 1:] = xywhn2xyxy(\n",
    "            labels[:, 1:], ratio[0] * w, ratio[1] * h, padw=pad[0], padh=pad[1]\n",
    "        )\n",
    "\n",
    "        if self.augment:\n",
    "            img, labels = random_perspective(\n",
    "                img,\n",
    "                labels,\n",
    "                degrees=self.hyp[\"degrees\"],\n",
    "                translate=self.hyp[\"translate\"],\n",
    "                scale=self.hyp[\"scale\"],\n",
    "                shear=self.hyp[\"shear\"],\n",
    "                perspective=self.hyp[\"perspective\"],\n",
    "            )\n",
    "\n",
    "        labels[:, 1:5] = xyxy2xywhn(\n",
    "            labels[:, 1:5], w=img.shape[1], h=img.shape[0], clip=False, eps=1e-3\n",
    "        )\n",
    "\n",
    "        # YOLO augmentation technique (!copy-paste!)\n",
    "        if self.augment:\n",
    "            # print('augm for', index, instance['filepath'])\n",
    "            # Albumentations\n",
    "            img, labels = self.albumentations(img, labels)\n",
    "            nl = len(labels)  # update after albumentations\n",
    "\n",
    "            # HSV color-space\n",
    "            augment_hsv(\n",
    "                img,\n",
    "                hgain=self.hyp[\"hsv_h\"],\n",
    "                sgain=self.hyp[\"hsv_s\"],\n",
    "                vgain=self.hyp[\"hsv_v\"],\n",
    "            )\n",
    "\n",
    "            # Flip up-down\n",
    "            if random.random() < self.hyp[\"flipud\"]:\n",
    "                img = np.flipud(img)\n",
    "                if nl:\n",
    "                    labels[:, 2] = 1 - labels[:, 2]\n",
    "\n",
    "            # Flip left-right\n",
    "            if random.random() < self.hyp[\"fliplr\"]:\n",
    "                img = np.fliplr(img)\n",
    "                if nl:\n",
    "                    labels[:, 1] = 1 - labels[:, 1]\n",
    "\n",
    "        nl = len(labels)\n",
    "\n",
    "        # why out size (?, 6)??\n",
    "        labels_out = torch.zeros((nl, 6))\n",
    "        if nl:\n",
    "            labels_out[:, 1:] = torch.from_numpy(labels)\n",
    "\n",
    "        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "        img = np.ascontiguousarray(img)\n",
    "\n",
    "        return torch.from_numpy(img), labels_out, instance[\"filepath\"], shapes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        img, label, path, shapes = zip(*batch)  # transposed\n",
    "        for i, l in enumerate(label):\n",
    "            l[:, 0] = i  # add target image index for build_targets()\n",
    "        return torch.stack(img, 0), torch.cat(label, 0), path, shapes\n",
    "\n",
    "\n",
    "class WinterizeFull(albumentations.ImageOnlyTransform):\n",
    "    \"\"\"TODO: replace with decorator.\"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        name_to_season_dict,\n",
    "        transform: albumentations.ImageOnlyTransform,\n",
    "    ):\n",
    "        super(Winterize, self).__init__(True, 1)\n",
    "    \n",
    "    def _transform(self, img):\n",
    "        self.noise = np.random.normal(1, 1, img.shape)\n",
    "        img = albumentations.brightness_contrast_adjust(img)\n",
    "        return self.noise \n",
    "\n",
    "    def apply(self, img, clip_limit=2, **params):\n",
    "        if albumentations.get_num_channels(img) != 4:\n",
    "            raise TypeError(\"Winterize transformation expects RGBA image\")\n",
    "\n",
    "        return self._transform(img)\n",
    "\n",
    "    def get_params(self):\n",
    "        return {'contrast_limit': self.contrast_limit, 'tiles_count': self.tiles_count, 'tiles_size': self.tiles_size, 'tiles_relation': self.tiles_relative}\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return (\"contrast_limit\", \"tiles_count\", \"tiles_size\", \"tiles_relative\")\n",
    "\n",
    "a = Winterize()\n",
    "\n",
    "img_t = a.apply(img)\n",
    "plt.imshow(img_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "984aa5e2a995156e35edb7585281b3914fa5d1af0440f85bd60b2ec0c79e66ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
