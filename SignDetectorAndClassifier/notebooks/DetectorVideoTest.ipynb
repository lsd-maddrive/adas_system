{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d88f8a4f",
   "metadata": {},
   "source": [
    "# Core import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21e9951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "%cd adas_system/notebooks\n",
    "\n",
    "try:\n",
    "    USE_TPU = bool(os.environ['COLAB_TPU_ADDR'])\n",
    "except:\n",
    "    USE_TPU = False\n",
    "\n",
    "if USE_TPU:\n",
    "    # !pip uninstall pytorch\n",
    "    # !pip install cloud-tpu-client==0.10 torch==1.10.0\n",
    "    # !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "    !pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n",
    "    import torch_xla\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    USE_TPU = True\n",
    "\n",
    "else:\n",
    "    USE_TPU = False\n",
    "\n",
    "IN_COLAB = False\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    if not os.path.isfile('1_ClassifierResearch.ipynb'):\n",
    "        print('already exist')\n",
    "        !git clone --branch 9_SignDetector https://github.com/lsd-maddrive/adas_system.git\n",
    "        %cd adas_system/notebooks\n",
    "        !mkdir ../data/rtsd-frames\n",
    "        !unzip -j -q /content/drive/MyDrive/USER_FULL_FRAMES.zip -d ./../data/rtsd-frames\n",
    "        !pwd\n",
    "        !ls\n",
    "\n",
    "except:\n",
    "    if IN_COLAB:\n",
    "        !git clone --branch 9_SignDetector https://github.com/lsd-maddrive/adas_system.git\n",
    "        !gdown --id 1npYrZB_1WsgPv3cCrhv8KbfZuTvTxWow\n",
    "        %cd adas_system/notebooks\n",
    "        !mkdir ../data/rtsd-frames\n",
    "        !unzip -j -q /content/USER_FULL_FRAMES.zip -d ./../data/rtsd-frames\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "###\n",
    "sys.path.append('D:\\\\d_tsw\\\\main_diplom\\\\notebooks\\\\SignDetectorAndClassifier\\\\src')\n",
    "from helper_utils import *\n",
    "###\n",
    "\n",
    "TEXT_COLOR = 'black'\n",
    "\n",
    "# Зафиксируем состояние случайных чисел\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (17,10)\n",
    "\n",
    "if USE_TPU:\n",
    "    device = xm.xla_device()\n",
    "else:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031ec83e",
   "metadata": {},
   "source": [
    "# Init dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33385669",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    PROJECT_ROOT = pathlib.Path(os.path.join(os.curdir, os.pardir))\n",
    "else:\n",
    "    PROJECT_ROOT = pathlib.Path('..')\n",
    "\n",
    "PROJECT_ROOT = pathlib.Path('D:\\\\d_tsw\\\\main_diplom\\\\SignDetectorAndClassifier')\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "NOTEBOOKS_DIR = PROJECT_ROOT / 'notebooks'\n",
    "VIDEO_DIR = DATA_DIR / 'reg_videos'\n",
    "\n",
    "video_path = str(VIDEO_DIR / '1.mp4')\n",
    "print(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb25f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2e710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "now = datetime.now\n",
    "\n",
    "LARGE = True\n",
    "\n",
    "if LARGE:\n",
    "    restore = DATA_DIR / 'YoloV5L.pt'\n",
    "    model_cfg_file = DATA_DIR / 'yolov5l_custom_anchors.yaml'\n",
    "else:\n",
    "    restore = DATA_DIR / 'YoloV5.pt'\n",
    "    model_cfg_file = DATA_DIR / 'yolov5s_custom_anchors.yaml'\n",
    "\n",
    "logger = logging.getLogger()\n",
    "# logger.setLevel('WARN')\n",
    "model = Model(cfg=model_cfg_file, ch=3, nc=1);\n",
    "model.load_state_dict(torch.load(restore, map_location='cpu'))\n",
    "# logger.setLevel('INFO')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "detectInterface = makeDetectFromModel(model)\n",
    "\n",
    "if not detectInterface.device == device:\n",
    "    detectInterface.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d15c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "from utils.augmentations import letterbox\n",
    "\n",
    "'''\n",
    "frame - BRG input frame\n",
    "trained_img_size - img.shape on which Model trained\n",
    "'''\n",
    "def FastTransformImgToModelInputFormat(frame, trained_img_size=(640, 640)):\n",
    "    frame = letterbox(frame, img_size, auto=False)[0]\n",
    "    frame = frame.transpose((2, 0, 1))[::-1]\n",
    "    frame = np.ascontiguousarray(frame)\n",
    "    frame = torch.from_numpy(frame).float()\n",
    "    frame /= 255\n",
    "    frame = frame[None, ...]\n",
    "    return frame\n",
    "\n",
    "video = cv2.VideoCapture(video_path)\n",
    "display_handle1=display(1, display_id=True)\n",
    "display_handle2=display(2, display_id=True)\n",
    "\n",
    "if LARGE:\n",
    "    img_size = 416\n",
    "else:\n",
    "    img_size = 640\n",
    "    \n",
    "img_size = (img_size, img_size)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "i = 1\n",
    "while True:\n",
    "    i += 1\n",
    "    if i % 2:\n",
    "        for j in range(3):\n",
    "            _, frame_src = video.read()\n",
    "        continue\n",
    "        \n",
    "    t0 = now()\n",
    "    \n",
    "    \n",
    "    _, frame_src = video.read()\n",
    "    frame_marks = frame_src.copy()\n",
    "    \n",
    "    cv2.imshow('frame_src', frame_src)\n",
    "    cv2.waitKey()\n",
    "    assert False\n",
    "    \n",
    "    modelInput = FastTransformImgToModelInputFormat(frame_marks, trained_img_size=img_size)\n",
    "    pred = detectInterface(modelInput.to(device))\n",
    "    \n",
    "    data = detectInterface.translatePreds(pred, img_size, frame_src.shape, conf_thres=0.101, max_det=10)\n",
    "    \n",
    "    for i in range(data['count']):\n",
    "        COORD_ARR = [data['coords'][i][0], \n",
    "                     data['coords'][i][1], \n",
    "                     data['coords'][i][2], \n",
    "                     data['coords'][i][3]\n",
    "                    ]\n",
    "        \n",
    "        frame_marks = cv2.rectangle(frame_marks, (COORD_ARR[0], COORD_ARR[1]), \n",
    "                        (COORD_ARR[2], COORD_ARR[3]), \n",
    "                        (255, 0, 0), \n",
    "                        3)\n",
    "        \n",
    "        frame_marks = cv2.putText(frame_marks, str(round(data['confs'][i], 3)), \n",
    "                           (data['coords'][i][2] - 40, data['coords'][i][3]),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                           0.7, (255, 255, 0),\n",
    "                           5, cv2.LINE_AA\n",
    "                          )\n",
    "        \n",
    "        frame_marks = cv2.putText(frame_marks, str(round(data['confs'][i], 3)), \n",
    "                           (data['coords'][i][2] - 40, data['coords'][i][3]),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                           0.7, (0, 0, 0),\n",
    "                           2, cv2.LINE_AA\n",
    "                          )\n",
    "    dt = now() - t0\n",
    "    frame_src = cv2.putText(frame_src, \n",
    "                            'fps:' + str(round(1 / dt.total_seconds() , 2)),\n",
    "                            (0, 60),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            3, (0, 0, 0),\n",
    "                            3, cv2.LINE_AA\n",
    "                           )\n",
    "    _, frame_src = cv2.imencode('.jpeg', frame_src)\n",
    "    _, frame_marks = cv2.imencode('.jpeg', frame_marks)\n",
    "   \n",
    "    display_handle1.update(Image(data=frame_src.tobytes()))\n",
    "    display_handle2.update(Image(data=frame_marks.tobytes()))\n",
    "    \n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc277e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858c3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
