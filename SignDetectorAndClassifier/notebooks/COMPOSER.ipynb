{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd80ec95",
   "metadata": {},
   "source": [
    "# Ноутбук для демонстрации `Composer` - объединения детектора и классификатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9071b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now\n",
    "import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import shutil\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "# Зафиксируем состояние случайных чисел\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (17,10)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de296904",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    PROJECT_ROOT = pathlib.Path(os.readlink(f'/proc/{os.environ[\"JPY_PARENT_PID\"]}/cwd'))\n",
    "except FileNotFoundError:\n",
    "    __file = %pwd\n",
    "    PROJECT_ROOT = pathlib.Path(__file).parents[1]\n",
    "\n",
    "# FIX THIS PATHS BY YOURS\n",
    "DATA_DIR = PROJECT_ROOT / 'SignDetectorAndClassifier' / 'data'\n",
    "VIDEO_DIR = DATA_DIR / 'reg_videos'\n",
    "\n",
    "video_path = str(VIDEO_DIR / '4.mp4')\n",
    "print(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e9096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maddrive_adas.sign_det.composer import BasicSignsDetectorAndClassifier\n",
    "from maddrive_adas.sign_det.base import (\n",
    "    AbstractComposer, DetectedInstance,\n",
    "    AbstractSignClassifier, AbstractSignDetector\n",
    ")\n",
    "from maddrive_adas.sign_det.classifier import EncoderBasedClassifier\n",
    "from maddrive_adas.sign_det.detector import YoloV5Detector\n",
    "\n",
    "# FIX THIS PATHS BY YOURS\n",
    "DETECTOR_ARCHIVE = PROJECT_ROOT / 'detector_archive'\n",
    "CLASSIFIER_ARCHIVE = PROJECT_ROOT / 'encoder_archive'\n",
    "SUBCLASSIFIER_ARCHIVE = PROJECT_ROOT / 'subclassifier_3.24_3.25_archive'\n",
    "\n",
    "c: AbstractSignClassifier = EncoderBasedClassifier(\n",
    "    config_path=str(CLASSIFIER_ARCHIVE),\n",
    "    path_to_subclassifier_3_24_and_3_25_config=str(SUBCLASSIFIER_ARCHIVE)\n",
    ")\n",
    "\n",
    "d: AbstractSignDetector = YoloV5Detector(\n",
    "    config_path=str(DETECTOR_ARCHIVE)\n",
    ")\n",
    "\n",
    "composer: AbstractComposer = BasicSignsDetectorAndClassifier(\n",
    "    classifier=c,\n",
    "    detector=d\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433bfac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "video = cv2.VideoCapture(video_path)\n",
    "display_handle1=display(1, display_id=True)\n",
    "\n",
    "# TODO: plot detector confidences\n",
    "\n",
    "# const for plot\n",
    "COLOR = (0, 255, 0)\n",
    "DELTA = 15\n",
    "\n",
    "while True:\n",
    "    # save initial time\n",
    "    t0 = now()\n",
    "    # get video frame\n",
    "    _, frame_src = video.read()\n",
    "    \n",
    "    if random.random() > 0.2:\n",
    "        continue\n",
    "    # conver BRG to RGB for model input and get composer predition\n",
    "    frame_src = cv2.cvtColor(frame_src, cv2.COLOR_BGR2RGB)    \n",
    "    detected_instance, predicted_signs = composer.detect_and_classify(frame_src, d_conf_thres=0.2, d_iou_thres=0.1)\n",
    "    # print(predicted_signs)\n",
    "    for idx, sign in enumerate(predicted_signs):\n",
    "        \n",
    "        COORD_ARR, conf = detected_instance.get_abs_roi(idx)\n",
    "        frame_src = cv2.rectangle(\n",
    "            frame_src, \n",
    "            (COORD_ARR[0], COORD_ARR[1]), \n",
    "            (COORD_ARR[2], COORD_ARR[3]), \n",
    "            COLOR, \n",
    "            3\n",
    "        )\n",
    "        \n",
    "        substring = f'{sign[0]}:C:{round(sign[1], 5)}|D:{round(conf, 3)}'\n",
    "        \n",
    "        frame_src = cv2.putText(frame_src, substring, \n",
    "                           (COORD_ARR[0], COORD_ARR[3] + DELTA),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                           0.7, (255, 255, 255),\n",
    "                           3, cv2.LINE_AA\n",
    "                          )\n",
    "        \n",
    "        frame_src = cv2.putText(frame_src, substring, \n",
    "                           (COORD_ARR[0], COORD_ARR[3] + DELTA),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                           0.7, (0, 0, 0),\n",
    "                           1, cv2.LINE_AA\n",
    "                          )\n",
    "        \n",
    "    dt = now() - t0\n",
    "    frame_src = cv2.putText(\n",
    "        frame_src, \n",
    "        'fps:' + str(round(1 / dt.total_seconds() , 2)),\n",
    "        (0, 70),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        3, (0, 0, 0),\n",
    "        3, cv2.LINE_AA\n",
    "    )\n",
    "    \n",
    "    # transform back to BGR for cv2\n",
    "    frame_src = cv2.cvtColor(frame_src, cv2.COLOR_RGB2BGR)\n",
    "    _, frame_src = cv2.imencode('.jpeg', frame_src)\n",
    "        \n",
    "    display_handle1.update(Image(data=frame_src.tobytes()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
