{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b91b328",
   "metadata": {},
   "source": [
    "### Метрики энкодера на основе resnet*\n",
    "\n",
    "### Визуализация в 3 ГК помимо того что не дает колличественных оценок точности энкодера, так и несет в себе в лучшем случае около 40% информации от выходного вектора длинной 1024. \n",
    "\n",
    "###  Необходимо ознакомится с метриками и оценками модели энкодера. исп.:\n",
    "* kMeans\n",
    "* OneClass SVM\n",
    "* Gaussian Mixture\n",
    "\n",
    "### Конечная цель: оценка целесообразности применения энкодера в рамках *данной* задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246547b7",
   "metadata": {},
   "source": [
    "Что откуда качать:\n",
    "\n",
    "* https://drive.google.com/file/d/1-oIPyg3uFT1n--MXyR4Uzx95YqR3NsNT/view?usp=sharing - дополнительные знаки - не референсные. Часть из них - вырезка из видосов, часть - собранно ручками. Разместить в папке *data/additional_sign/*\n",
    "* https://drive.google.com/file/d/1-rTwhmdUdcuPMYz8BiPQV3fiWCSJjE20/view?usp=sharing - *last_encoder_1024_98* - веса энкодера. Разместить в папке с ноутбуком.\n",
    "* https://drive.google.com/file/d/1-K3ee1NbMmx_0T5uwMesStmKnZO_6mWi/view?usp=sharing - rtds с csv, содержащей инфу. Разместить в папке *data*: data/R_MERGED/.. и data/RTDS_DATASET.csv.\n",
    "* https://drive.google.com/file/d/1-l3VvU-WtSoXbW_AaTFUreVD-tgXV8Q0/view?usp=sharing - стоковые знаки. Используются как референс, то есть объеденяются с rtds с пометкой 'train'. Разместить так: data/STOCK_SIGNS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# core imports\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# append src\n",
    "PROJECT_ROOT = Path(os.readlink(f'/proc/{os.environ[\"JPY_PARENT_PID\"]}/cwd'))\n",
    "DATA_DIR = PROJECT_ROOT / 'SignDetectorAndClassifier' / 'data'\n",
    "\n",
    "# Зафиксируем состояние случайных чисел\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (17,10)\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "device\n",
    "\n",
    "PLOT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e7384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maddrive_adas.utils.models import get_model_and_img_size\n",
    "encoder, img_size = get_model_and_img_size(DATA_DIR / 'encoder_config.json')\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "from maddrive_adas.utils.checkpoint import load_checkpoint\n",
    "encoder, _, _, _ = load_checkpoint(encoder, filename=str(DATA_DIR / 'last_encoder'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d951445",
   "metadata": {},
   "source": [
    "### Этап 1.1. Берем RTDS, из него берем *train* как *baseline*. Заменяем *valid* на *test*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33139cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PREFIX = DATA_DIR / 'ENCODER_DATASET'\n",
    "RTDS_DF = pd.read_csv(DATASET_PREFIX / 'WIDE_DATASET_4_ENCODER.csv')\n",
    "RTDS_DF['filepath'] = RTDS_DF['filepath'].apply(lambda x: str(DATASET_PREFIX / x))\n",
    "RTDS_DF.drop_duplicates(subset=['filepath'], inplace=True)\n",
    "\n",
    "# убираем доп знаки \n",
    "# RTDS_DF = RTDS_DF[RTDS_DF['filepath'].str.contains('rtsd')]\n",
    "\n",
    "TARGET_SIGNS = [\n",
    "    '1.1', '1.6', '1.8', '1.22', '1.31', '1.33', \n",
    "    '2.1', '2.2', '2.3', '2.4', '2.5', \n",
    "    '3.1', '3.18', '3.20', '3.21', '3.22', '3.23', '3.24',\n",
    "    '3.25', '3.27', '3.28', '3.31', \n",
    "    '4.1.1', '4.3', \n",
    "    '5.5', '5.6', '5.16', \n",
    "    '5.19.1', '5.20', \n",
    "    '6.3.2', '6.4', \n",
    "    '7.3', '7.4'\n",
    "]\n",
    "\n",
    "RTDS_DF = RTDS_DF[RTDS_DF['sign'].isin(TARGET_SIGNS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f27b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "RTDS_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb48b984",
   "metadata": {},
   "outputs": [],
   "source": [
    "RTDS_DF[RTDS_DF['filepath'].str.contains('rtsd')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa427d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(RTDS_DF['sign'])))\n",
    "print(len(set(RTDS_DF['encoded'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac7c929",
   "metadata": {},
   "source": [
    "### *train* как референс, *valid* - query для валидации.\n",
    "### Этап 1.2. Формируем DataFrame отсутствущих знаков в RTDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c19ae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "included_signs = sorted(set(RTDS_DF.sign))\n",
    "print('Included signs in ENCODER_DATASET:', included_signs)\n",
    "not_included_signs = sorted(set(TARGET_SIGNS) - set(RTDS_DF.sign))\n",
    "print('Not included in ENCODER_DATASET:', not_included_signs)\n",
    "\n",
    "print('Getting aditional sings...')\n",
    "additional_DF = pd.DataFrame(columns=RTDS_DF.columns)\n",
    "\n",
    "encode_offset = max(set(RTDS_DF['encoded'])) + 1\n",
    "files = os.listdir(DATA_DIR / 'additional_sign')\n",
    "\n",
    "skipped_signs = []\n",
    "row_list = []\n",
    "\n",
    "for file in files:\n",
    "    sign = file.split('_')[0]\n",
    "     \n",
    "    if sign.rsplit('.', 1)[0] == '3.25':\n",
    "        sign = '3.25'\n",
    "        \n",
    "    if sign.rsplit('.', 1)[0] == '3.24':\n",
    "        sign = '3.24'         \n",
    "\n",
    "    if sign in included_signs:\n",
    "        skipped_signs.append(sign)\n",
    "        continue\n",
    "        \n",
    "    row = {'filepath': str(DATA_DIR / 'additional_sign' / file), \n",
    "           'sign': sign, \n",
    "           'set': 'test', # HANDLE ME\n",
    "           'encoded': None\n",
    "          }\n",
    "\n",
    "    row_list.append(row)\n",
    "\n",
    "print('Skipped signs:', skipped_signs)\n",
    "additional_DF = pd.DataFrame(row_list, columns=RTDS_DF.columns)\n",
    "le.fit(list(set(additional_DF.sign).union(set(RTDS_DF.sign))))\n",
    "\n",
    "print('Including part of additional_DF for:', sorted(set(additional_DF.sign)), 'sign.')\n",
    "additional_DF = additional_DF[~additional_DF['sign'].isin(RTDS_DF['sign'])]\n",
    "\n",
    "RTDS_DF = pd.concat([RTDS_DF, additional_DF], ignore_index=True)\n",
    "RTDS_DF['encoded'] = le.transform(RTDS_DF['sign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb015b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_subset = RTDS_DF[RTDS_DF['set'] == 'test']\n",
    "# display(valid_subset)\n",
    "sum(valid_subset['sign'] == '1.6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db48ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('So we got', len(set(RTDS_DF['sign'])), 'signs. Assume == 33')\n",
    "LABEL_DICT = dict(zip(RTDS_DF.sign, RTDS_DF.encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4d31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_from_train_for_signs = sorted(set(RTDS_DF.loc[RTDS_DF['set'] == 'train', 'sign']))\n",
    "print('We will get centroids from TRAIN for', centroid_from_train_for_signs)\n",
    "centroid_from_stock_for_signs = sorted(set(TARGET_SIGNS) - set(centroid_from_train_for_signs))\n",
    "print('We should get centroids from STOCK signs for', centroid_from_stock_for_signs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03085880",
   "metadata": {},
   "source": [
    "### Этап 2. Формируем для отсутствующих~=**ДЛЯ ВСЕХ** знаков baseline из образцовых знаков с википедии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2392a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOCK_SIGNS_CSV_LOCATION = DATA_DIR / 'STOCK_SIGNS/STOCK_SIGNS.csv'\n",
    "STOCK_SIGNS_DATAFRAME = pd.read_csv(STOCK_SIGNS_CSV_LOCATION)\n",
    "STOCK_SIGNS_DATAFRAME.rename({'SIGN': 'sign'}, axis='columns', inplace=True)\n",
    "\n",
    "STOCK_SIGNS_DATAFRAME['filepath'] = STOCK_SIGNS_DATAFRAME['filepath'].apply(lambda x: str(x).replace('\\\\', '/'))\n",
    "STOCK_SIGNS_DATAFRAME.loc[STOCK_SIGNS_DATAFRAME['sign'] == '5.19.2', 'sign'] = '5.19.1'\n",
    "\n",
    "STOCK_SIGNS_DATAFRAME['sign'] = STOCK_SIGNS_DATAFRAME['sign'].apply(\n",
    "        lambda x: '3.25' if x.rsplit('.', 1)[0] == '3.25' else x)\n",
    "\n",
    "## FIXUP для проблем описанных ниже\n",
    "STOCK_SIGNS_DATAFRAME['sign'] = STOCK_SIGNS_DATAFRAME['sign'].apply(\n",
    "        lambda x: '3.18' if x.rsplit('.', 1)[0] == '3.18' else x)\n",
    "\n",
    "STOCK_SIGNS_DATAFRAME['sign'] = STOCK_SIGNS_DATAFRAME['sign'].apply(\n",
    "        lambda x: '2.3' if x.rsplit('.', 1)[0] == '2.3' else x)\n",
    "\n",
    "STOCK_SIGNS_DATAFRAME['sign'] = STOCK_SIGNS_DATAFRAME['sign'].apply(\n",
    "        lambda x: '3.24' if x.rsplit('.', 1)[0] == '3.24' else x)\n",
    "\n",
    "STOCK_SIGNS_DATAFRAME['filepath'] = STOCK_SIGNS_DATAFRAME['filepath'].apply(lambda x: str(DATA_DIR / x))\n",
    "STOCK_SIGNS_DATAFRAME['encoded'] = [LABEL_DICT[i] for i in STOCK_SIGNS_DATAFRAME['sign']]\n",
    "\n",
    "STOCK_SIGNS_DATAFRAME['set'] = 'train'\n",
    "\n",
    "print('Leave only signs from', centroid_from_stock_for_signs)\n",
    "STOCK_SIGNS_DATAFRAME = STOCK_SIGNS_DATAFRAME[STOCK_SIGNS_DATAFRAME['sign'].isin(\n",
    "    centroid_from_stock_for_signs)]\n",
    "\n",
    "display(STOCK_SIGNS_DATAFRAME)\n",
    "\n",
    "RTDS_DF = pd.concat([RTDS_DF, STOCK_SIGNS_DATAFRAME], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cdfb44",
   "metadata": {},
   "source": [
    "### Baseline готов, тестовый датасет готов. Че хотим? Хотим получить какие-нибудь метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2692320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maddrive_adas.utils.transforms import get_minimal_and_augment_transforms\n",
    "from utils.datasets import SignDataset\n",
    "\n",
    "minimal_transform, _, = get_minimal_and_augment_transforms(img_size)\n",
    "\n",
    "train_dataset = SignDataset(\n",
    "    RTDS_DF, \n",
    "    set_label='train', \n",
    "    transform=minimal_transform, \n",
    "    hyp=None,\n",
    "    alpha_color=144\n",
    ")\n",
    "\n",
    "valid_dataset = SignDataset(\n",
    "    RTDS_DF, \n",
    "    set_label='test',  \n",
    "    transform=minimal_transform, \n",
    "    hyp=None,\n",
    "    alpha_color=144\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7dd09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from maddrive_adas.utils.datasets import get_dataloader_from_dataset\n",
    "\n",
    "@torch.no_grad()\n",
    "def simpleGetAllEmbeddings(model, dataset, batch_size, dsc=''):\n",
    "    dataloader = get_dataloader_from_dataset(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    s, e = 0, 0\n",
    "    pbar = tqdm(\n",
    "        enumerate(dataloader),\n",
    "        total=len(dataloader),\n",
    "        position=0,\n",
    "        leave=False,\n",
    "        desc='Getting all embeddings...' + dsc)\n",
    "    \n",
    "    info_arr = []\n",
    "    add_info_len = None\n",
    "\n",
    "    for idx, (data, labels, info) in pbar:\n",
    "        data = data.to(device)\n",
    "        q = model(data)\n",
    "\n",
    "        if labels.dim() == 1:\n",
    "            labels = labels.unsqueeze(1)\n",
    "        if idx == 0:\n",
    "            labels_ret = torch.zeros(\n",
    "                len(dataloader.dataset),\n",
    "                labels.size(1),\n",
    "                device=device,\n",
    "                dtype=labels.dtype,\n",
    "            )\n",
    "            all_q = torch.zeros(\n",
    "                len(dataloader.dataset),\n",
    "                q.size(1),\n",
    "                device=device,\n",
    "                dtype=q.dtype,\n",
    "            )\n",
    "\n",
    "        info = np.array(info)\n",
    "        if add_info_len == None:\n",
    "            add_info_len = info.shape[0]\n",
    "\n",
    "        info_arr.extend(info.T.reshape((-1, add_info_len)))\n",
    "        e = s + q.size(0)\n",
    "        all_q[s:e] = q\n",
    "        labels_ret[s:e] = labels\n",
    "        s = e\n",
    "\n",
    "    labels_ret = labels_ret.squeeze(1)\n",
    "    all_q = torch.nn.functional.normalize(all_q)\n",
    "    return all_q, labels_ret, info_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc729ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1800\n",
    "num_workers = 16\n",
    "\n",
    "encoder.eval()\n",
    "train_embeddings, train_labels, train_additional_info = simpleGetAllEmbeddings(\n",
    "    encoder, train_dataset, batch_size, ' for train'\n",
    ")\n",
    "\n",
    "test_embeddings, test_labels, test_additional_info = simpleGetAllEmbeddings(\n",
    "    encoder, valid_dataset, batch_size, ' for valid'\n",
    ")\n",
    "\n",
    "print('Test labels:', test_labels.unique(), 'len:', len(test_labels.unique()))\n",
    "print('Train labels:', train_labels.unique(), 'len:', len(train_labels.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ae270",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_embeddings.max())\n",
    "print(test_embeddings.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb3518",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(RTDS_DF[RTDS_DF['set']=='train']['encoded'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c5fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(RTDS_DF[RTDS_DF['set']=='test']['sign'])))\n",
    "print(len(set(RTDS_DF[RTDS_DF['set']=='train']['sign'])))\n",
    "\n",
    "print(len(set(RTDS_DF[RTDS_DF['set'] == 'test']['encoded'])))\n",
    "print(len(set(RTDS_DF[RTDS_DF['set'] == 'train']['encoded'])))\n",
    "\n",
    "print(len(set(RTDS_DF[RTDS_DF['set']=='test'].index)))\n",
    "print(len(RTDS_DF[RTDS_DF['set']=='train'].index))\n",
    "\n",
    "print(len(set(RTDS_DF[RTDS_DF['set']=='test'].index)))\n",
    "print(len(RTDS_DF[RTDS_DF['set']=='train'].index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a6e5b0",
   "metadata": {},
   "source": [
    "### Выше все ок, тестовый набор содержит тест+валид, который сформирован ноутбуков *RTSD-R_MERGED.ipynb*. В валид попало много знаков пешеходного перехода, т.к. их количество значительно превосходило остальные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22987833",
   "metadata": {},
   "source": [
    "## Get Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e36b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "INVERSED_LABEL_DICT = {v: k for k, v in LABEL_DICT.items()}\n",
    "\n",
    "labels_list = train_labels.cpu().numpy()\n",
    "labels_set = list(set(labels_list))\n",
    "\n",
    "embeddingsListForCentroids = train_embeddings.cpu().numpy()\n",
    "centroid_location_dict_cpu = {}\n",
    "\n",
    "p = tqdm(labels_set)\n",
    "for label in p:\n",
    "    p.set_description(\n",
    "        f'Current label: {label} [{INVERSED_LABEL_DICT[label]}]'\n",
    "    )\n",
    "    mask = labels_list == label\n",
    "    \n",
    "    currentLabelEmbeddingsForCentroids = embeddingsListForCentroids[mask]\n",
    "    zipped = list(zip(*currentLabelEmbeddingsForCentroids))\n",
    "    \n",
    "    singleCoord = []\n",
    "    for coord in zipped:\n",
    "        coord = sum(coord) / len(coord)\n",
    "        singleCoord.append(coord)\n",
    "        # print(coord)\n",
    "        \n",
    "    centroid_location_dict_cpu[label] = singleCoord\n",
    "\n",
    "centroid_location_dict_gpu = {}\n",
    "for key, item in centroid_location_dict_cpu.items():\n",
    "    centroid_location_dict_gpu[key] = torch.Tensor(item).to(device)\n",
    "\n",
    "print('Getting centroids done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f41ce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_nearest_centroids(\n",
    "        embs, #np.array, \n",
    "        labels,\n",
    "        centroid_coords_dict_gpu, #: dict[int, np.array],\n",
    "    ): # -> list[tuple[float, str]]:\n",
    "\n",
    "    labels_per_embeddings = labels.cpu().tolist()\n",
    "\n",
    "    centroid_index_to_key = {\n",
    "        int(index): int(val) for index, val in enumerate(\n",
    "            centroid_location_dict_gpu.keys()\n",
    "        )\n",
    "    }\n",
    "    centroid_locations = torch.stack([centroid_location_dict_gpu[label] for _, label in centroid_index_to_key.items()])\n",
    "    dist_sign_list = []\n",
    "    for i, emb in tqdm(\n",
    "            enumerate(embs),\n",
    "            total=len(embs)\n",
    "        ):\n",
    "\n",
    "        dist = (emb - centroid_locations).pow(2).sum(-1).sqrt()\n",
    "        key = centroid_index_to_key[int(torch.argmin(dist))]\n",
    "\n",
    "        realSign = INVERSED_LABEL_DICT[labels_per_embeddings[i]]\n",
    "        predictedSign = INVERSED_LABEL_DICT[key]\n",
    "        dist_sign_list.append(\n",
    "            (\n",
    "                float(dist[key]),\n",
    "                predictedSign\n",
    "            )\n",
    "        )\n",
    "    return dist_sign_list\n",
    "\n",
    "nearest_centroid_list_for_train = _get_nearest_centroids(\n",
    "    train_embeddings,\n",
    "    train_labels,\n",
    "    centroid_location_dict_gpu,\n",
    ")\n",
    "\n",
    "nearest_centroid_list_for_test = _get_nearest_centroids(\n",
    "    test_embeddings,\n",
    "    test_labels,\n",
    "    centroid_location_dict_gpu,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adaf66d",
   "metadata": {},
   "source": [
    "### lets construct plot DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11131998",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(centroid_location_dict_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "dim3 = True\n",
    "print('Constructing dataframe for plotting.')\n",
    "\n",
    "coords = ['x', 'y'] + (['z'] if dim3 else [])\n",
    "plot_df = pd.DataFrame(\n",
    "    columns=[*coords, 'type', 'size', 'sign', 'filepath', 'color', 'marker', 'nearest_centroid']\n",
    ")\n",
    "\n",
    "reducer = PCA(\n",
    "    n_components=3 if dim3 else 2, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_size = 2\n",
    "train_type = 'train'\n",
    "test_size = 2\n",
    "test_type = 'test'\n",
    "centroid_size = 10\n",
    "centroid_type = 'centroid'\n",
    "\n",
    "## FIT REDUCER\n",
    "train_embeddings_ = reducer.fit_transform(train_embeddings.cpu().numpy())\n",
    "\n",
    "from itertools import cycle\n",
    "import plotly.express as px\n",
    "palette = cycle(\n",
    "        [*px.colors.qualitative.Dark24, \n",
    "         *px.colors.qualitative.Alphabet, \n",
    "         *px.colors.qualitative.Light24]\n",
    "    )\n",
    "colorDict = {}\n",
    "\n",
    "listOfRows = []\n",
    "\n",
    "## CENTROIDS\n",
    "for k, v in tqdm(centroid_location_dict_cpu.items()):\n",
    "    coords = reducer.transform(np.array(v).reshape(1, -1)).flatten()\n",
    "    path = RTDS_DF[RTDS_DF['sign'] == INVERSED_LABEL_DICT[k]]['filepath'].values[0]\n",
    "    colorDict[INVERSED_LABEL_DICT[k]] = next(palette)\n",
    "    row = pd.Series(\n",
    "        [*coords, centroid_type, centroid_size, INVERSED_LABEL_DICT[k], path, \n",
    "         colorDict[INVERSED_LABEL_DICT[k]], 'diamond', (0.0, 'self')],\n",
    "        index=plot_df.columns,\n",
    "    )\n",
    "    listOfRows.append(row)\n",
    "\n",
    "\n",
    "    \n",
    "## TRAIN\n",
    "for idx, (fitted_coords, label, info) in tqdm(\n",
    "        enumerate(\n",
    "            zip(train_embeddings_,\n",
    "                train_labels, \n",
    "                train_additional_info)\n",
    "        ),\n",
    "        total=len(train_labels)\n",
    "    ):\n",
    "    label = label.cpu().numpy()\n",
    "    color = colorDict[INVERSED_LABEL_DICT[int(label)]]\n",
    "    \n",
    "    row = pd.Series(\n",
    "        [*fitted_coords, train_type, train_size, INVERSED_LABEL_DICT[int(label)], info[0], \n",
    "         colorDict[INVERSED_LABEL_DICT[k]], 'circle',\n",
    "        nearest_centroid_list_for_train[idx]\n",
    "        ],\n",
    "        index=plot_df.columns,\n",
    "    )\n",
    "    listOfRows.append(row)\n",
    "\n",
    "## TEST\n",
    "test_embeddings_ = reducer.transform(test_embeddings.cpu().numpy())\n",
    "\n",
    "for idx, (coord, label, info) in tqdm(\n",
    "    enumerate(\n",
    "        zip(test_embeddings_, test_labels, test_additional_info)),\n",
    "    total=len(test_labels)\n",
    "):\n",
    "    label = label.cpu().numpy()\n",
    "    \n",
    "    row = pd.Series(\n",
    "        [*coord, test_type, test_size, info[1], info[0], \n",
    "        colorDict[INVERSED_LABEL_DICT[k]], 'circle',\n",
    "        nearest_centroid_list_for_test[idx]\n",
    "        ],\n",
    "        index=plot_df.columns,\n",
    "    )\n",
    "    \n",
    "    listOfRows.append(row)\n",
    "\n",
    "plot_df = pd.concat([plot_df, pd.DataFrame(listOfRows)], axis=0)\n",
    "plot_df['x'] = plot_df['x'].astype(float)\n",
    "plot_df['y'] = plot_df['y'].astype(float)\n",
    "if 'z' in plot_df.columns:\n",
    "    plot_df['z'] = plot_df['z'].astype(float)\n",
    "    \n",
    "plot_df['size'] = plot_df['size'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adba312",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(reducer.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dd6372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from itertools import cycle\n",
    "\n",
    "PLOT_CENTROID_AND_TEST_ONLY = True\n",
    "PLOT_LIMIT_FRAC = 1\n",
    "\n",
    "if PLOT_CENTROID_AND_TEST_ONLY:\n",
    "    plot_df_ = plot_df[plot_df['type'] != 'train'][::-1]\n",
    "else:\n",
    "    plot_df_ = plot_df[::-1]\n",
    "\n",
    "if PLOT_LIMIT_FRAC:\n",
    "    plot_df_ = plot_df_.groupby(['sign', 'type']).sample(frac=PLOT_LIMIT_FRAC)\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc, html, Input, Output, no_update\n",
    "import base64\n",
    "\n",
    "app = JupyterDash(__name__)\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"graph-tooltip-5\", \"show\"),\n",
    "    Output(\"graph-tooltip-5\", \"bbox\"),\n",
    "    Output(\"graph-tooltip-5\", \"children\"),\n",
    "    Input(\"graph-5\", \"hoverData\"),\n",
    ")\n",
    "def display_hover(hoverData):\n",
    "\n",
    "    if hoverData is None:\n",
    "        return False, no_update, no_update\n",
    "\n",
    "    hover_data = hoverData[\"points\"][0]\n",
    "    bbox = hover_data[\"bbox\"]\n",
    "    num = hover_data[\"pointNumber\"]\n",
    "    data = hover_data['customdata']\n",
    "    sign = data[0]\n",
    "    rel_img_path = data[1]\n",
    "    nearest_centroid_info = data[3]\n",
    "    # print(nearest_centroid_info[0])\n",
    "    try:\n",
    "        with open(rel_img_path, 'rb') as f:\n",
    "            image = f.read()\n",
    "    except FileNotFoundError as exc_obj:\n",
    "        print('[!] Exception', data, exc_obj)\n",
    "        return False, no_update, no_update\n",
    "    \n",
    "    b64sed_image = 'data:image/png;base64,' + base64.b64encode(image).decode('utf-8')\n",
    "    prgrph_str = 'Sign:' + sign + ', Nearest:' + str(nearest_centroid_info[1]) \\\n",
    "            + ', Dist:' + str(nearest_centroid_info[0])\n",
    "    \n",
    "    children = [\n",
    "        html.Div([\n",
    "            html.Img(\n",
    "                src=b64sed_image,\n",
    "                style={\"width\": \"70px\", 'display': 'block', 'margin': '0 auto'},\n",
    "            ),\n",
    "            html.P(prgrph_str, style={\"fontSize\": 14, 'text-align':'center'}),\n",
    "            html.P(rel_img_path, style={\"fontSize\": 10}),\n",
    "        ])\n",
    "    ]\n",
    "    return True, bbox, children\n",
    "\n",
    "plot_args = {\n",
    "    'x': 'x',\n",
    "    'y': 'y',\n",
    "    'color': 'sign',\n",
    "    'size': 'size',\n",
    "    'opacity': 0.2 if dim3 else 0.5,\n",
    "    'symbol': 'type',\n",
    "    'hover_name': 'sign',\n",
    "    'hover_data': ['sign', 'filepath', 'type', 'nearest_centroid'],\n",
    "    'animation_group': 'type',\n",
    "    'color_discrete_sequence': [\n",
    "        *px.colors.qualitative.Dark24, \n",
    "        *px.colors.qualitative.Alphabet, \n",
    "        *px.colors.qualitative.Light24\n",
    "    ]\n",
    "}\n",
    "\n",
    "if dim3:\n",
    "    plotFcn = px.scatter_3d\n",
    "    plot_args.update({'z': 'z'})\n",
    "else:\n",
    "    plotFcn = px.scatter\n",
    "      \n",
    "fig = plotFcn(\n",
    "        plot_df_,\n",
    "        **plot_args,\n",
    "\n",
    "    )\n",
    "\n",
    "fig.update_traces(\n",
    "    hoverinfo=\"none\", \n",
    "    hovertemplate=None,\n",
    "    marker=dict(\n",
    "        line=dict(\n",
    "        width=0)\n",
    "    )\n",
    ")\n",
    "    \n",
    "fig.update_layout(\n",
    "    width=950,\n",
    "    height=950\n",
    ")\n",
    "\n",
    "## FIX Z-ORDER\n",
    "if True:\n",
    "    sampleData = list(fig.data)\n",
    "    centroidsList = []\n",
    "    for t in list(sampleData[:]):\n",
    "        if (t.ids[0] == 'centroid'):\n",
    "            temp_t = t\n",
    "            sampleData.remove(t)\n",
    "            temp_t['marker']['opacity'] = 1\n",
    "            temp_t['text'] = temp_t['customdata'][0][0]\n",
    "            temp_t['textposition'] = 'top center'\n",
    "            temp_t['mode'] = 'markers+text'\n",
    "            temp_t['marker']['line']['width'] = 40 if dim3 else 2\n",
    "            temp_t['marker']['line']['color'] = 'rgb(0, 0, 0)'\n",
    "            centroidsList.append(temp_t)\n",
    "            \n",
    "    fig.data = tuple(sampleData + centroidsList)\n",
    "    \n",
    "fig.update_layout(font=dict(size=18))\n",
    "\n",
    "app.layout = html.Div(\n",
    "            className=\"container\",\n",
    "            children=[\n",
    "                html.Div(html.H2(\"Visualization\")),\n",
    "                dcc.Graph(id=\"graph-5\", figure=fig, clear_on_unhover=True),\n",
    "                dcc.Tooltip(id=\"graph-tooltip-5\", direction='bottom'),\n",
    "            ],\n",
    "        )\n",
    "    \n",
    "if __name__ == '__main__' and PLOT:\n",
    "    app.run_server(mode='inline', debug=True, port=2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095bfc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_ = '6.3.2'\n",
    "centroid = centroid_location_dict_gpu[LABEL_DICT['6.4']]\n",
    "sign_embeddings = test_embeddings[test_labels == LABEL_DICT[sign_]] \n",
    "print(sign_embeddings)\n",
    "\n",
    "distances = (sign_embeddings - centroid).pow(2).sum(-1).sqrt()\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1517c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEulerDistance(a, b):\n",
    "    squares = [(p-q) ** 2 for p, q in zip(a, b)]\n",
    "    return sum(squares) ** .5\n",
    "    \n",
    "distancesSign = {}\n",
    "\n",
    "centroidSignList = list(centroid_location_dict_cpu.keys())\n",
    "# print(centroidSignList)\n",
    "for idx, ikey in enumerate(centroidSignList):\n",
    "    distancesSign[INVERSED_LABEL_DICT[ikey]] = {}\n",
    "    distancesSign[INVERSED_LABEL_DICT[ikey]][INVERSED_LABEL_DICT[ikey]] = np.NaN\n",
    "    for jdx, jkey in enumerate(centroidSignList[idx + 1:]):\n",
    "        dist = getEulerDistance(\n",
    "            centroid_location_dict_cpu[ikey],\n",
    "            centroid_location_dict_cpu[jkey]\n",
    "        )\n",
    "        distancesSign[INVERSED_LABEL_DICT[ikey]][INVERSED_LABEL_DICT[jkey]] = dist\n",
    "        \n",
    "# distancesSign\n",
    "distancesSign = pd.DataFrame.from_dict(distancesSign)\n",
    "for i in range(len(distancesSign)):\n",
    "    distancesSign.iloc[i] = distancesSign.iloc[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c665018",
   "metadata": {},
   "outputs": [],
   "source": [
    "figH = px.imshow(distancesSign)\n",
    "\n",
    "app1 = JupyterDash(__name__)\n",
    "\n",
    "PATH_PREFIX = '../data/STOCK_SIGNS/'\n",
    "PATH_POSTFIX = '.png'\n",
    "\n",
    "@app1.callback(\n",
    "    Output(\"graph-tooltip-5\", \"show\"),\n",
    "    Output(\"graph-tooltip-5\", \"bbox\"),\n",
    "    Output(\"graph-tooltip-5\", \"children\"),\n",
    "    Input(\"graph-5\", \"hoverData\"),\n",
    ")\n",
    "def display_hover(hoverData):\n",
    "    if hoverData is None:\n",
    "        return False, no_update, no_update\n",
    "\n",
    "    hover_data = hoverData[\"points\"][0]\n",
    "    \n",
    "    hover_data['x'] = '2.3.1' if hover_data['x'] == '2.3' else hover_data['x']\n",
    "    hover_data['y'] = '2.3.1' if hover_data['y'] == '2.3' else hover_data['y']        \n",
    "    hover_data['x'] = '3.18.1'  if hover_data['x'] == '3.18' else hover_data['x'] \n",
    "    hover_data['y'] = '3.18.1'  if hover_data['y'] == '3.18' else hover_data['y']\n",
    "        \n",
    "    x_img_path = PATH_PREFIX + hover_data['x'] + PATH_POSTFIX\n",
    "    y_img_path = PATH_PREFIX + hover_data['y'] + PATH_POSTFIX\n",
    "    \n",
    "    try:\n",
    "        with open(x_img_path, 'rb') as f:\n",
    "            image1 = f.read()\n",
    "        with open(y_img_path, 'rb') as f:\n",
    "            image2 = f.read()\n",
    "    except:\n",
    "        print(hoverData)\n",
    "        return False, no_update, no_update\n",
    "    \n",
    "    img1 = 'data:image/png;base64,' + base64.b64encode(image1).decode('utf-8')\n",
    "    img2 = 'data:image/png;base64,' + base64.b64encode(image2).decode('utf-8')\n",
    "\n",
    "    children = [\n",
    "        html.Div([\n",
    "            html.Img(\n",
    "                src=img1,\n",
    "                style={\"width\": \"70px\",  'margin': '0 auto'},\n",
    "            ),\n",
    "            html.Img(\n",
    "                src=img2,\n",
    "                style={\"width\": \"70px\",  'margin': '0 auto'},\n",
    "            ),\n",
    "            html.P(hover_data['x'] + ':' + hover_data['y'], style={\"fontSize\": 14, 'text-align':'center'}),\n",
    "            html.P(str(hover_data['z']), style={\"fontSize\": 14, 'text-align':'center'}),\n",
    "            \n",
    "        ]),\n",
    "    ]\n",
    "    return True, hover_data[\"bbox\"], children\n",
    "\n",
    "figH.update_traces(hoverinfo=\"none\", hovertemplate=None)\n",
    "    \n",
    "figH.update_layout(\n",
    "        width=600,\n",
    "        height=600)\n",
    "\n",
    "app1.layout = html.Div(\n",
    "    className=\"container\",\n",
    "        children=[\n",
    "            html.Div(html.H2(\"Расстояние между центроидами\")),\n",
    "            dcc.Graph(id=\"graph-5\", figure=figH, clear_on_unhover=True),\n",
    "            dcc.Tooltip(id=\"graph-tooltip-5\", direction='bottom'),\n",
    "            ],\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__' and PLOT:\n",
    "    app1.run_server(mode='inline', debug=True, port=2003)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7240b4d",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c10859",
   "metadata": {},
   "source": [
    "* train_embeddings, train_labels, train_additional_info - в этих переменных вся инфа о тестовых картинках;\n",
    "* centroid_location_dict_cpu - словарь центроидов на CPU.\n",
    "* centroid_location_dict_gpu - словарь центроидов на GPU.\n",
    "* getEulerDistance - функция эвклидова расстояния."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f80840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "sign_set = sorted(set(RTDS_DF['sign']))\n",
    "v = {v: 0 for v in sign_set}\n",
    "cf_dict = {k: deepcopy(v) for k in sign_set}\n",
    "\n",
    "CHECK_TRAIN = False\n",
    "embs = train_embeddings if CHECK_TRAIN else test_embeddings\n",
    "labels_per_embeddings = train_labels if CHECK_TRAIN else test_labels\n",
    "labels_per_embeddings = labels_per_embeddings.cpu().tolist()\n",
    "\n",
    "centroid_index_to_key = {int(index): int(val) for index, val in enumerate(centroid_location_dict_gpu.keys())}\n",
    "centroid_locations = torch.stack([centroid_location_dict_gpu[label] for _, label in centroid_index_to_key.items()])\n",
    "\n",
    "for i, emb in tqdm(\n",
    "        enumerate(embs),\n",
    "        total=len(embs)\n",
    "    ):\n",
    "    \n",
    "    dist = (emb - centroid_locations).pow(2).sum(-1).sqrt()\n",
    "    key = centroid_index_to_key[int(torch.argmin(dist))]\n",
    "    \n",
    "    realSign = INVERSED_LABEL_DICT[labels_per_embeddings[i]]\n",
    "    predictedSign = INVERSED_LABEL_DICT[key]\n",
    "\n",
    "    cf_dict[realSign][predictedSign] += 1\n",
    "    \n",
    "cf_df = pd.DataFrame(\n",
    "    columns=sorted(set(RTDS_DF.sign)),\n",
    "    index=sorted(set(RTDS_DF.sign))\n",
    ")\n",
    "\n",
    "for real_sign, predicted_signs in cf_dict.items():\n",
    "    for predicted_sign, val in predicted_signs.items():\n",
    "        cf_df[real_sign][predicted_sign] = val\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af036615",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_dict['2.2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acaf74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cf = px.imshow(\n",
    "    cf_df.apply(lambda x: (x / x.sum()) if x.sum() else 0, axis=1).replace(0, np.nan),\n",
    "    color_continuous_scale=px.colors.sequential.Cividis_r,\n",
    ")\n",
    "\n",
    "app2 = JupyterDash(__name__ + 'cf')\n",
    "\n",
    "PATH_PREFIX = '../data/STOCK_SIGNS/'\n",
    "PATH_POSTFIX = '.png'\n",
    "\n",
    "@app2.callback(\n",
    "    Output(\"graph-tooltip-5\", \"show\"),\n",
    "    Output(\"graph-tooltip-5\", \"bbox\"),\n",
    "    Output(\"graph-tooltip-5\", \"children\"),\n",
    "    Input(\"graph-5\", \"hoverData\"),\n",
    ")\n",
    "def display_hover(hoverData):\n",
    "    if hoverData is None:\n",
    "        return False, no_update, no_update\n",
    "\n",
    "    hover_data = hoverData[\"points\"][0]\n",
    "    sum_y = sum(map(int, cf_dict[hover_data['x']].values()))\n",
    "    \n",
    "    if not hover_data['z']:\n",
    "        return False, no_update, no_update\n",
    "    \n",
    "    hover_data['x'] = '2.3.1' if hover_data['x'] == '2.3' else hover_data['x']\n",
    "    hover_data['y'] = '2.3.1' if hover_data['y'] == '2.3' else hover_data['y']        \n",
    "    hover_data['x'] = '3.18.1'  if hover_data['x'] == '3.18' else hover_data['x'] \n",
    "    hover_data['y'] = '3.18.1'  if hover_data['y'] == '3.18' else hover_data['y']\n",
    "    hover_data['x'] = '3.25.10' if hover_data['x'] == '3.25' else hover_data['x']\n",
    "    hover_data['y'] = '3.25.10' if hover_data['y'] == '3.25' else hover_data['y']         \n",
    "    hover_data['x'] = '3.24.10' if hover_data['x'] == '3.24' else hover_data['x']\n",
    "    hover_data['y'] = '3.24.10' if hover_data['y'] == '3.24' else hover_data['y']   \n",
    "    \n",
    "    x_img_path = PATH_PREFIX + hover_data['x'] + PATH_POSTFIX\n",
    "    y_img_path = PATH_PREFIX + hover_data['y'] + PATH_POSTFIX\n",
    "    \n",
    "    bbox = hover_data[\"bbox\"]\n",
    "    \n",
    "    try:\n",
    "        with open(x_img_path, 'rb') as f:\n",
    "            image1 = f.read()\n",
    "        with open(y_img_path, 'rb') as f:\n",
    "            image2 = f.read()\n",
    "    except FileNotFoundError:\n",
    "        return False, no_update, no_update\n",
    "    \n",
    "    img1 = 'data:image/png;base64,' + base64.b64encode(image1).decode('utf-8')\n",
    "    img2 = 'data:image/png;base64,' + base64.b64encode(image2).decode('utf-8')\n",
    "\n",
    "    children = [\n",
    "        html.Div([\n",
    "            html.Img(\n",
    "                src=img1,\n",
    "                style={\"width\": \"70px\",  'margin': '0 auto'},\n",
    "            ),\n",
    "            html.Img(\n",
    "                src=img2,\n",
    "                style={\"width\": \"70px\",  'margin': '0 auto'},\n",
    "            ),\n",
    "            html.P(hover_data['x'] + ':' + hover_data['y'], style={\"fontSize\": 14, 'text-align':'center'}),\n",
    "            html.P(\n",
    "                str(hover_data['z']) \n",
    "                + ': all:' + str(int(sum_y * hover_data['z'])), \n",
    "                style={\"fontSize\": 14, 'text-align':'center'}\n",
    "            ),\n",
    "        ]),\n",
    "    ]\n",
    "    return True, bbox, children\n",
    "\n",
    "fig_cf.update_traces(\n",
    "        hoverinfo=\"none\", \n",
    "        hovertemplate=None)\n",
    "    \n",
    "fig_cf.update_layout(\n",
    "    width=950,\n",
    "    height=650,\n",
    "    xaxis_title='Target Sign',\n",
    "    yaxis_title='Predicted Sign'\n",
    ")\n",
    "\n",
    "app2.layout = html.Div(\n",
    "    className=\"container\",\n",
    "    children=[\n",
    "        html.Div(html.H2(\"Confusion matrix\")),\n",
    "            dcc.Graph(\n",
    "                id=\"graph-5\", \n",
    "                figure=fig_cf, \n",
    "                clear_on_unhover=True\n",
    "            ),\n",
    "        dcc.Tooltip(id=\"graph-tooltip-5\", direction='bottom'),\n",
    "    ],\n",
    ")\n",
    "    \n",
    "# fig_cf.show()\n",
    "if __name__ == '__main__' and PLOT:\n",
    "    app2.run_server(mode='inline', debug=True, port=2004)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9846156",
   "metadata": {},
   "source": [
    "Precision/F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2d99c5",
   "metadata": {},
   "source": [
    "Значения precision находятся в матрице ниже. В строках - актульные значения, в столбцах точность/вероятность предсказывания соответсвующего знака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0036782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TPdict = {}\n",
    "FNdict = {}\n",
    "FPdict = {}\n",
    "TNdict = {}\n",
    "\n",
    "for i, row in cf_df.iterrows():    \n",
    "    TPdict[i] = cf_df[i][i]\n",
    "    FNdict[i] = cf_df[i].sum() - TPdict[i]\n",
    "    FPdict[i] = cf_df.loc[i].sum() - TPdict[i]\n",
    "    TNdict[i] = cf_df.fillna(0).values.sum() - TPdict[i] - FNdict[i] - FPdict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1674608",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign = '3.22'\n",
    "print(TPdict[sign])\n",
    "print(FNdict[sign])\n",
    "print(FPdict[sign])\n",
    "print(TNdict[sign])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a56a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PrecisionDict = {}\n",
    "RecallDict = {}\n",
    "F1Dict = {}\n",
    "SupportDict = {}\n",
    "\n",
    "for i in TPdict.keys():\n",
    "    try:\n",
    "        PrecisionDict[i] = TPdict[i] / (TPdict[i] + FPdict[i])\n",
    "        RecallDict[i] = TPdict[i] / (TPdict[i] + FNdict[i])\n",
    "        F1Dict[i] = 2 / (1 / PrecisionDict[i] + 1 / RecallDict[i])\n",
    "        SupportDict[i] = TPdict[i] + FNdict[i]\n",
    "        # print(SupportDict[i]),\n",
    "        # print(sum(RTDS_DF[RTDS_DF['set']=='test']['sign'] == i))\n",
    "        assert SupportDict[i] == sum(RTDS_DF[RTDS_DF['set']=='test']['sign'] == i), \\\n",
    "            'For ' + str(i) + ' mismatch: ' + str(SupportDict[i]) + ' != ' + str(\n",
    "            sum(RTDS_DF[RTDS_DF['set']=='test']['sign'] == i)\n",
    "        )\n",
    "    except (ZeroDivisionError):\n",
    "        PrecisionDict[i] = RecallDict[i] = F1Dict[i] = 0\n",
    "        SupportDict[i] = sum(RTDS_DF[RTDS_DF['set']=='test']['sign'] == i)\n",
    "        print('ZDE for', i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d7923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Precision', 'Recall', 'F1', 'Support']\n",
    "metrics = {}\n",
    "\n",
    "for i in zip(PrecisionDict.items(), RecallDict.items(), F1Dict.items(), SupportDict.items()):\n",
    "    metrics[i[0][0]] = [i[0][1], i[1][1], i[2][1], i[3][1]]\n",
    "    \n",
    "metricsDf = pd.DataFrame().from_dict(metrics, orient='index')\n",
    "metricsDf.columns = columns\n",
    "# metricsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f1354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_from_stock_for_signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12447488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8261264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOT_INCLUDED_IN_TRAIN = centroid_from_stock_for_signs # ['1.31', '1.6', '2.4', '3.22', '3.25', '3.31', '6.3.2']\n",
    "\n",
    "TRAINED = metricsDf.loc[~metricsDf.index.isin(NOT_INCLUDED_IN_TRAIN)]\n",
    "NOT_TRAINED = metricsDf.loc[metricsDf.index.isin(NOT_INCLUDED_IN_TRAIN)]\n",
    "\n",
    "display(TRAINED)\n",
    "display(NOT_TRAINED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f8674",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, 'Next cells should be executed mannualy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4db492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_config_for_package(\n",
    "    model: nn.Module, \n",
    "    centroid_location_dict: dict,\n",
    "    model_config: str,\n",
    "    output_file_path: Path = Path('saved_model')\n",
    "):\n",
    "    print(f'Saving model for {model_config}')\n",
    "    torch.save({\n",
    "        'model': model.state_dict(),\n",
    "        'centroid_location': centroid_location_dict,\n",
    "        'model_config': model_config\n",
    "    }, output_file_path)\n",
    "    print('Saving success!')\n",
    "\n",
    "with open(DATA_DIR / 'encoder_config.json') as f:\n",
    "    model_config = f.read()\n",
    "    \n",
    "centroid_location_dict = {\n",
    "    INVERSED_LABEL_DICT[x]: coord for x, coord in centroid_location_dict_cpu.items()\n",
    "}\n",
    "save_model_config_for_package(\n",
    "    model=encoder,\n",
    "    centroid_location_dict=centroid_location_dict,\n",
    "    model_config=model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b1c076",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED.to_excel('trained.xls', engine='xlsxwriter')\n",
    "NOT_TRAINED.to_excel('not_trained.xls', engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d500de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed907089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c81a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metricsDf.to_excel('metrics3_24.xls', engine='xlsxwriter')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f126ba513cd923a91965ccfdcd1e275957d64ce4742838d456229721288bc16"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
