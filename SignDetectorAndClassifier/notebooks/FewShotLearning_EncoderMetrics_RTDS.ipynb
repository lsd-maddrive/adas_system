{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b91b328",
   "metadata": {},
   "source": [
    "### Метрики энкодера на основе Resnet18.  \n",
    "#### Выходной слой: *nn.Linear(in_features=512, out_features=1024, bias=True)*\n",
    "\n",
    "### Визуализация в 3 ГК помимо того что не дает колличественных оценок точности энкодера, так и несет в себе в лучшем случае около 40% информации от выходного вектора длинной 1024. \n",
    "\n",
    "###  Необходимо ознакомится с метриками и оценками модели энкодера. исп.:\n",
    "* kMeans\n",
    "* OneClass SVM\n",
    "* Gaussian Mixture\n",
    "\n",
    "### Конечная цель: оценка целесообразности применения энкодера в рамках *данной* задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import cv2\n",
    "import PIL\n",
    "import cv2\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "TEXT_COLOR = 'black'\n",
    "# Зафиксируем состояние случайных чисел\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (17,10)\n",
    "\n",
    "USE_COLAB_GPU = False\n",
    "IN_COLAB = False\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    USE_COLAB_GPU = True\n",
    "    from google.colab import drive\n",
    "except:\n",
    "    if IN_COLAB:\n",
    "        print('[!] YOU ARE IN COLAB, BUT DIDNT MOUND A DRIVE. Model wont be synced[!]')\n",
    "\n",
    "        if not os.path.isfile(CURRENT_FILE_NAME):\n",
    "            print(\"FIX ME\")\n",
    "        IN_COLAB = False\n",
    "\n",
    "    else:\n",
    "        print('[!] RUNNING NOT IN COLAB')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e7384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet\n",
    "encoder = resnet.resnet18(pretrained=True)\n",
    "encoder.fc = nn.Linear(in_features=512, out_features=1024, bias=True)\n",
    "r = encoder.load_state_dict(torch.load('last_encoder_1024_98')['model'])\n",
    "encoder.eval()\n",
    "assert r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa18a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def simpleGetAllEmbeddings(model, dataset, batch_size, dsc=''):\n",
    "    \n",
    "    dataloader = getDataLoaderFromDataset(\n",
    "        dataset,\n",
    "        shuffle=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    s, e = 0, 0\n",
    "    pbar = tqdm(\n",
    "        enumerate(dataloader), \n",
    "        total=len(dataloader),\n",
    "        position=0,\n",
    "        leave=False,\n",
    "        desc='Getting all embeddings...' + dsc)\n",
    "    info_arr = []\n",
    "    \n",
    "    add_info_len = None\n",
    "    \n",
    "    for idx, (data, labels, info) in pbar:\n",
    "        data = data.to(device)\n",
    "        \n",
    "        q = model(data)\n",
    "        \n",
    "        if labels.dim() == 1:\n",
    "            labels = labels.unsqueeze(1)\n",
    "        if idx == 0:\n",
    "            labels_ret = torch.zeros(\n",
    "                len(dataloader.dataset),\n",
    "                labels.size(1),\n",
    "                device=device,\n",
    "                dtype=labels.dtype,\n",
    "            )\n",
    "            all_q = torch.zeros(\n",
    "                len(dataloader.dataset),\n",
    "                q.size(1),\n",
    "                device=device,\n",
    "                dtype=q.dtype,\n",
    "            )\n",
    "        \n",
    "        info = np.array(info)\n",
    "        if add_info_len == None:\n",
    "            add_info_len = info.shape[0]\n",
    "        \n",
    "        info_arr.extend(info.T.reshape((-1, add_info_len)))\n",
    "        e = s + q.size(0)\n",
    "        all_q[s:e] = q\n",
    "        labels_ret[s:e] = labels\n",
    "        s = e  \n",
    "    \n",
    "    all_q = torch.nn.functional.normalize(all_q)\n",
    "    return all_q, labels_ret, info_arr\n",
    "\n",
    "### compute accuracy using AccuracyCalculator from pytorch-metric-learning ###\n",
    "def test(train_set, test_set, model, accuracy_calculator, batch_size):\n",
    "    model.eval()\n",
    "    train_embeddings, train_labels, _ = simpleGetAllEmbeddings(model, train_set, batch_size, ' for train')\n",
    "    test_embeddings, test_labels, _ = simpleGetAllEmbeddings(model, test_set, batch_size, ' for test')\n",
    "    train_labels = train_labels.squeeze(1)\n",
    "    test_labels = test_labels.squeeze(1)\n",
    "    accuracies = accuracy_calculator.get_accuracy(\n",
    "        test_embeddings, train_embeddings, test_labels, train_labels, False\n",
    "    )\n",
    "    print(accuracies)\n",
    "    # print(\"Test set accuracy (Precision@1) = {}\".format(accuracies[\"precision_at_1\"]))\n",
    "    return accuracies[\"precision_at_1\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:adas] *",
   "language": "python",
   "name": "conda-env-adas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
