{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgZKi4UDtiDt"
   },
   "source": [
    "# датасет должен быть или скачен или сделан с помощью ноутбука RTSD-R_MERGED\n",
    "Объединенный датасет доступен по [ссылке](https://drive.google.com/drive/folders/1jmxG2zfi-Fs3m2KrMGmjD347aYiT8YFM?usp=sharing).\n",
    "\n",
    "Положить в папку data содержимое так, чтобы были следующие пути:  \n",
    "* \\$(ROOT_DIR)/data/merged-rtsd/...\n",
    "* \\$(ROOT_DIR)/data/gt.csv\n",
    "\n",
    "> *gt_Set_NaN.csv - содержит тот же датасет, но значения колонки Set обнулено*\n",
    "\n",
    "gt - датафрейм содержащий:  \n",
    "* имена файлов - поле filename\n",
    "* класс знака - поле sign_class\n",
    "* флаг присутствия знака при работе с датасетом - IsPresent. Предполагается, что вместо удаления записи, будет устанавливатся этот флаг, включающий/не влючающий знак в выборку\n",
    "* в какой набор включен знак - поле Set $\\in$ $\\{train, valid, test\\}$\n",
    "\n",
    "~~\\# !gdown --id '1eKNfEuNQadRW1H4NOoMw5sdnyHV14ze0'\n",
    "\\# !unzip rtsd-r3.zip\n",
    "\\# !rm -rf rtsd-r3.zip~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4F3G3CsMuscG",
    "outputId": "907d3f75-5486-4b78-f2a0-9e5f62908bba"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import cv2\n",
    "import PIL\n",
    "from datetime import datetime\n",
    "\n",
    "%cd adas_system/notebooks\n",
    "\n",
    "IN_COLAB = False\n",
    "USE_COLAB_GPU = False\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    USE_COLAB_GPU = True\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    if not os.path.isfile('1_ClassifierResearch.ipynb'):\n",
    "        !git clone --branch 9_SignDetector https://github.com/lsd-maddrive/adas_system.git\n",
    "\n",
    "    !gdown --id 1-K3ee1NbMmx_0T5uwMesStmKnZO_6mWi\n",
    "    %cd adas_system/notebooks\n",
    "    !mkdir ../data/R_MERGED\n",
    "    !unzip -q -o /content/R_MERGED.zip -d ./../data/\n",
    "\n",
    "except:\n",
    "    if IN_COLAB:\n",
    "        print('[!]YOU ARE IN COLAB, BUT DIDNT MOUND A DRIVE. Model wont be synced[!]')\n",
    "\n",
    "        if not os.path.isfile('1_ClassifierResearch.ipynb'):\n",
    "            !git clone --branch 9_SignDetector https://github.com/lsd-maddrive/adas_system.git\n",
    "            !gdown --id 1-K3ee1NbMmx_0T5uwMesStmKnZO_6mWi\n",
    "            %cd adas_system/notebooks\n",
    "            !mkdir ../data/R_MERGED\n",
    "            !unzip -q -o /content/R_MERGED.zip -d ./../data/\n",
    "\n",
    "        IN_COLAB = False\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "###\n",
    "import nt_helper\n",
    "from nt_helper.helper_utils import *\n",
    "###\n",
    "\n",
    "TEXT_COLOR = 'black'\n",
    "\n",
    "# Зафиксируем состояние случайных чисел\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (17,10)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEVqwKlEvGbN"
   },
   "source": [
    "Init dirs, init main vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 991
    },
    "id": "jIdFu3ebuhn2",
    "outputId": "ee106d7b-08ed-459f-cb1a-b8dd5105312f"
   },
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    PROJECT_ROOT = pathlib.Path(os.path.join(os.curdir, os.pardir))\n",
    "else:\n",
    "    PROJECT_ROOT = pathlib.Path('..')\n",
    "    \n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "NOTEBOOKS_DIR = PROJECT_ROOT / 'notebooks'\n",
    "\n",
    "gt = pd.read_csv(DATA_DIR / 'RTDS_DATASET.csv')\n",
    "\n",
    "# FIX ME\n",
    "SIGN_TO_NUMBER = pd.read_csv(DATA_DIR / 'sign_to_number.csv', index_col=0).T.to_dict('records')[0]\n",
    "NUMBER_TO_SIGN = pd.read_csv(DATA_DIR / 'number_to_sign.csv', index_col=0).T.to_dict('records')[0]\n",
    "\n",
    "gt['filepath'] = gt['filepath'].apply(lambda x: DATA_DIR / x)\n",
    "GT_SRC_LEN = len(gt.index)\n",
    "display(gt)\n",
    "\n",
    "_, ax = plt.subplots(nrows=3, ncols=1, figsize=(21, 8))\n",
    "LABELS = ['train', 'valid', 'test']\n",
    "\n",
    "for i in range(len(LABELS)):\n",
    "    g = sns.countplot(x='SIGN', \n",
    "                      data=gt[gt['SET']==LABELS[i]],  \n",
    "                      ax=ax[i], \n",
    "                      order=sorted(gt['SIGN'].value_counts().index.tolist())\n",
    "                     )\n",
    "    ax[i].tick_params(labelrotation=90)\n",
    "    ax[i].set_title(LABELS[i])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2n04o2cOnm9r",
    "outputId": "5fc93ac9-568f-4b0e-bafa-41e80a267b3c"
   },
   "outputs": [],
   "source": [
    "TRAIN_FILES_SET = set(gt[gt['SET']== 'train']['filepath'].values)\n",
    "print(len(TRAIN_FILES_SET))\n",
    "VALID_FILES_SET = set(gt[gt['SET']== 'valid']['filepath'].values)\n",
    "print(len(VALID_FILES_SET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IVY-IRUbyk3w",
    "outputId": "ba094f36-2bf1-4aef-803f-aa7b1a89b709"
   },
   "outputs": [],
   "source": [
    "gt[gt['SET']== 'train']['SIGN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDSUN2WNnm9s"
   },
   "outputs": [],
   "source": [
    "set.intersection(TRAIN_FILES_SET, VALID_FILES_SET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5_jRi1Inm9s"
   },
   "source": [
    "Создадим загрузчик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "zBVIaE6pTQV7",
    "outputId": "31650200-64cc-402d-9fc4-c546bd7ed326"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "LE_LOCATION = DATA_DIR / 'le.npy'\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "if os.path.isfile(LE_LOCATION):\n",
    "    le.classes_ = np.load(LE_LOCATION)\n",
    "else:\n",
    "    le.fit_transform(gt['SIGN'])\n",
    "    np.save(LE_LOCATION, le.classes_)\n",
    "\n",
    "gt['ENCODED_LABELS'] = le.transform(gt['SIGN'])\n",
    "display(gt)\n",
    "\n",
    "class SignDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, set_label, img_size=64, transform=None, le=None):\n",
    "        \n",
    "        if isinstance(img_size, int):\n",
    "            img_size = (img_size, img_size)\n",
    "        \n",
    "\n",
    "        self.img_size = img_size\n",
    "        self.df = df[df['SET']==set_label]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        label = self.df.iloc[index]['ENCODED_LABELS']\n",
    "        path = self.df.iloc[index]['filepath']\n",
    "        # print(self.df.iloc[index])\n",
    "        img = cv2.imread(str(path))\n",
    "        img = cv2.resize(img, self.img_size)\n",
    "        img_tnsr = torch.Tensor.permute(torch.Tensor(img), [2, 0, 1]).div(255)\n",
    "        # print('ENCODED LABEL:', le.transform([label])[0])\n",
    "        return img_tnsr, label # random.randrange(0, 7) #0#le.transform([label])[0]\n",
    "\n",
    "img_size = 64    \n",
    "train_dataset = SignDataset(gt, 'train', img_size)\n",
    "valid_dataset = SignDataset(gt, 'valid', img_size)\n",
    "test_dataset = SignDataset(gt, 'test', img_size)\n",
    "\n",
    "MODEL_CLASSES = len(set(gt['SIGN']))\n",
    "\n",
    "if IN_COLAB or USE_COLAB_GPU:\n",
    "    batch_size = 512\n",
    "else:\n",
    "    batch_size = 1\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        shuffle=False)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "eLj8SOp_nm9t",
    "outputId": "d3497804-f8d4-4045-97f8-2c5b3b363e96"
   },
   "outputs": [],
   "source": [
    "img_t, encoded_label = train_dataset[6]\n",
    "print('encoded:', encoded_label)\n",
    "\n",
    "decoded_label = le.inverse_transform([encoded_label])[0]\n",
    "print('-le transform:', decoded_label)\n",
    "sign = NUMBER_TO_SIGN[decoded_label]\n",
    "print('-sing:', sign)\n",
    "\n",
    "img = torch.Tensor.permute(torch.Tensor(img_t), [1, 2, 0]).cpu().detach().numpy()\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IT1astLanm9u"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_epoch(model, loader, loss_op, optim, device, it_limit=99000):\n",
    "    \n",
    "    # Таким образом переводим модель в режим обучения\n",
    "    # В этом режиме вычисляются градиенты, нужные для обучения\n",
    "    torch.enable_grad()\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    accur = []\n",
    "    loss_val = []\n",
    "    pbar = tqdm(enumerate(loader),\n",
    "                total=len(loader), \n",
    "                position=0,\n",
    "                leave=False)\n",
    "    \n",
    "    for idx, (data, target) in pbar:\n",
    "        \n",
    "        if it_limit and idx > it_limit:\n",
    "            break\n",
    "            \n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        pred = model(data)\n",
    "        \n",
    "        local_acc = evaluate_batch_accuracy(pred, target).cpu()\n",
    "        accur.append(local_acc)\n",
    "        \n",
    "        # print(pred)\n",
    "        loss = loss_op(pred, target)\n",
    "        loss_val.append(loss.item())\n",
    "        \n",
    "        # Gradient descent\n",
    "        \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        \n",
    "        pbar.set_description(\"train epoch mean accuracy: %.4f last_acc: %.4f\" % (torch.mean(torch.stack(accur, dim=0)), local_acc))\n",
    "        \n",
    "    # print('train:', accur)\n",
    "    return torch.mean(torch.stack(accur, dim=0))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_batch_accuracy_old(y_pred, y_true):\n",
    "    '''\n",
    "    Оценка точности предсказания (accuracy)\n",
    "\n",
    "    y_pred:\n",
    "        батч сырых степеней уверенности, размер (N, K)\n",
    "    y_true:\n",
    "        вектор истинных значений, размер (N)\n",
    "    '''\n",
    "    y_pred = y_pred.detach().numpy()\n",
    "    y_true = y_true.detach().numpy()\n",
    "    # print(y_true)\n",
    "    # print(y_pred)\n",
    "    accuracy = 0\n",
    "    for i in range(len(y_true)):\n",
    "        index_max = max(range(len(y_pred[i, :])), key=y_pred[i].__getitem__)\n",
    "        # print(index_max)\n",
    "        if (index_max == y_true[i]):\n",
    "            accuracy += 1\n",
    "    accuracy /= len(y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def evaluate_batch_accuracy(y_pred, y_true):\n",
    "    # print('y_pred', y_pred)\n",
    "    # print('y_true', y_true)\n",
    "    # return torch.from_numpy(np.array([evaluate_batch_accuracy_old(y_pred.cpu(), y_true.cpu())]))\n",
    "\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "    # print('y_pred_softmax', y_pred_tags)\n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_true).float()\n",
    "    # print(correct_pred)\n",
    "    # s\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    # acc = torch.round(acc)\n",
    "    # print(acc.dtype)\n",
    "    return acc\n",
    "\n",
    "def valid_epoch(model, loader, device, it_limit=9999):\n",
    "    accur = []\n",
    "    \n",
    "    #torch.no_grad()\n",
    "    #model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    pbar = tqdm(enumerate(loader),\n",
    "                total=len(loader),\n",
    "                position=0,\n",
    "                leave=False)\n",
    "        \n",
    "    for idx, (imgs_batch, labels_batch) in pbar:\n",
    "        imgs_batch = imgs_batch.to(device)\n",
    "\n",
    "        if it_limit and idx > it_limit:\n",
    "            break\n",
    "            \n",
    "        labels_batch = labels_batch.to(device)\n",
    "        # print(labels_batch)\n",
    "        pred = model(imgs_batch)\n",
    "        # print('-\\n', pred)\n",
    "        local_acc = evaluate_batch_accuracy(pred, labels_batch).cpu()\n",
    "        accur.append(local_acc)\n",
    "        \n",
    "        pbar.set_description(\"valid epoch accuracy: %f\" % torch.mean(torch.stack(accur, dim=0)))\n",
    "    ## print('valid acc:', accur)\n",
    "    return torch.mean(torch.stack(accur, dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431,
     "referenced_widgets": [
      "cf5a789839554b369239f83d5dc6cae6",
      "5ea93dc83fa8446f998e97991da45601",
      "ebca474f1cfd4965b22707c0799d523a",
      "c016f835ab2d4e60b8fea866679f6bb2",
      "f7f034ff92854ef19271ce3f37dda03b",
      "347110ddffa3444db30bf934f09ed416",
      "8442282f4b6347559713d427cbccfd56",
      "ef84701c47ac4aee98ca2c328c765924",
      "5f75ef8cf2e844f288c1b2d534ad2472",
      "e1d8b76728b449ba94337f54fdd6c4e0",
      "561cc61c1be44335b9b971f5f2801066"
     ]
    },
    "id": "OboAl3B5TQV8",
    "outputId": "3d1f1f5d-2de2-49b8-dac4-c895c447660d"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'lr': 0.005,\n",
    "    'epochs': 10,\n",
    "    'it_limit': None\n",
    "}\n",
    "\n",
    "DEFAULT_MODEL_LOCATION = DATA_DIR / 'resnet18_classifier'\n",
    "\n",
    "from torchvision import models\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(512, MODEL_CLASSES)\n",
    "\n",
    "if os.path.isfile(DEFAULT_MODEL_LOCATION):\n",
    "    print('[+] Model restored from', DEFAULT_MODEL_LOCATION)\n",
    "    model.load_state_dict(torch.load(DEFAULT_MODEL_LOCATION))\n",
    "\n",
    "loss_op = nn.CrossEntropyLoss().cuda()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=config['lr'])\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "SHOULD_I_TRAIN = True\n",
    "if SHOULD_I_TRAIN:\n",
    "    pbar = tqdm(range(config['epochs']),\n",
    "            total=config['epochs'],\n",
    "            position=0,\n",
    "            leave=True)\n",
    "    \n",
    "    for epoch in pbar:\n",
    "\n",
    "        train_res = train_epoch(model, train_loader, loss_op, optim, device, config['it_limit']) # \n",
    "        print('t:', train_res)\n",
    "\n",
    "        valid_res = valid_epoch(model, valid_loader, device, config['it_limit'])\n",
    "        print('v:', valid_res)\n",
    "        \n",
    "        #test_res = valid_epoch(model, test_loader, device, config['it_limit'])\n",
    "        #print('!test:', test_res)\n",
    "        \n",
    "        now = datetime.now()\n",
    "        model_save_name = 'resnet18_classifier_{}_T_ACC{:.4f}_V_ACC{:.4f}'.format(now.strftime(\"%m.%d_%H.%M\"),\n",
    "                                                                      train_res,\n",
    "                                                                      valid_res)    \n",
    "        pbar.set_description(\"per epoch valid accuracy %f\" % valid_res)\n",
    "        \n",
    "        torch.save(model.state_dict(), DATA_DIR / model_save_name)\n",
    "        if IN_COLAB:\n",
    "            shutil.copy2(model_save_name, '/content/drive/MyDrive/')\n",
    "\n",
    "        torch.save(model.state_dict(), DATA_DIR / 'resnet18_classifier')\n",
    "        if IN_COLAB:\n",
    "            shutil.copy2(DATA_DIR / 'resnet18_classifier', '/content/gdrive/MyDrive/')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZ9HwUaanm9v"
   },
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvJody9xnm9v"
   },
   "outputs": [],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbIbJMtenm9w"
   },
   "outputs": [],
   "source": [
    "np.argmax([-3.67795, -4.46502, -4.00991, -4.30823, -1.97269, -2.26844, -3.99708, -3.03939, -3.76454, -2.84363, -2.88698, -3.26370, -3.60900, -2.46001, -2.57443, -2.67174, -4.14144, -4.07914, -2.78208, -1.07245, -1.77695,  6.58318, -0.19589, -3.07037, -2.55007, -2.18623, -0.31675, -3.51333, -2.96916, -4.83923, -3.64467])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHBZQn9hnm9w"
   },
   "outputs": [],
   "source": [
    "le.transform([42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JoYs_rKJnm9w"
   },
   "outputs": [],
   "source": [
    "le.inverse_transform([12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBh8CRiJnm9w"
   },
   "source": [
    "# TEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BcNgfHHvnm9x"
   },
   "outputs": [],
   "source": [
    "gt.iloc[70380  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "nxOZYYsUnm9x",
    "outputId": "a705e071-e068-43f2-8792-ee5d156f668b"
   },
   "outputs": [],
   "source": [
    "def getRandomFromDataset(gt: pd.DataFrame, label='test', img_size=64, id_=None):\n",
    "    \n",
    "    if isinstance(img_size, int):\n",
    "        img_size = (img_size, img_size)\n",
    "    \n",
    "    random_instance = gt[gt['SET']==label].sample(1)\n",
    "\n",
    "    if id_:\n",
    "        random_instance = gt[gt['SET']==label].iloc[[id_], :]\n",
    "    \n",
    "    # print(random_instance)\n",
    "    img_path = str(random_instance['filepath'].values[0])\n",
    "\n",
    "    sign_class = random_instance['SIGN'].values[0]\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    img_model = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_model = cv2.resize(img, img_size)\n",
    "    \n",
    "    model_input = torch.Tensor.permute(torch.Tensor(img_model), [2, 0, 1]).div(255)[None, ...]\n",
    "    \n",
    "    return model_input, img, le.transform([sign_class])[0]\n",
    "\n",
    "def translateNumber2Sign(le, encoded_label):\n",
    "    return NUMBER_TO_SIGN[le.transform([encoded_label])[0]]\n",
    "    \n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "model_input, img, encoded_label = getRandomFromDataset(new_mini_df, label='train')\n",
    "\n",
    "# print('encoded_label:', encoded_label)\n",
    "#decoded = le.inverse_transform([encoded_label])\n",
    "print('decoded_label:', le.inverse_transform([encoded_label]))\n",
    "print('sign', NUMBER_TO_SIGN[le.inverse_transform([encoded_label])[0]])\n",
    "\n",
    "preds = model(model_input.to(device)).cpu().detach().numpy()\n",
    "print(preds)\n",
    "print('argmax', np.argmax(preds))\n",
    "print('Predicted:',  NUMBER_TO_SIGN[np.argmax(preds)])\n",
    "\n",
    "fig = plt.figure(figsize=(2,2))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZTUo-5Gnm9x"
   },
   "outputs": [],
   "source": [
    "le.transform([22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w37spXJgnm9x"
   },
   "outputs": [],
   "source": [
    "gt.iloc[34290  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yea4Az14nm9y"
   },
   "outputs": [],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2kKz393Pnm9y"
   },
   "outputs": [],
   "source": [
    "le.transform([24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9--Oe82hnm9y"
   },
   "outputs": [],
   "source": [
    "SIGN_TO_NUMBER[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5pSRtu4pnm9y",
    "outputId": "d8fe512e-5821-4da4-9de8-adc08dce696a"
   },
   "outputs": [],
   "source": [
    "# print(len(test_loader))\n",
    "model.to('cpu')\n",
    "iters = 1\n",
    "\n",
    "for data, target in test_loader:\n",
    "    \n",
    "    data.to(device)\n",
    "    \n",
    "    print('target:', target)\n",
    "    t = target.cpu().detach().numpy()\n",
    "    # print('sign', NUMBER_TO_SIGN[le.inverse_transform([t[1]])[0]])\n",
    "\n",
    "    preds = model(data)# .detach().numpy()\n",
    "    \n",
    "    acc = evaluate_batch_accuracy(preds, target)\n",
    "    \n",
    "    print('accuracy', acc)\n",
    "    print(preds)\n",
    "    _, argmaxes = torch.max(preds, dim=1)\n",
    "    print(argmaxes)\n",
    "    #print('argmax', np.argmax(preds))\n",
    "    #print('Predicted:',  NUMBER_TO_SIGN[np.argmax(preds)])\n",
    "\n",
    "    #img = torch.Tensor.permute(data[0], [1, 2, 0]).detach().numpy()\n",
    "    #plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1iVIYk8Dnm9z"
   },
   "outputs": [],
   "source": [
    "a = model(img_t[None, ...])\n",
    "a.shape\n",
    "np.argmax(a.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1FkYsLnd9IWk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79DuV9tV9oz8"
   },
   "outputs": [],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VwuZo3RC2QZC"
   },
   "outputs": [],
   "source": [
    "!7z a resnets resnet18_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcB8vXrDTQV8"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "###\n",
    "import nt_helper\n",
    "from nt_helper.helper_utils import *\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "img_t, label_e = test_dataset[3]\n",
    "showTensorPicture(img_t, label=MODEL_CLASS_UNMAP[label_e])\n",
    "print(\"PREDICTED SIGN:\", MODEL_CLASS_UNMAP[label_e])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PICK RANDOM IMAGE FROM EACH SIGN CLASS for TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_ = gt[gt[\"SET\"]=='train']\n",
    "SIGN_SET = set(gt_['SIGN'])\n",
    "\n",
    "nrows, ncols = 6, 7\n",
    "fig = plt.figure()\n",
    "\n",
    "new_mini_df = pd.DataFrame(columns=gt_.columns)\n",
    "# display(new_mini_df)\n",
    "\n",
    "for idx, sign_class in enumerate(SIGN_SET):\n",
    "    \n",
    "    instance = gt_[gt_['SIGN'] == sign_class].sample(1)\n",
    "    # display(instance)\n",
    "    new_mini_df.loc[len(new_mini_df)] = instance.iloc[0]\n",
    "    # print(new_mini_df)\n",
    "    path = str(instance['filepath'].values[0])\n",
    "    sign = instance['SIGN'].values[0]\n",
    "    img = cv2.imread(path)\n",
    "    ax = fig.add_subplot(nrows, ncols, idx+1)\n",
    "    \n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), aspect=1)\n",
    "    ax.set_title(str(le.transform([sign_class])[0]) + ':' + str(sign_class) + ':' + str(NUMBER_TO_SIGN[sign_class]))\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(new_mini_df[::4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, set_label, img_size=64, transform=None, le=None):\n",
    "        \n",
    "        if isinstance(img_size, int):\n",
    "            img_size = (img_size, img_size)\n",
    "        \n",
    "\n",
    "        self.img_size = img_size\n",
    "        self.df = df[df['SET']==set_label]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        label = self.df.iloc[index]['ENCODED_LABELS']\n",
    "        path = self.df.iloc[index]['filepath']\n",
    "        # print(self.df.iloc[index])\n",
    "        img = cv2.imread(str(path))\n",
    "        img = cv2.resize(img, self.img_size)\n",
    "        img_tnsr = torch.Tensor.permute(torch.Tensor(img), [2, 0, 1]).div(255)\n",
    "        # print('ENCODED LABEL:', le.transform([label])[0])\n",
    "        return img_tnsr, torch.tensor(label, dtype=torch.long) # random.randrange(0, 7) #0#le.transform([label])[0]\n",
    "\n",
    "small_test_loader = SignDataset(new_mini_df, 'train', 64)\n",
    "print('LOADER SIZE =', len(small_test_loader))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        small_test_loader,\n",
    "        batch_size=1,\n",
    "        pin_memory=True,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model, loader, loss_op, optim, device, it_limit=99000):\n",
    "\n",
    "    torch.enable_grad()\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    accur = []\n",
    "    loss_val = []\n",
    "    pbar = tqdm(enumerate(loader),\n",
    "                total=len(loader), \n",
    "                position=0,\n",
    "                leave=False)\n",
    "    \n",
    "    for idx, (data, target) in pbar:\n",
    "        \n",
    "        if it_limit and idx > it_limit:\n",
    "            break\n",
    "            \n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        pred = model(data)\n",
    "        \n",
    "        local_acc = evaluate_batch_accuracy(pred, target)# .cpu()\n",
    "        accur.append(local_acc)\n",
    "        \n",
    "        loss = loss_op(pred, target)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        loss_val.append(loss.item())\n",
    "        \n",
    "        pbar.set_description(\"train epoch mean accuracy: %.4f last_acc: %.4f\" % (np.mean(accur), local_acc))\n",
    "        \n",
    "    return np.mean(accur)\n",
    "\n",
    "def evaluate_batch_accuracy(y_pred, y_true):\n",
    "    y_pred = y_pred.cpu().detach().numpy()\n",
    "    y_true = y_true.cpu().detach().numpy()\n",
    "    accuracy = 0\n",
    "    for i in range(len(y_true)):\n",
    "        index_max = max(range(len(y_pred[i, :])), key=y_pred[i].__getitem__)\n",
    "        # print(index_max)\n",
    "        if (index_max == y_true[i]):\n",
    "            accuracy += 1\n",
    "    accuracy /= len(y_pred)\n",
    "    # print('y_pred:', torch.Tensor(y_pred))\n",
    "    # print('y_true:', torch.Tensor(y_true))\n",
    "    # print('accura:', accuracy)\n",
    "    # input('PK')\n",
    "    return accuracy\n",
    "\n",
    "    return acc\n",
    "\n",
    "def valid_epoch(model, loader, device, it_limit=9999):\n",
    "    accur = []\n",
    "    #torch.no_grad()\n",
    "    #model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    pbar = tqdm(enumerate(loader),\n",
    "                total=len(loader),\n",
    "                position=0,\n",
    "                leave=False)\n",
    "        \n",
    "    for idx, (imgs_batch, labels_batch) in pbar:\n",
    "        imgs_batch = imgs_batch.to(device)\n",
    "            \n",
    "        labels_batch = labels_batch.to(device)\n",
    "\n",
    "        pred = model(imgs_batch)\n",
    "        # print('pred', pred)\n",
    "        # print('pred', labels_batch)\n",
    "        \n",
    "        local_acc = evaluate_batch_accuracy(pred, labels_batch)# .cpu()\n",
    "        # print('acc:', local_acc)\n",
    "        # input(\"Press Enter to continue...\")\n",
    "        accur.append(local_acc)\n",
    "        \n",
    "        pbar.set_description(\"valid epoch accuracy: %f\" % local_acc)\n",
    "\n",
    "    return np.mean(accur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'lr': 0.1,\n",
    "    'epochs': 9,\n",
    "    'it_limit': None\n",
    "}\n",
    "\n",
    "DEFAULT_MODEL_LOCATION = DATA_DIR / 'resnet18_classifier'\n",
    "\n",
    "from torchvision import models\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(512, 31)\n",
    "\n",
    "if os.path.isfile(DEFAULT_MODEL_LOCATION):\n",
    "    print('[+] Model restored from', DEFAULT_MODEL_LOCATION)\n",
    "    # model.load_state_dict(torch.load(DEFAULT_MODEL_LOCATION))\n",
    "    \n",
    "\n",
    "loss_op = nn.CrossEntropyLoss().cuda()\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=config['lr'])\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "SHOULD_I_TRAIN = True\n",
    "if SHOULD_I_TRAIN:\n",
    "    pbar = tqdm(range(config['epochs']),\n",
    "                total=config['epochs'],\n",
    "                leave=True)\n",
    "    \n",
    "    for epoch in pbar:\n",
    "\n",
    "        train_res = train_epoch(model, train_loader, loss_op, optim, device, config['it_limit']) # \n",
    "        print('train accuracy:', train_res)\n",
    "\n",
    "        valid_res = valid_epoch(model, train_loader, device, config['it_limit'])\n",
    "        print('valid accuracy:', valid_res)\n",
    "        \n",
    "        #test_res = valid_epoch(model, test_loader, device, config['it_limit'])\n",
    "        #print('!test:', test_res)\n",
    "        \n",
    "        now = datetime.now()\n",
    "        model_save_name = 'resnet18_classifier_{}_T_ACC{:.4f}_V_ACC{:.4f}'.format(now.strftime(\"%m.%d_%H.%M\"),\n",
    "                                                                      train_res,\n",
    "                                                                      valid_res)    \n",
    "        pbar.set_description(\"per epoch valid accuracy %f\" % valid_res)\n",
    "        \n",
    "        torch.save(model.state_dict(), DATA_DIR / model_save_name)\n",
    "        print('MODEL CHECK CREATED')\n",
    "        if IN_COLAB:\n",
    "            shutil.copy2(model_save_name, '/content/drive/MyDrive/')\n",
    "\n",
    "        torch.save(model.state_dict(), DATA_DIR / 'resnet18_classifier')\n",
    "        if IN_COLAB:\n",
    "            shutil.copy2(DATA_DIR / 'resnet18_classifier', '/content/gdrive/MyDrive/')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_ = gt[gt[\"SET\"]=='train']\n",
    "SIGN_SET = set(gt_['SIGN'])\n",
    "\n",
    "nrows, ncols = 6, 7\n",
    "fig = plt.figure()\n",
    "\n",
    "model.to('cpu')\n",
    "\n",
    "for idx, (img, encoded_label) in enumerate(small_test_loader):\n",
    "    \n",
    "    pred = model(img[None, ...])\n",
    "    \n",
    "    argmax = np.argmax(pred.detach().numpy())\n",
    "    model_pred_decoded = le.inverse_transform([argmax])[0]\n",
    "    model_pred_sign = NUMBER_TO_SIGN[model_pred_decoded]\n",
    "    # make img from tensor\n",
    "    img = torch.Tensor.permute(img, [1, 2, 0]).numpy()\n",
    "    \n",
    "    # get decoded_label\n",
    "    decoded_label = le.inverse_transform([encoded_label])[0]\n",
    "    \n",
    "    # translate decoded to sign\n",
    "    sign = NUMBER_TO_SIGN[decoded_label]\n",
    "    \n",
    "    ax = fig.add_subplot(nrows, ncols, idx+1)\n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), aspect=1)\n",
    "    ax.set_title('FACT:' + str(sign) + '; PRED:' + str(model_pred_sign))\n",
    "    \n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1_ClassifierResearch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
