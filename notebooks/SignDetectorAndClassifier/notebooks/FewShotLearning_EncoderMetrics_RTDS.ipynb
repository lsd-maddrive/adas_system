{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b91b328",
   "metadata": {},
   "source": [
    "### Метрики энкодера на основе Resnet18.  \n",
    "#### Выходной слой: *nn.Linear(in_features=512, out_features=1024, bias=True)*\n",
    "\n",
    "### Визуализация в 3 ГК помимо того что не дает колличественных оценок точности энкодера, так и несет в себе в лучшем случае около 40% информации от выходного вектора длинной 1024. \n",
    "\n",
    "###  Необходимо ознакомится с метриками и оценками модели энкодера. исп.:\n",
    "* kMeans\n",
    "* OneClass SVM\n",
    "* Gaussian Mixture\n",
    "\n",
    "### Конечная цель: оценка целесообразности применения энкодера в рамках *данной* задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246547b7",
   "metadata": {},
   "source": [
    "Что откуда качать:\n",
    "\n",
    "* https://drive.google.com/file/d/1-oIPyg3uFT1n--MXyR4Uzx95YqR3NsNT/view?usp=sharing - дополнительные знаки - не референсные. Часть из них - вырезка из видосов, часть - собранно ручками. Разместить в папке *data/additional_sign/*\n",
    "* https://drive.google.com/file/d/1-rTwhmdUdcuPMYz8BiPQV3fiWCSJjE20/view?usp=sharing - *last_encoder_1024_98* - веса энкодера. Разместить в папке с ноутбуком.\n",
    "* https://drive.google.com/file/d/1-K3ee1NbMmx_0T5uwMesStmKnZO_6mWi/view?usp=sharing - rtds с csv, содержащей инфу. Разместить в папке *data*: data/R_MERGED/.. и data/RTDS_DATASET.csv.\n",
    "* https://drive.google.com/file/d/1-l3VvU-WtSoXbW_AaTFUreVD-tgXV8Q0/view?usp=sharing - стоковые знаки. Используются как референс, то есть объеденяются с rtds с пометкой 'train'. Разместить так: data/STOCK_SIGNS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import cv2\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "TEXT_COLOR = 'black'\n",
    "# Зафиксируем состояние случайных чисел\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (17,10)\n",
    "\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f40ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = pathlib.Path('..').resolve()\n",
    "    \n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "SRC_PATH = str(PROJECT_ROOT / 'src')\n",
    "\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.append(SRC_PATH)\n",
    "    \n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e7384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet\n",
    "# encoder = resnet.resnet18(pretrained=True)\n",
    "# encoder.fc = nn.Linear(in_features=512, out_features=512, bias=True)\n",
    "encoder = resnet.resnet50(pretrained=True)\n",
    "encoder.fc = nn.Linear(in_features=2048, out_features=512, bias=False)\n",
    "state_dict = torch.load('last_encoder')['model']\n",
    "r = encoder.load_state_dict(state_dict)\n",
    "encoder.eval()  \n",
    "encoder.to(device)\n",
    "assert r, 'Cannot load state dict'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d951445",
   "metadata": {},
   "source": [
    "### Этап 1.1. Берем RTDS, из него берем *train* как *baseline*. Заменяем *valid* на *test*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33139cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PREFIX = DATA_DIR / 'ENCODER_DATASET'\n",
    "RTDS_DF = pd.read_csv(DATASET_PREFIX / 'WIDE_DATASET_4_ENCODER.csv')\n",
    "RTDS_DF['filepath'] = RTDS_DF['filepath'].apply(lambda x: str(DATASET_PREFIX / x))\n",
    "RTDS_DF.drop_duplicates(subset=['filepath'], inplace=True)\n",
    "RTDS_DF['set'] = RTDS_DF['set'].apply(lambda x: 'test' if x == 'valid' else x)\n",
    "\n",
    "TARGET_SIGNS = [\n",
    "        '1.1', '1.6', '1.8', '1.22', '1.31', '1.33', \n",
    "        '2.1', '2.2', '2.3', '2.4', '2.5', \n",
    "        '3.1', '3.18', '3.20', '3.21', '3.22', '3.23', '3.24',\n",
    "        '3.25', '3.27', '3.28', '3.31', \n",
    "        '4.1.1', '4.3', \n",
    "        '5.5', '5.6', '5.16', \n",
    "        '5.19.1', '5.20', \n",
    "        '6.3.2', '6.4', \n",
    "        '7.3', '7.4'\n",
    "    ]\n",
    "\n",
    "RTDS_DF = RTDS_DF[RTDS_DF['sign'].isin(TARGET_SIGNS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa427d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(RTDS_DF['sign'])))\n",
    "print(len(set(RTDS_DF['encoded'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac7c929",
   "metadata": {},
   "source": [
    "### *train* как референс, *valid* - query для валидации.\n",
    "### Этап 1.2. Формируем DataFrame отсутствущих знаков в RTDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c19ae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "included_signs = sorted(set(RTDS_DF.sign))\n",
    "print('Included signs in ENCODER_DATASET:', included_signs)\n",
    "not_included_signs = sorted(set(TARGET_SIGNS) - set(RTDS_DF.sign))\n",
    "print('Not included in ENCODER_DATASET:', not_included_signs)\n",
    "\n",
    "print('Getting aditional sings...')\n",
    "additional_DF = pd.DataFrame(columns=RTDS_DF.columns)\n",
    "\n",
    "encode_offset = max(set(RTDS_DF['encoded'])) + 1\n",
    "files = os.listdir(DATA_DIR / 'additional_sign')\n",
    "\n",
    "skipped_signs = []\n",
    "\n",
    "row_list = []\n",
    "for file in files:\n",
    "    sign = file.split('_')[0]\n",
    "     \n",
    "    if sign.rsplit('.', 1)[0] == '3.25':\n",
    "        sign = '3.25'\n",
    "        \n",
    "    if sign.rsplit('.', 1)[0] == '3.24':\n",
    "        sign = '3.24'         \n",
    "\n",
    "    if sign in included_signs:\n",
    "        skipped_signs.append(sign)\n",
    "        continue\n",
    "        \n",
    "    row = {'filepath': str(DATA_DIR / 'additional_sign' / file), \n",
    "           'sign': sign, \n",
    "           'set': 'test',\n",
    "           'encoded': None\n",
    "          }\n",
    "\n",
    "    row_list.append(row)\n",
    "\n",
    "print('Skipped signs:', skipped_signs)\n",
    "additional_DF = pd.DataFrame(row_list, columns=RTDS_DF.columns)\n",
    "le.fit(list(set(additional_DF.sign).union(set(RTDS_DF.sign))))\n",
    "\n",
    "print('Including part of additional_DF for:', sorted(set(additional_DF.sign)), 'sign.')\n",
    "additional_DF = additional_DF[~additional_DF['sign'].isin(RTDS_DF['sign'])]\n",
    "\n",
    "RTDS_DF = pd.concat([RTDS_DF, additional_DF], ignore_index=True)\n",
    "RTDS_DF['encoded'] = le.transform(RTDS_DF['sign'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb015b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_subset = RTDS_DF[RTDS_DF['set'] == 'test']\n",
    "# display(valid_subset)\n",
    "sum(valid_subset['sign'] == '1.8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db48ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('So we got', len(set(RTDS_DF['sign'])), 'signs. Assume == 33')\n",
    "LABEL_DICT = dict(zip(RTDS_DF.sign, RTDS_DF.encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4d31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_from_train_for_signs = sorted(set(RTDS_DF.loc[RTDS_DF['set'] == 'train', 'sign']))\n",
    "print('We will get centroids from TRAIN for', centroid_from_train_for_signs)\n",
    "centroid_from_stock_for_signs = sorted(set(TARGET_SIGNS) - set(centroid_from_train_for_signs))\n",
    "print('We should get centroids from STOCK signs for', centroid_from_stock_for_signs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03085880",
   "metadata": {},
   "source": [
    "### Этап 2. Формируем для отсутствующих~=**ДЛЯ ВСЕХ** знаков baseline из образцовых знаков с википедии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2392a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOCK_SIGNS_CSV_LOCATION = DATA_DIR / 'STOCK_SIGNS/STOCK_SIGNS.csv'\n",
    "STOCK_SIGNS_DATAFRAME = pd.read_csv(STOCK_SIGNS_CSV_LOCATION)\n",
    "STOCK_SIGNS_DATAFRAME.rename({'SIGN': 'sign'}, axis='columns', inplace=True)\n",
    "\n",
    "STOCK_SIGNS_DATAFRAME['filepath'] = STOCK_SIGNS_DATAFRAME['filepath'].apply(lambda x: str(x).replace('\\\\', '/'))\n",
    "STOCK_SIGNS_DATAFRAME.loc[STOCK_SIGNS_DATAFRAME['sign'] == '5.19.2', 'sign'] = '5.19.1'\n",
    "\n",
    "STOCK_SIGNS_DATAFRAME['sign'] = STOCK_SIGNS_DATAFRAME['sign'].apply(\n",
    "        lambda x: '3.25' if x.rsplit('.', 1)[0] == '3.25' else x)\n",
    "\n",
    "## FIXUP для проблем описанных ниже\n",
    "STOCK_SIGNS_DATAFRAME['sign'] = STOCK_SIGNS_DATAFRAME['sign'].apply(\n",
    "        lambda x: '3.18' if x.rsplit('.', 1)[0] == '3.18' else x)\n",
    "\n",
    "STOCK_SIGNS_DATAFRAME['sign'] = STOCK_SIGNS_DATAFRAME['sign'].apply(\n",
    "        lambda x: '2.3' if x.rsplit('.', 1)[0] == '2.3' else x)\n",
    "\n",
    "STOCK_SIGNS_DATAFRAME['sign'] = STOCK_SIGNS_DATAFRAME['sign'].apply(\n",
    "        lambda x: '3.24' if x.rsplit('.', 1)[0] == '3.24' else x)\n",
    "\n",
    "STOCK_SIGNS_DATAFRAME['filepath'] = STOCK_SIGNS_DATAFRAME['filepath'].apply(lambda x: str(DATA_DIR / x))\n",
    "STOCK_SIGNS_DATAFRAME['encoded'] = [LABEL_DICT[i] for i in STOCK_SIGNS_DATAFRAME['sign']]\n",
    "\n",
    "STOCK_SIGNS_DATAFRAME['set'] = 'train'\n",
    "\n",
    "print('Leave only signs from', centroid_from_stock_for_signs)\n",
    "STOCK_SIGNS_DATAFRAME = STOCK_SIGNS_DATAFRAME[STOCK_SIGNS_DATAFRAME['sign'].isin(\n",
    "    centroid_from_stock_for_signs)]\n",
    "\n",
    "display(STOCK_SIGNS_DATAFRAME)\n",
    "\n",
    "RTDS_DF = pd.concat([RTDS_DF, STOCK_SIGNS_DATAFRAME], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738422ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_MERGED = RTDS_DF\n",
    "R_MERGED.loc[((R_MERGED['set']=='test') | (R_MERGED['set']=='valid'))  & (R_MERGED['sign']=='5.19.1')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264898f7",
   "metadata": {},
   "source": [
    "## БЕДА, RTDS объеденяет все 3.18 в одну группу. Еще проблемные: 2.3.1. Ну пофиг блин) Смотрим на ошибки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cdfb44",
   "metadata": {},
   "source": [
    "### Baseline готов, тестовый датасет готов. Че хотим? Хотим получить какие-нибудь метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2692320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from albumentations.augmentations.transforms import PadIfNeeded\n",
    "from albumentations.augmentations.geometric.resize import LongestMaxSize\n",
    "\n",
    "\n",
    "img_size = 32\n",
    "\n",
    "minimal_transform = A.Compose(\n",
    "        [\n",
    "        LongestMaxSize(\n",
    "            img_size,\n",
    "            interpolation=cv2.INTER_AREA  \n",
    "        ),\n",
    "        PadIfNeeded(\n",
    "            img_size, \n",
    "            img_size, \n",
    "            border_mode=cv2.BORDER_CONSTANT, \n",
    "            value=0\n",
    "        ),\n",
    "        ToTensorV2(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "class SignDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, set_label=None, hyp=None, transform=None, alpha_color=None):\n",
    "        self.transform = transform\n",
    "        self.df = df[df['set'] == set_label] if set_label else df        \n",
    "        self.hyp = hyp\n",
    "        self.alpha_color = alpha_color\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        label = int(row['encoded'])\n",
    "        path = str(row['filepath'])\n",
    "        sign = str(row['sign'])\n",
    "        img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "        # check does it contains transparent channel\n",
    "        if img.shape[2] == 4:\n",
    "            # randomize transparent\n",
    "            trans_mask = img[:, :, 3] == 0\n",
    "            img[trans_mask] = [self.alpha_color if self.alpha_color else random.randrange(0, 256),\n",
    "                               self.alpha_color if self.alpha_color else random.randrange(0, 256),\n",
    "                               self.alpha_color if self.alpha_color else random.randrange(0, 256),\n",
    "                               255]\n",
    "\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "        # /randomize transparent\n",
    "\n",
    "        # augment \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        # /augment\n",
    "        \n",
    "        img = img / 255\n",
    "        return img, label, (path, sign)\n",
    "\n",
    "train_dataset = SignDataset(RTDS_DF, \n",
    "                            set_label='train', \n",
    "                            transform=minimal_transform, \n",
    "                            hyp=None,\n",
    "                            alpha_color=144\n",
    "                           )\n",
    "\n",
    "valid_dataset = SignDataset(RTDS_DF, \n",
    "                            set_label='test',  \n",
    "                            transform=minimal_transform, \n",
    "                            hyp=None,\n",
    "                            alpha_color=144\n",
    "                           )\n",
    "\n",
    "nrows, ncols = 70, 6\n",
    "fig = plt.figure(figsize = (16,200))\n",
    "\n",
    "for idx, (img, encoded_label, (path, sign)) in enumerate(valid_dataset):\n",
    "    if idx + 1 > 0:\n",
    "        break\n",
    "    img = torch.Tensor.permute(img, [1, 2, 0]).numpy() \n",
    "    ax = fig.add_subplot(nrows, ncols, idx+1)\n",
    "        \n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), aspect=1)\n",
    "    ax.set_title(str(sign), fontsize=15)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7dd09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def getDataLoaderFromDataset(dataset, batch_size=8, shuffle=False, drop_last=False):\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def simpleGetAllEmbeddings(model, dataset, batch_size, dsc=''):\n",
    "    dataloader = getDataLoaderFromDataset(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    s, e = 0, 0\n",
    "    pbar = tqdm(\n",
    "        enumerate(dataloader),\n",
    "        total=len(dataloader),\n",
    "        position=0,\n",
    "        leave=False,\n",
    "        desc='Getting all embeddings...' + dsc)\n",
    "    \n",
    "    info_arr = []\n",
    "    add_info_len = None\n",
    "\n",
    "    for idx, (data, labels, info) in pbar:\n",
    "        data = data.to(device)\n",
    "        q = model(data)\n",
    "\n",
    "        if labels.dim() == 1:\n",
    "            labels = labels.unsqueeze(1)\n",
    "        if idx == 0:\n",
    "            labels_ret = torch.zeros(\n",
    "                len(dataloader.dataset),\n",
    "                labels.size(1),\n",
    "                device=device,\n",
    "                dtype=labels.dtype,\n",
    "            )\n",
    "            all_q = torch.zeros(\n",
    "                len(dataloader.dataset),\n",
    "                q.size(1),\n",
    "                device=device,\n",
    "                dtype=q.dtype,\n",
    "            )\n",
    "\n",
    "        info = np.array(info)\n",
    "        if add_info_len == None:\n",
    "            add_info_len = info.shape[0]\n",
    "\n",
    "        info_arr.extend(info.T.reshape((-1, add_info_len)))\n",
    "        e = s + q.size(0)\n",
    "        all_q[s:e] = q\n",
    "        labels_ret[s:e] = labels\n",
    "        s = e\n",
    "\n",
    "    labels_ret = labels_ret.squeeze(1)\n",
    "    all_q = torch.nn.functional.normalize(all_q)\n",
    "    return all_q, labels_ret, info_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc729ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1800\n",
    "num_workers = 16\n",
    "\n",
    "encoder.eval()\n",
    "train_embeddings, train_labels, train_additional_info = simpleGetAllEmbeddings(\n",
    "    encoder, train_dataset, batch_size, ' for train'\n",
    ")\n",
    "\n",
    "test_embeddings, test_labels, test_additional_info = simpleGetAllEmbeddings(\n",
    "    encoder, valid_dataset, batch_size, ' for test'\n",
    ")\n",
    "\n",
    "print('Test labels:', test_labels.unique(), 'len:', len(test_labels.unique()))\n",
    "print('Train labels:', train_labels.unique(), 'len:', len(train_labels.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cb3518",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(RTDS_DF[RTDS_DF['set']=='train']['encoded'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c5fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(RTDS_DF[RTDS_DF['set']=='test']['sign'])))\n",
    "print(len(set(RTDS_DF[RTDS_DF['set']=='train']['sign'])))\n",
    "\n",
    "print(len(set(RTDS_DF[RTDS_DF['set'] == 'test']['encoded'])))\n",
    "print(len(set(RTDS_DF[RTDS_DF['set'] == 'train']['encoded'])))\n",
    "\n",
    "print(len(set(RTDS_DF[RTDS_DF['set']=='test'].index)))\n",
    "print(len(RTDS_DF[RTDS_DF['set']=='train'].index))\n",
    "\n",
    "print(len(set(RTDS_DF[RTDS_DF['set']=='test'].index)))\n",
    "print(len(RTDS_DF[RTDS_DF['set']=='train'].index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a6e5b0",
   "metadata": {},
   "source": [
    "### Выше все ок, тестовый набор содержит тест+валид, который сформирован ноутбуков *RTSD-R_MERGED.ipynb*. В валид попало много знаков пешеходного перехода, т.к. их количество значительно превосходило остальные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22987833",
   "metadata": {},
   "source": [
    "## Get Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d1cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "INVERSED_LABEL_DICT = {v: k for k, v in LABEL_DICT.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e36b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = train_labels.cpu().numpy()\n",
    "labels_set = list(set(labels_list))\n",
    "\n",
    "embeddingsListForCentroids = train_embeddings.cpu().numpy()\n",
    "centroidLocationDict = {}\n",
    "\n",
    "p = tqdm(labels_set)\n",
    "for label in p:\n",
    "    p.set_description(\n",
    "        f'Current label: {label} [{INVERSED_LABEL_DICT[label]}]'\n",
    "    )\n",
    "    mask = labels_list == label\n",
    "    \n",
    "    currentLabelEmbeddingsForCentroids = embeddingsListForCentroids[mask]\n",
    "    zipped = list(zip(*currentLabelEmbeddingsForCentroids))\n",
    "    \n",
    "    singleCoord = []\n",
    "    for coord in zipped:\n",
    "        coord = sum(coord) / len(coord)\n",
    "        singleCoord.append(coord)\n",
    "        # print(coord)\n",
    "        \n",
    "    centroidLocationDict[label] = singleCoord\n",
    "\n",
    "print('Getting centroids done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adaf66d",
   "metadata": {},
   "source": [
    "### lets construct plot DataFrame\n",
    "Фундаментальный вопрос. fit PCA надо делать на train или на train+test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f1cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "dim3 = True\n",
    "\n",
    "print('Constructing dataframe for plotting.')\n",
    "\n",
    "coords = ['x', 'y'] + (['z'] if dim3 else [])\n",
    "columns = [*coords, 'type', 'size', 'sign', 'filepath', 'color', 'marker']\n",
    "\n",
    "plot_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "reducer = PCA(\n",
    "    n_components=3 if dim3 else 2, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "train_size = 2\n",
    "train_type = 'train'\n",
    "\n",
    "test_size = 2\n",
    "test_type = 'test'\n",
    "\n",
    "centroid_size = 10\n",
    "centroid_type = 'centroid'\n",
    "\n",
    "\n",
    "## FIT REDUCER\n",
    "train_embeddings_ = reducer.fit_transform(train_embeddings.cpu().numpy())\n",
    "\n",
    "from itertools import cycle\n",
    "import plotly.express as px\n",
    "palette = cycle(\n",
    "        [*px.colors.qualitative.Dark24, \n",
    "         *px.colors.qualitative.Alphabet, \n",
    "         *px.colors.qualitative.Light24]\n",
    "    )\n",
    "colorDict = {}\n",
    "\n",
    "listOfRows = []\n",
    "## CENTROIDS\n",
    "for k, v in tqdm(centroidLocationDict.items()):\n",
    "    coords = reducer.transform(np.array(v).reshape(1, -1)).flatten()\n",
    "    # print([*coords, centroid_type, centroid_size, INVERSED_LABEL_DICT[k]])\n",
    "    # print('Getting any for', INVERSED_LABEL_DICT[k])\n",
    "    path = RTDS_DF[RTDS_DF['sign'] == INVERSED_LABEL_DICT[k]]['filepath'].values[0]\n",
    "        \n",
    "    colorDict[INVERSED_LABEL_DICT[k]] = next(palette)\n",
    "    \n",
    "    row = pd.Series(\n",
    "        [*coords, centroid_type, centroid_size, INVERSED_LABEL_DICT[k], path, \n",
    "         colorDict[INVERSED_LABEL_DICT[k]], 'diamond'],\n",
    "        index=plot_df.columns,\n",
    "    )\n",
    "    listOfRows.append(row)\n",
    "    \n",
    "## TRAIN\n",
    "for idx, (coord, label, info) in tqdm(\n",
    "    enumerate(\n",
    "        zip(train_embeddings_, train_labels, train_additional_info)),\n",
    "    total=len(train_labels)\n",
    "):\n",
    "    label = label.cpu().numpy()\n",
    "    \n",
    "    color = colorDict[INVERSED_LABEL_DICT[int(label)]]\n",
    "    \n",
    "    row = pd.Series(\n",
    "        [*coord, train_type, train_size, INVERSED_LABEL_DICT[int(label)], info[0], \n",
    "         colorDict[INVERSED_LABEL_DICT[k]], 'circle'],\n",
    "        index=plot_df.columns,\n",
    "    )\n",
    "    listOfRows.append(row)\n",
    "\n",
    "\n",
    "## TEST\n",
    "test_embeddings_ = reducer.transform(test_embeddings.cpu().numpy())\n",
    "\n",
    "for idx, (coord, label, info) in tqdm(\n",
    "    enumerate(\n",
    "        zip(test_embeddings_, test_labels, test_additional_info)),\n",
    "    total=len(test_labels)\n",
    "):\n",
    "    label = label.cpu().numpy()\n",
    "    \n",
    "    row = pd.Series(\n",
    "        [*coord, test_type, test_size, info[1], info[0], \n",
    "        colorDict[INVERSED_LABEL_DICT[k]], 'circle'],\n",
    "        index=plot_df.columns,\n",
    "    )\n",
    "    \n",
    "    listOfRows.append(row)\n",
    "\n",
    "plot_df = pd.concat([plot_df, pd.DataFrame(listOfRows)], axis=0)\n",
    "plot_df['x'] = plot_df['x'].astype(float)\n",
    "plot_df['y'] = plot_df['y'].astype(float)\n",
    "if 'z' in plot_df.columns:\n",
    "    plot_df['z'] = plot_df['z'].astype(float)\n",
    "    \n",
    "plot_df['size'] = plot_df['size'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c582d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(listOfRows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd15a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(centroidLocationDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adba312",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(reducer.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dd6372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from itertools import cycle\n",
    "\n",
    "PLOT_CENTROID_AND_TEST_ONLY = True\n",
    "PLOT_LIMIT_FRAC = 0.6\n",
    "\n",
    "if PLOT_CENTROID_AND_TEST_ONLY:\n",
    "    plot_df_ = plot_df[plot_df['type'] != 'train'][::-1]\n",
    "else:\n",
    "    plot_df_ = plot_df[::-1]\n",
    "\n",
    "if PLOT_LIMIT_FRAC:\n",
    "    plot_df_ = plot_df_.groupby(['sign', 'type']).sample(frac=PLOT_LIMIT_FRAC)\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc, html, Input, Output, no_update\n",
    "import base64\n",
    "\n",
    "app = JupyterDash(__name__)\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"graph-tooltip-5\", \"show\"),\n",
    "    Output(\"graph-tooltip-5\", \"bbox\"),\n",
    "    Output(\"graph-tooltip-5\", \"children\"),\n",
    "    Input(\"graph-5\", \"hoverData\"),\n",
    ")\n",
    "def display_hover(hoverData):\n",
    "\n",
    "    if hoverData is None:\n",
    "        return False, no_update, no_update\n",
    "\n",
    "    hover_data = hoverData[\"points\"][0]\n",
    "    bbox = hover_data[\"bbox\"]\n",
    "    num = hover_data[\"pointNumber\"]\n",
    "    data = hover_data['customdata']\n",
    "    sign = data[0]\n",
    "    rel_img_path = data[1]\n",
    "    \n",
    "    try:\n",
    "        with open(rel_img_path, 'rb') as f:\n",
    "            image = f.read()\n",
    "    except FileNotFoundError as exc_obj:\n",
    "        print(data)\n",
    "        return False, no_update, no_update\n",
    "    \n",
    "    b64sed_image = 'data:image/png;base64,' + base64.b64encode(image).decode('utf-8')\n",
    "\n",
    "    children = [\n",
    "        html.Div([\n",
    "            html.Img(\n",
    "                src=b64sed_image,\n",
    "                style={\"width\": \"70px\", 'display': 'block', 'margin': '0 auto'},\n",
    "            ),\n",
    "            html.P(sign, style={\"fontSize\": 14, 'text-align':'center'}),\n",
    "            html.P(rel_img_path, style={\"fontSize\": 10}),\n",
    "        ])\n",
    "    ]\n",
    "    return True, bbox, children\n",
    "\n",
    "dim3 = True\n",
    "plot_args = {\n",
    "    'x': 'x',\n",
    "    'y': 'y',\n",
    "    'color': 'sign',\n",
    "    'size': 'size',\n",
    "    'opacity': 0.2 if dim3 else 0.5,\n",
    "    'symbol': 'type',\n",
    "    'hover_name': 'sign',\n",
    "    'hover_data': ['sign', 'filepath', 'type'],\n",
    "    'animation_group': 'type',\n",
    "    'color_discrete_sequence': [\n",
    "        *px.colors.qualitative.Dark24, \n",
    "        *px.colors.qualitative.Alphabet, \n",
    "        *px.colors.qualitative.Light24\n",
    "    ]\n",
    "}\n",
    "\n",
    "if dim3:\n",
    "    plotFcn = px.scatter_3d\n",
    "    plot_args.update({'z': 'z'})\n",
    "else:\n",
    "    plotFcn = px.scatter\n",
    "      \n",
    "fig = plotFcn(\n",
    "        plot_df_,\n",
    "        **plot_args,\n",
    "\n",
    "    )\n",
    "\n",
    "fig.update_traces(\n",
    "        hoverinfo=\"none\", \n",
    "        hovertemplate=None,\n",
    "        marker=dict(\n",
    "            line=dict(\n",
    "                width=0)\n",
    "           )\n",
    ")\n",
    "    \n",
    "fig.update_layout(\n",
    "        width=950,\n",
    "        height=950)\n",
    "\n",
    "## FIX Z-ORDER\n",
    "if True:\n",
    "    sampleData = list(fig.data)\n",
    "    centroidsList = []\n",
    "    for t in list(sampleData[:]):\n",
    "        if (t.ids[0] == 'centroid'):\n",
    "            temp_t = t\n",
    "            sampleData.remove(t)\n",
    "            temp_t['marker']['opacity'] = 1\n",
    "            temp_t['text'] = temp_t['customdata'][0][0]\n",
    "            temp_t['textposition'] = 'top center'\n",
    "            temp_t['mode'] = 'markers+text'\n",
    "            temp_t['marker']['line']['width'] = 40 if dim3 else 2\n",
    "            temp_t['marker']['line']['color'] = 'rgb(0, 0, 0)'\n",
    "            centroidsList.append(temp_t)\n",
    "            \n",
    "    fig.data = tuple(sampleData + centroidsList)\n",
    "    \n",
    "fig.update_layout(font=dict(size=18))\n",
    "\n",
    "app.layout = html.Div(\n",
    "            className=\"container\",\n",
    "            children=[\n",
    "                dcc.Graph(id=\"graph-5\", figure=fig, clear_on_unhover=True),\n",
    "                dcc.Tooltip(id=\"graph-tooltip-5\", direction='bottom'),\n",
    "            ],\n",
    "        )\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run_server(mode='inline', debug=True, port=2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1517c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEulerDistance(a, b):\n",
    "    squares = [(p-q) ** 2 for p, q in zip(a, b)]\n",
    "    return sum(squares) ** .5\n",
    "    \n",
    "distancesSign = {}\n",
    "\n",
    "centroidSignList = list(centroidLocationDict.keys())\n",
    "# print(centroidSignList)\n",
    "for idx, ikey in enumerate(centroidSignList):\n",
    "    distancesSign[INVERSED_LABEL_DICT[ikey]] = {}\n",
    "    \n",
    "    \n",
    "    distancesSign[INVERSED_LABEL_DICT[ikey]][INVERSED_LABEL_DICT[ikey]] = np.NaN\n",
    "    for jdx, jkey in enumerate(centroidSignList[idx + 1:]):\n",
    "        dist = getEulerDistance(\n",
    "            centroidLocationDict[ikey],\n",
    "            centroidLocationDict[jkey]\n",
    "        )\n",
    "        distancesSign[INVERSED_LABEL_DICT[ikey]][INVERSED_LABEL_DICT[jkey]] = dist\n",
    "        \n",
    "# distancesSign\n",
    "distancesSign = pd.DataFrame.from_dict(distancesSign)\n",
    "for i in range(len(distancesSign)):\n",
    "    distancesSign.iloc[i] = distancesSign.iloc[:, i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c665018",
   "metadata": {},
   "outputs": [],
   "source": [
    "figH = px.imshow(distancesSign)\n",
    "# fig.show()\n",
    "\n",
    "app1 = JupyterDash(__name__)\n",
    "\n",
    "PATH_PREFIX = '../data/STOCK_SIGNS/'\n",
    "PATH_POSTFIX = '.png'\n",
    "\n",
    "@app1.callback(\n",
    "    Output(\"graph-tooltip-5\", \"show\"),\n",
    "    Output(\"graph-tooltip-5\", \"bbox\"),\n",
    "    Output(\"graph-tooltip-5\", \"children\"),\n",
    "    Input(\"graph-5\", \"hoverData\"),\n",
    ")\n",
    "def display_hover(hoverData):\n",
    "    if hoverData is None:\n",
    "        return False, no_update, no_update\n",
    "\n",
    "    hover_data = hoverData[\"points\"][0]\n",
    "    \n",
    "    hover_data['x'] = '2.3.1' if hover_data['x'] == '2.3' else hover_data['x']\n",
    "    hover_data['y'] = '2.3.1' if hover_data['y'] == '2.3' else hover_data['y']        \n",
    "    hover_data['x'] = '3.18.1'  if hover_data['x'] == '3.18' else hover_data['x'] \n",
    "    hover_data['y'] = '3.18.1'  if hover_data['y'] == '3.18' else hover_data['y']\n",
    "        \n",
    "    x_img_path = PATH_PREFIX + hover_data['x'] + PATH_POSTFIX\n",
    "    y_img_path = PATH_PREFIX + hover_data['y'] + PATH_POSTFIX\n",
    "    \n",
    "    try:\n",
    "        with open(x_img_path, 'rb') as f:\n",
    "            image1 = f.read()\n",
    "        with open(y_img_path, 'rb') as f:\n",
    "            image2 = f.read()\n",
    "    except:\n",
    "        print(hoverData)\n",
    "        return False, no_update, no_update\n",
    "    \n",
    "    img1 = 'data:image/png;base64,' + base64.b64encode(image1).decode('utf-8')\n",
    "    img2 = 'data:image/png;base64,' + base64.b64encode(image2).decode('utf-8')\n",
    "\n",
    "    children = [\n",
    "        html.Div([\n",
    "            html.Img(\n",
    "                src=img1,\n",
    "                style={\"width\": \"70px\",  'margin': '0 auto'},\n",
    "            ),\n",
    "            html.Img(\n",
    "                src=img2,\n",
    "                style={\"width\": \"70px\",  'margin': '0 auto'},\n",
    "            ),\n",
    "            html.P(hover_data['x'] + ':' + hover_data['y'], style={\"fontSize\": 14, 'text-align':'center'}),\n",
    "            html.P(str(hover_data['z']), style={\"fontSize\": 14, 'text-align':'center'}),\n",
    "            \n",
    "        ]),\n",
    "    ]\n",
    "    return True, hover_data[\"bbox\"], children\n",
    "\n",
    "figH.update_traces(hoverinfo=\"none\", hovertemplate=None)\n",
    "    \n",
    "figH.update_layout(\n",
    "        width=600,\n",
    "        height=600)\n",
    "\n",
    "app1.layout = html.Div(\n",
    "    className=\"container\",\n",
    "        children=[\n",
    "            html.Div(html.H2(\"Confusion Matrix\")),\n",
    "            dcc.Graph(id=\"graph-5\", figure=figH, clear_on_unhover=True),\n",
    "            dcc.Tooltip(id=\"graph-tooltip-5\", direction='bottom'),\n",
    "            ],\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app1.run_server(mode='inline', debug=True, port=2003)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7240b4d",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c10859",
   "metadata": {},
   "source": [
    "* train_embeddings, train_labels, train_additional_info - в этих переменных вся инфа о тестовых картинках;\n",
    "* centroidLocationDict - словарь центроидов\n",
    "* getEulerDistance - функция эвклидова расстояния."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd047a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroidLocationDictGpu = {}\n",
    "for key, item in centroidLocationDict.items():\n",
    "    centroidLocationDictGpu[key] = torch.Tensor(item).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f80840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%prun -s cumulative\n",
    "from copy import deepcopy\n",
    "sign_set = sorted(set(RTDS_DF['sign']))\n",
    "v = {v: 0 for v in sign_set}\n",
    "cf_dict = {k: deepcopy(v) for k in sign_set}\n",
    "\n",
    "CHECK_TRAIN = False\n",
    "embs = train_embeddings if CHECK_TRAIN else test_embeddings\n",
    "labels_per_embeddings = train_labels if CHECK_TRAIN else test_labels\n",
    "labels_per_embeddings = labels_per_embeddings.cpu().tolist()\n",
    "\n",
    "centroid_index_to_key = {int(index): int(val) for index, val in enumerate(centroidLocationDictGpu.keys())}\n",
    "centroid_locations = torch.stack([centroidLocationDictGpu[label] for _, label in centroid_index_to_key.items()])\n",
    "\n",
    "for i, emb in tqdm(\n",
    "    enumerate(embs),\n",
    "    total=len(embs)\n",
    "    ):\n",
    "    minDist = 999999\n",
    "    closerVal = -1\n",
    "    \n",
    "    dist = (emb - centroid_locations).pow(2).sum(-1).sqrt()\n",
    "    # print(dist.shape)\n",
    "    key = int(torch.argmin(dist))\n",
    "    # print(key, i)\n",
    "\n",
    "    key = centroid_index_to_key[key]\n",
    "    \n",
    "    realSign = INVERSED_LABEL_DICT[labels_per_embeddings[i]]\n",
    "    predictedSign = INVERSED_LABEL_DICT[key]\n",
    "    # print(realSign)\n",
    "    # print(predictedSign)\n",
    "    \n",
    "    # print('for', realSign, 'predicted', predictedSign)\n",
    "            \n",
    "    cf_dict[realSign][predictedSign] += 1\n",
    "    # assert False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb5abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in cf_dict['1.6'].items():\n",
    "    if v:\n",
    "        print(k, ':', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c8eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_df = pd.DataFrame(columns=sorted(set(RTDS_DF.sign)),\n",
    "                    index=sorted(set(RTDS_DF.sign))\n",
    "                   )\n",
    "for read_sign, predicted_signs in cf_dict.items():\n",
    "    for predicted_sign, val in predicted_signs.items():\n",
    "        cf_df.loc[read_sign][predicted_sign] = val\n",
    "\n",
    "cf_df = cf_df.T\n",
    "cf_df.fillna(0, inplace=True)\n",
    "\n",
    "SHOILD_I_NORMOLIZE = False\n",
    "if SHOILD_I_NORMOLIZE:\n",
    "    cf_df = cf_df.apply(lambda x: x / x.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acaf74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "figCf = px.imshow(cf_df.apply(lambda x: x / x.sum(), axis=1),\n",
    "                  color_continuous_scale=px.colors.sequential.Cividis_r)\n",
    "\n",
    "app2 = JupyterDash(__name__)\n",
    "\n",
    "PATH_PREFIX = '../data/STOCK_SIGNS/'\n",
    "PATH_POSTFIX = '.png'\n",
    "\n",
    "@app2.callback(\n",
    "    Output(\"graph-tooltip-5\", \"show\"),\n",
    "    Output(\"graph-tooltip-5\", \"bbox\"),\n",
    "    Output(\"graph-tooltip-5\", \"children\"),\n",
    "    Input(\"graph-5\", \"hoverData\"),\n",
    ")\n",
    "def display_hover(hoverData):\n",
    "    if hoverData is None:\n",
    "        return False, no_update, no_update\n",
    "\n",
    "    hover_data = hoverData[\"points\"][0]\n",
    "    sum_x = sum(map(int, cf_dict[hover_data['y']].values()))\n",
    "    \n",
    "    if not hover_data['z']:\n",
    "        return False, no_update, no_update\n",
    "    \n",
    "    hover_data['x'] = '2.3.1' if hover_data['x'] == '2.3' else hover_data['x']\n",
    "    hover_data['y'] = '2.3.1' if hover_data['y'] == '2.3' else hover_data['y']        \n",
    "    hover_data['x'] = '3.18.1'  if hover_data['x'] == '3.18' else hover_data['x'] \n",
    "    hover_data['y'] = '3.18.1'  if hover_data['y'] == '3.18' else hover_data['y']\n",
    "    hover_data['x'] = '3.25.10' if hover_data['x'] == '3.25' else hover_data['x']\n",
    "    hover_data['y'] = '3.25.10' if hover_data['y'] == '3.25' else hover_data['y']         \n",
    "    hover_data['x'] = '3.24.10' if hover_data['x'] == '3.24' else hover_data['x']\n",
    "    hover_data['y'] = '3.24.10' if hover_data['y'] == '3.24' else hover_data['y']   \n",
    "    \n",
    "    x_img_path = PATH_PREFIX + hover_data['x'] + PATH_POSTFIX\n",
    "    y_img_path = PATH_PREFIX + hover_data['y'] + PATH_POSTFIX\n",
    "    \n",
    "    bbox = hover_data[\"bbox\"]\n",
    "    \n",
    "    try:\n",
    "        with open(x_img_path, 'rb') as f:\n",
    "            image1 = f.read()\n",
    "        with open(y_img_path, 'rb') as f:\n",
    "            image2 = f.read()\n",
    "    except:\n",
    "        # print(hoverData)\n",
    "        return False, no_update, no_update\n",
    "    \n",
    "    img1 = 'data:image/png;base64,' + base64.b64encode(image1).decode('utf-8')\n",
    "    img2 = 'data:image/png;base64,' + base64.b64encode(image2).decode('utf-8')\n",
    "\n",
    "    children = [\n",
    "        html.Div([\n",
    "            html.Img(\n",
    "                src=img1,\n",
    "                style={\"width\": \"70px\",  'margin': '0 auto'},\n",
    "            ),\n",
    "            html.Img(\n",
    "                src=img2,\n",
    "                style={\"width\": \"70px\",  'margin': '0 auto'},\n",
    "            ),\n",
    "            html.P(hover_data['x'] + ':' + hover_data['y'], style={\"fontSize\": 14, 'text-align':'center'}),\n",
    "            html.P(\n",
    "                str(hover_data['z']) \n",
    "                + ': all:' + str(sum_x * hover_data['z']), \n",
    "                style={\"fontSize\": 14, 'text-align':'center'}\n",
    "            ),\n",
    "        ]),\n",
    "    ]\n",
    "    return True, bbox, children\n",
    "\n",
    "figCf.update_traces(\n",
    "        hoverinfo=\"none\", \n",
    "        hovertemplate=None\n",
    ")\n",
    "    \n",
    "figCf.update_layout(\n",
    "        width=950,\n",
    "        height=650)\n",
    "# figCf['layout'].update(plot_bgcolor='green')\n",
    "app2.layout = html.Div(\n",
    "            className=\"container\",\n",
    "            children=[\n",
    "                dcc.Graph(id=\"graph-5\", figure=figCf, clear_on_unhover=True),\n",
    "                dcc.Tooltip(id=\"graph-tooltip-5\", direction='bottom'),\n",
    "            ],\n",
    "        )\n",
    "    \n",
    "#fig.show()\n",
    "if __name__ == '__main__':\n",
    "    app2.run_server(mode='inline', debug=True, port=2003)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9846156",
   "metadata": {},
   "source": [
    "Precision/F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2d99c5",
   "metadata": {},
   "source": [
    "Значения precision находятся в матрице ниже. В строках - актульные значения, в столбцах точность/вероятность предсказывания соответсвующего знака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0036782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "TPdict = {}\n",
    "FNdict = {}\n",
    "FPdict = {}\n",
    "TNdict = {}\n",
    "\n",
    "for i, row in cf_df.iterrows():    \n",
    "    try:\n",
    "        TPdict[i] = cf_df[i][i]\n",
    "        FNdict[i] = cf_df[i].sum() - TPdict[i]\n",
    "        FPdict[i] = cf_df.loc[i].sum() - TPdict[i]\n",
    "        TNdict[i] = cf_df.fillna(0).values.sum() - TPdict[i] - FNdict[i] - FPdict[i]\n",
    "    except KeyError as exc_obj:\n",
    "        print(traceback.format_exc())\n",
    "        print('err for key', i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a56a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PrecisionDict = {}\n",
    "RecallDict = {}\n",
    "F1Dict = {}\n",
    "SupportDict = {}\n",
    "for i in TPdict.keys():\n",
    "    PrecisionDict[i] = TPdict[i] / (TPdict[i] + FPdict[i])\n",
    "    RecallDict[i] = TPdict[i] / (TPdict[i] + FNdict[i])\n",
    "    F1Dict[i] = 2 / (1 / PrecisionDict[i] + 1 / RecallDict[i])\n",
    "    SupportDict[i] = TPdict[i] + FNdict[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d7923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Precision', 'Recall', 'F1', 'Support']\n",
    "metrics = {}\n",
    "\n",
    "for i in zip(PrecisionDict.items(), RecallDict.items(), F1Dict.items(), SupportDict.items()):\n",
    "    metrics[i[0][0]] = [i[0][1], i[1][1], i[2][1], i[3][1]]\n",
    "    \n",
    "metricsDf = pd.DataFrame().from_dict(metrics, orient='index')\n",
    "metricsDf.columns = columns\n",
    "metricsDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c81a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsDf.to_excel('metrics3_24.xls', engine='xlsxwriter')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f126ba513cd923a91965ccfdcd1e275957d64ce4742838d456229721288bc16"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
