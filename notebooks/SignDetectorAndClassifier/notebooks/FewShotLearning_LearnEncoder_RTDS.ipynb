{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc13461",
   "metadata": {
    "id": "fdc13461"
   },
   "source": [
    "## Цель ноутбука: изучение метода Few Shots Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefeb9ca",
   "metadata": {
    "id": "eefeb9ca"
   },
   "source": [
    "Проблемы со знаками решены так:\n",
    "\n",
    "| Знак | Описание | Источник |\n",
    "| ------------- | ------------- | ---- |\n",
    "| 1.6 | Пересечение равнозначных дорог | Надеемся на удачу |\n",
    "| 1.31 | Туннель | Надеемся на удачу |\n",
    "| 2.4 | Уступите дорогу | GTSRB Recognition |\n",
    "| 3.21 | Конец запрещения обгона | GTSRB Recognition |\n",
    "| 3.22 | Обгон грузовым автомобилям запрещен | GTSRB Recognition |\n",
    "| 3.23 | Конец запрещения обгона грузовым автомобилям | GTSRB Recognition |\n",
    "| 3.24-90 | Огр 90 | Объеденили |\n",
    "| 3.24-100 | Огр 100 | Объеденили |\n",
    "| 3.24-110 | Огр 110 | Объеденили |\n",
    "| 3.24-120 | Огр 120 | Объеденили |\n",
    "| 3.24-130 | Огр 130 | Объеденили |\n",
    "| 3.25 | Конец огр. максимальной скорости | GTSRB Recognition |\n",
    "| 3.31 | Конец всех ограничений | GTSRB Recognition |\n",
    "| 6.3.2 | Зона для разворота | Надеемся на удачу |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5a296e",
   "metadata": {
    "id": "1a5a296e"
   },
   "source": [
    "Инициализация библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b694f2b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b694f2b3",
    "outputId": "a70cff22-aa1e-404b-a582-99057acc2231"
   },
   "outputs": [],
   "source": [
    "# autoreload \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# core imports\n",
    "import pathlib\n",
    "import sys\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "# append src\n",
    "PROJECT_ROOT = pathlib.Path('..').resolve()\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "SRC_PATH = str(PROJECT_ROOT / 'src')\n",
    "\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.append(SRC_PATH)\n",
    "\n",
    "# Зафиксируем состояние случайных чисел\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (17,10)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19a8a95",
   "metadata": {
    "id": "b19a8a95"
   },
   "source": [
    "Инициализация основных путей и папки src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d99cb4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "f3d99cb4",
    "outputId": "1d1f48a4-4a0b-496b-ee8f-3e4abf275c4a"
   },
   "outputs": [],
   "source": [
    "DATASET_PREFIX = DATA_DIR / 'ENCODER_DATASET'\n",
    "RTDS_DF = pd.read_csv(DATASET_PREFIX / 'WIDE_DATASET_4_ENCODER.csv')\n",
    "\n",
    "RTDS_DF['filepath'] = RTDS_DF['filepath'].apply(lambda x: str(DATASET_PREFIX / x))\n",
    "\n",
    "RTDS_DF.drop_duplicates(subset=['filepath'], inplace=True)\n",
    "RTDS_DF.reset_index(inplace=True, drop=True)\n",
    "# RTDS_DF = RTDS_DF.groupby(['sign', 'set']).apply(lambda x: x.sample(frac=0.5))\n",
    "\n",
    "# убираем доп знаки \n",
    "RTDS_DF = RTDS_DF[RTDS_DF['filepath'].str.contains('rtsd')]\n",
    "\n",
    "TARGET_SIGNS = [\n",
    "    '1.1', '1.6', '1.8', '1.22', '1.31', '1.33', \n",
    "    '2.1', '2.2', '2.3', '2.4', '2.5', \n",
    "    '3.1', '3.18', '3.20', '3.21', '3.22', '3.23', '3.24',\n",
    "    '3.25', '3.27', '3.28', '3.31', \n",
    "    '4.1.1', '4.3', \n",
    "    '5.5', '5.6', '5.16', \n",
    "    '5.19.1', '5.20', \n",
    "    '6.3.2', '6.4', \n",
    "    '7.3', '7.4'\n",
    "]\n",
    "\n",
    "# RTDS_DF = RTDS_DF[RTDS_DF['sign'].isin(TARGET_SIGNS)]\n",
    "\n",
    "RTDS_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b46b42e",
   "metadata": {
    "id": "3b46b42e"
   },
   "outputs": [],
   "source": [
    "from utils.models import get_model_and_img_size\n",
    "encoder, img_size = get_model_and_img_size(DATA_DIR.parent / 'src/encoder_config.json')\n",
    "encoder = encoder.to(device)   \n",
    "\n",
    "    \n",
    "from utils.transforms import get_minimal_and_augment_transforms\n",
    "minimal_transform, augment_transform = get_minimal_and_augment_transforms(img_size)\n",
    "\n",
    "from utils.datasets import SignDataset\n",
    "train_dataset = SignDataset(\n",
    "    RTDS_DF, \n",
    "    set_label='train', \n",
    "    transform=minimal_transform, \n",
    "    hyp=None,\n",
    "    alpha_color=144\n",
    ")\n",
    "\n",
    "valid_dataset = SignDataset(\n",
    "    RTDS_DF, \n",
    "    set_label='valid',  \n",
    "    transform=minimal_transform, \n",
    "    hyp=None,\n",
    "    alpha_color=144\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487a7cb7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 842
    },
    "id": "487a7cb7",
    "outputId": "b0ba54df-1fcf-4b69-da9c-f7df8c79bc8d"
   },
   "outputs": [],
   "source": [
    "def getNSamplesFromDataSet(ds, N):\n",
    "    random_index = random.sample(range(0, len(ds)), N)\n",
    "    ret = []\n",
    "    for index in random_index:\n",
    "        ret.append(ds[index])\n",
    "    return ret\n",
    "\n",
    "IMG_COUNT = 18\n",
    "nrows, ncols = 70, 6\n",
    "fig = plt.figure(figsize = (16,200))\n",
    "\n",
    "PLOT_SOFT_LIMIT = 0 # skip\n",
    "\n",
    "TEMP_DS = getNSamplesFromDataSet(train_dataset, PLOT_SOFT_LIMIT)\n",
    "# TEMP_DS = train_dataset.sort_values(['SIGN'], axis=1)\n",
    "# TEMP_DS = train_dataset\n",
    "for idx, (img, encoded_label, info) in enumerate(TEMP_DS):\n",
    "    \n",
    "    img = torch.Tensor.permute(img, [1, 2, 0]).numpy() \n",
    "    ax = fig.add_subplot(nrows, ncols, idx+1)\n",
    "    ax.imshow(img, aspect=1)\n",
    "    title = str(info[1]) # + '\\n' + (str(info[0]))\n",
    "    ax.set_title(title, fontsize=15)\n",
    "    \n",
    "    if idx > PLOT_SOFT_LIMIT:\n",
    "        print('[!] plot soft limit reached. Breaking.')\n",
    "        break\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6fc60c",
   "metadata": {
    "id": "8d6fc60c"
   },
   "outputs": [],
   "source": [
    "batch_size = 1024 # HANDLE PARAM\n",
    "num_workers = 4 # HANDLE PARAM\n",
    "\n",
    "from utils.datasets import get_dataloader_from_dataset\n",
    "\n",
    "\n",
    "train_loader = get_dataloader_from_dataset(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40780e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def simpleGetAllEmbeddings(model, dataset, batch_size, num_workers, dsc=''):\n",
    "    dataloader = get_dataloader_from_dataset(\n",
    "        dataset,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    s, e = 0, 0\n",
    "    pbar = tqdm(\n",
    "        dataloader, \n",
    "        total=len(dataloader),\n",
    "        position=0,\n",
    "        leave=False,\n",
    "        desc='Getting all embeddings...' + dsc)\n",
    "    info_arr = []\n",
    "\n",
    "    allocate_once_flag: bool = True\n",
    "    for (data, label, info) in pbar:\n",
    "        data = data.to(device)\n",
    "        q = model(data)\n",
    "        \n",
    "        if label.dim() == 1:\n",
    "            label = label.unsqueeze(1)\n",
    "        if allocate_once_flag:\n",
    "            labels_ret = torch.zeros(\n",
    "                len(dataloader.dataset),\n",
    "                label.size(1),\n",
    "                device=device,\n",
    "                dtype=label.dtype,\n",
    "            )\n",
    "            all_q = torch.zeros(\n",
    "                len(dataloader.dataset),\n",
    "                q.size(1),\n",
    "                device=device,\n",
    "                dtype=q.dtype,\n",
    "            )\n",
    "            allocate_once_flag = False\n",
    "        e = s + q.size(0)\n",
    "        all_q[s:e] = q\n",
    "        labels_ret[s:e] = label\n",
    "        s = e  \n",
    "    \n",
    "    all_q = torch.nn.functional.normalize(all_q)\n",
    "    return all_q, labels_ret.squeeze(1), info_arr\n",
    "    \n",
    "### compute accuracy using AccuracyCalculator from pytorch-metric-learning ###    \n",
    "@torch.no_grad()\n",
    "def test(train_set, test_set, model, accuracy_calculator, batch_size, num_workers):\n",
    "    model.eval()\n",
    "    train_embeddings, train_labels, _ = simpleGetAllEmbeddings(\n",
    "        model, train_set, batch_size, num_workers, ' for train')\n",
    "    test_embeddings, test_labels, _ = simpleGetAllEmbeddings(\n",
    "        model, test_set, batch_size, num_workers, ' for valid')\n",
    "    accuracies = accuracy_calculator.get_accuracy(\n",
    "        test_embeddings, train_embeddings, test_labels, train_labels, False\n",
    "    )\n",
    "    print(accuracies)\n",
    "    return accuracies[\"precision_at_1\"]\n",
    "\n",
    "### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###\n",
    "def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    \n",
    "    pbar = tqdm(\n",
    "        train_loader, \n",
    "        total=len(train_loader),\n",
    "        position=0,\n",
    "        leave=False,\n",
    "        desc='WAITING...')\n",
    "    \n",
    "    batch_size = train_loader.batch_size\n",
    "    for (data, labels, _) in pbar:\n",
    "        \n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        embeddings = model(data)\n",
    "        \n",
    "        indices_tuple = mining_func(embeddings, labels)\n",
    "        loss = loss_func(embeddings, labels, indices_tuple)\n",
    "\n",
    "        instant_loss = loss.item()\n",
    "        loss_sum += instant_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        rounded_loss = round(instant_loss / batch_size, 5)\n",
    "        pbar.set_description(\n",
    "            f'TRAIN: INSTANT MEAN LOSS \\t{rounded_loss}, MINED TRIPLET: \\t{mining_func.num_triplets} \\t'\n",
    "        )\n",
    "    \n",
    "    return loss_sum / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03ddd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(str(DATA_DIR / 'runs/encoder4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be43bf4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553,
     "referenced_widgets": [
      "884ba4d9b4da4f6ea38b5f42eb9c82f0",
      "6511c5c959084662a03a935f53c3ac80",
      "1f3b07440bb945a9b4f8577f9035bbd4",
      "b85b5a67e6ac421086d910cc2eea8702",
      "14196cf414984cf6ac7deb105157b22d",
      "a7ab6c12864940428613f15d9de71792",
      "02e64db32ce14e4c8e0e87cc6a88ead4",
      "bd85823aa3324d1084c7ad4c9b9f6f75",
      "fd5ac201bdd7423dba2bf4a11359cf46",
      "16082e8a38294a8990d7cc6f8d1e428b",
      "9ce8304ad70243f3803a360ecec4990c",
      "c6fd127ae5074f6aa1a6ac2090d2c78e",
      "d676d9c8a96244e19df84ff8cd23d9d6",
      "088bfdb186944b9cae13f45ee8866cfc",
      "040a332d46b24b7886f47ea8ab1c996b",
      "6229f877414548a4b81bf12e9f867c37",
      "6f903f0791d44040a8e526a4460d7ece",
      "53fb1197e472477a83d2e4f70bb9f0a9",
      "87c2dfa6a1834f1488b5af8aeb58d993",
      "cd3536e6aae7417cab2f845e464b4eaa",
      "627336cc294e495a8c1050388093210f",
      "fa058285a68e42448e1c811e9bb3daaa",
      "748340dd41ad4574867c56e4c209bb16",
      "248a599ad4c04b459fbf3085d4a0e905",
      "59eb169b38d344d696a779eec38d4cfb",
      "16948c743ae744fbad17e86237a850fc",
      "81af14bee21a4d1aac0dbd80e909a950",
      "3c07edeef448427e82bf4b3ce22628ab",
      "706e43c3039341d1976d17ccd0b8051f",
      "17fab1f02c8c40a2a60354e60cbd052b",
      "f6f29f8e4019419094ddebc1a6221e9a",
      "30bfad83fbe04aa5b7f78269de51abbd",
      "7eae6e014dc34438aa01877eac6356dd",
      "002a2513d2b24253933906fadf5fbb0f",
      "12aaa7daa21e42da92df774f66b64171",
      "52da5918eb984231bf7d68af159ab6f0",
      "b21e94d058cb4bf0acf61d0a93112077",
      "bf3b492612c54b4d95d92201aa8477be",
      "1efce39b6d7c427da3204a26016d9a8c",
      "7b6f65bc6f3d410ba01aedf820c89448",
      "429bf5246e4f48a4b14c334cf163d44d",
      "1e7fcec0c1dd4fdc98db126ab77a1fda",
      "d2dfce75702e49d49a3823c2e48d3b05",
      "d0ad7b190f444ed99a00932ba52be8d2",
      "7c7ee49fcde04748a9acdbebb7754d8b",
      "6476ad581a814d4aa2629bcc2fa566c3",
      "f5b771ac175c4b2da4efaefce8a6f60c",
      "2b46a8cb5051498f80e41b67aebe9e02",
      "0be8cc08ee024c968a8e5d4ee8fbd5c5",
      "a34eced2588e41a58b0ee5476d0669b8",
      "3bcf609218e74ee2aade8587795aaa57",
      "802a5c0ac05a4a11ae63cc7b879ed24f",
      "db7f14b7643647329e9efd38fd264e94",
      "b1b682f108c74fe49cc10d9e6456c712",
      "6b039929b95f43a984eacdda4fab6a65",
      "90621fc5f9194802809f4e38112972d8",
      "b11817028fce49a4a77c4bba686cb831",
      "4e0df4759e3248e294679565721d77a0",
      "4127a6d237884b15a116850ca88dac3c",
      "a88dda357e1a4def9e2f6a55281dcb0a",
      "b0fb6b674e624c458a69411be3f0ba0c",
      "c9e63506613548e68f0018cd4972e974",
      "dd6e2a3c43d74a1585c06b1533dd2704",
      "b7bb0d0e85ec481fa313c241c5dbd677",
      "dbb0fa5c50e549e8b909a3edef068e6b",
      "d89d7d66960249fd81c7c46866e2d60f",
      "21cc13c81325458487fac95626512323",
      "53f4d66997d54ceaa1abbcc71534fd10",
      "12fa207f86744963b9aa097ee061a276",
      "319d32aad8b8491fa27ad283db60a1d6",
      "2e68042fcbc14122b122d89c062cfdb1",
      "536b1be6a26b4aab8958346aa47c6cac",
      "460af53089fb4d4f8a0af6db0c4a2c61",
      "4e16bf75d82e4324ba7b3170b4c872b7",
      "7f29ea1787824049ae611331fb4d2e5b",
      "589a08ab3eb04552ac31ae67435e62a2",
      "00563ca6149c4893922585dbbb064237",
      "5a5f5245e486447080ddcc5acb444784",
      "360d4d0130eb436998597d8fd11fd923",
      "be786180681b4d40a49fe842e99f8768",
      "3d06dd79e7e6485095c9118e51eee269",
      "583195950dfb49fba656ae8e7c3e4ceb",
      "f4652bb13a6c4e268a4385b866110386",
      "a36d28cc3c6d41f4b871775400bf574f",
      "c41c63ad3193469e945e53c7d51d9f57",
      "6688ff7dff234b719f1be17cde7a3650",
      "428cd2f2b04a45688140fed0ab3fb356",
      "0653a0f1074c4793be1adb8a38503c09",
      "32381d422e7244918697a46a283aff04",
      "64ae04c1cb9a4c43809f71c7c9f83ac1",
      "8d0ff762e62d46b589d31099b60b51be",
      "d22ec449a99a4d9e972a1795733a67f0",
      "cc18b25a93174c76b255c4b29e825e9b",
      "1f8bdf6e0a374d109cedae1c64fa80af",
      "0d49e92cec85435ead68679637721aed",
      "e5028e9788684a779a40a7874bde6ae7",
      "f95080b2e1d448cdb1dd2496d2ef8309",
      "7689c5d143b04c75a5195ae3b5d8bf6c",
      "47c7b5aaf75441f4a0945e17e580278e",
      "47f7613a625847a1b00a6bc0ff5a2807",
      "68cca4002d994fa297ee098b15bc8b40",
      "7ee611b3b6254572ac73354e7ba85337",
      "4ef5eb52337342c193dad88ab43261c1",
      "d9bb239fd6f345c78f44328613ce7cea",
      "48bdc72412e2427e81fcd6134045700a",
      "9fdcab27f94c41a4bb2c8819c5ea84b3",
      "8b4ea8a2d4274f949e8fca3fa9431173",
      "b5bdf5edff3c4094a367faa28a1bb649",
      "5144060990a546509954527ad3a6cac1",
      "8f1e4034be4847bc82c6d1e64be5b58f",
      "5dd0b990af7b423ebc46db078f95fed4",
      "a2f7a015983f49d282755fb12be2c32e",
      "42c97f71979b412fb54342770d7a1455",
      "dd1453fcbd954d1eac530e8da406f654",
      "306a8ba4b33a4293962961025f602911",
      "c286d57619bb4e618100c339e056c7fa",
      "c2e2faf12ecd4402b3f70fe27ba758fd",
      "75b25015440e49c4b7b1af8eec002444",
      "184e57dc8b9d484f8305d1b12b0cd80f",
      "92ab35da1dfc4e7183f034bfbca394ed",
      "2ba34fac331a41dd8e7373dbd9c53860"
     ]
    },
    "id": "be43bf4b",
    "outputId": "21230855-e730-4c58-809e-3ebfea619d5e"
   },
   "outputs": [],
   "source": [
    "from pytorch_metric_learning import distances, losses, miners, reducers\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "config = {\n",
    "    'lr': 0.1,\n",
    "    'epochs': 100,\n",
    "    'momentum':  0.937,\n",
    "    'margin': 0.05\n",
    "}\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    encoder.parameters(), \n",
    "    lr=config['lr'], \n",
    "    momentum=config['momentum'], \n",
    "    nesterov=True\n",
    ")\n",
    "\n",
    "scheduler = lr_scheduler.CyclicLR(\n",
    "    optimizer, \n",
    "    base_lr=0.001, \n",
    "    max_lr=0.2,\n",
    "    step_size_up=3,\n",
    "    step_size_down=4,\n",
    "    mode=\"exp_range\",\n",
    "    gamma=0.95,\n",
    "    cycle_momentum=True\n",
    ")\n",
    "\n",
    "from utils.checkpoint import save_checkpoint, load_checkpoint\n",
    "try:\n",
    "    # raise Exception\n",
    "    encoder, optimizer, scheduler, started_epoch = load_checkpoint(\n",
    "        encoder, scheduler, optimizer, str(DATA_DIR / 'last_encoder'))\n",
    "    print('[+] Checkpoint loaded')\n",
    "\n",
    "except Exception as exc_obj:\n",
    "    started_epoch = 0\n",
    "    print(f'[!] cannot load checkpoint: {exc_obj}')\n",
    "\n",
    "distance = distances.LpDistance()\n",
    "reducer = reducers.AvgNonZeroReducer()\n",
    "loss_func = losses.TripletMarginLoss(\n",
    "    margin=config['margin'], \n",
    "    distance=distance, \n",
    "    reducer=reducer\n",
    ")\n",
    "mining_func = miners.TripletMarginMiner(\n",
    "    margin=config['margin'], \n",
    "    distance=distance, \n",
    "    type_of_triplets=\"hard\"\n",
    ")\n",
    "\n",
    "accuracy_calculator = AccuracyCalculator(\n",
    "    device=torch.device('cpu'),\n",
    "    include = (\"precision_at_1\",), k = 1\n",
    ")\n",
    "scheduler = lr_scheduler.CyclicLR(\n",
    "    optimizer, \n",
    "    base_lr=0.001, \n",
    "    max_lr=0.2,\n",
    "    step_size_up=3,\n",
    "    step_size_down=4,\n",
    "    mode=\"exp_range\",\n",
    "    gamma=0.95,\n",
    "    cycle_momentum=True\n",
    ")\n",
    "\n",
    "pbar = trange(\n",
    "        started_epoch, \n",
    "        config['epochs'], \n",
    "        initial=started_epoch, \n",
    "        total=config['epochs'],\n",
    "        leave=True,\n",
    "        desc='WAITING FOR FIRST EPOCH END...')\n",
    "\n",
    "MODEL_PREFIX = 'EXCLUDE_ADDI_SIGNS'\n",
    "for epoch in pbar:\n",
    "    train_loss = train(\n",
    "        encoder, \n",
    "        loss_func, \n",
    "        mining_func, \n",
    "        device, \n",
    "        train_loader, \n",
    "        optimizer, \n",
    "        epoch\n",
    "    )\n",
    "    mean_acc = test(\n",
    "        train_dataset, \n",
    "        valid_dataset, \n",
    "        encoder, \n",
    "        accuracy_calculator, \n",
    "        batch_size, \n",
    "        num_workers\n",
    "    )\n",
    "    \n",
    "    iter_checkpoint_filename = str(DATA_DIR / str(MODEL_PREFIX + 'encoder_loss_' \\\n",
    "        + str(round(train_loss, 5)) \\\n",
    "        + '_acc_' + str(round(mean_acc, 5)) \\\n",
    "        + 'epoch_' + str(epoch) + '.encoder'))\n",
    "    \n",
    "    save_checkpoint(\n",
    "        encoder, \n",
    "        scheduler, \n",
    "        optimizer, \n",
    "        epoch,\n",
    "        iter_checkpoint_filename)\n",
    "    \n",
    "    save_checkpoint(\n",
    "        encoder, \n",
    "        scheduler, \n",
    "        optimizer, \n",
    "        epoch,\n",
    "        str(DATA_DIR / 'last_encoder'))\n",
    "\n",
    "    lr_val = scheduler.get_last_lr()[0]\n",
    "    scheduler.step()\n",
    "    \n",
    "    writer.add_scalar('mean valid accuracy', mean_acc, epoch)\n",
    "    writer.add_scalar('traineng loss', train_loss, epoch)\n",
    "    writer.add_scalar('learning rate', lr_val, epoch)\n",
    "    \n",
    "    pbar.set_description(\n",
    "        \"PER %d EPOCH: TRAIN LOSS: %.4f; VALID ACCUR: %.4f, LR %.5f\" % (\n",
    "            epoch,\n",
    "            train_loss, \n",
    "            mean_acc,\n",
    "            lr_val\n",
    "            )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086117c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, 'END'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FewShotLearning_RTDS.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "3f126ba513cd923a91965ccfdcd1e275957d64ce4742838d456229721288bc16"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
