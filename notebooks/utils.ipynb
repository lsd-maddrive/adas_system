{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ce18eb7",
   "metadata": {},
   "source": [
    "# GET ONLY OSED FULL FRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7653cfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (25,8)\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import cv2\n",
    "import PIL\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if not IN_COLAB:\n",
    "    PROJECT_ROOT = pathlib.Path(os.path.join(os.curdir, os.pardir))\n",
    "else:\n",
    "    PROJECT_ROOT = pathlib.Path('')\n",
    "\n",
    "if not IN_COLAB:\n",
    "    PROJECT_ROOT = pathlib.Path(os.path.join(os.curdir, os.pardir))\n",
    "else:\n",
    "    PROJECT_ROOT = pathlib.Path('')\n",
    "    \n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "NOTEBOOKS_DIR = PROJECT_ROOT / 'notebooks'\n",
    "\n",
    "YOLO_MODEL_HOME_DIR = DATA_DIR / 'YoloV5'\n",
    "AUGMENT_HOME_DIR = YOLO_MODEL_HOME_DIR / 'utils'\n",
    "\n",
    "if YOLO_MODEL_HOME_DIR not in sys.path:\n",
    "    sys.path.append(str(YOLO_MODEL_HOME_DIR))\n",
    "    \n",
    "if (NOTEBOOKS_DIR / 'full-gt.csv').is_file():\n",
    "    full_gt = pd.read_csv(NOTEBOOKS_DIR / 'full-gt.csv')\n",
    "else:\n",
    "    full_gt = pd.read_csv(DATA_DIR / 'full-gt.csv')\n",
    "\n",
    "FORMATED_GT_PATH = \"formated_full_gt.csv\"\n",
    "FULL_GT_SRC_LEN = len(full_gt.index)\n",
    "\n",
    "full_gt_unique_filenames = set(full_gt['filename'])\n",
    "full_gt_unique_filenames_size = len(full_gt_unique_filenames)\n",
    "%run utils.ipynb\n",
    "import ast\n",
    "\n",
    "i = 0;\n",
    "\n",
    "if os.path.isfile(FORMATED_GT_PATH):\n",
    "    print(\"FORMATED GT EXIST. LOAD IT\")\n",
    "    formated_full_gt_df = pd.read_csv(FORMATED_GT_PATH, dtype=object)\n",
    "    # display(formated_full_gt_df)\n",
    "    formated_full_gt_df['coords'].replace({'\\n ':',', ' \\s+': ' ', '\\[ ': '['}, regex=True, inplace=True)\n",
    "    # display(formated_full_gt_df)\n",
    "    formated_full_gt_df['coords'] = formated_full_gt_df['coords'].apply(\n",
    "        lambda x: ast.literal_eval(x)\n",
    "    )\n",
    "    \n",
    "    formated_full_gt_df['size'] = formated_full_gt_df['size'].apply(\n",
    "        lambda x: ast.literal_eval(x)\n",
    "    )\n",
    "else:\n",
    "    print(\"FORMATED GT DOESNT EXIST. CREATE IT\")\n",
    "    # get all original filenames\n",
    "    full_gt_unique_filenames = set(full_gt['filename'])\n",
    "    \n",
    "    formated_full_gt_list = []\n",
    "\n",
    "    import imagesize\n",
    "    \n",
    "    for src_filename_iterator in list(full_gt_unique_filenames):\n",
    "\n",
    "        mask = np.in1d(full_gt['filename'], [src_filename_iterator])\n",
    "        coord_data_arr = full_gt[mask][['x_from', 'y_from', 'width', 'height']].to_numpy()\n",
    "        \n",
    "        filepath = DATA_DIR / \"rtsd-frames\" / src_filename_iterator\n",
    "        origW, origH = imagesize.get(filepath)\n",
    "                \n",
    "        rel_coord = []\n",
    "        for coord in coord_data_arr:\n",
    "            # make from x, y, dx, dx -> x1, y1, x2, y2\n",
    "            CV2RectangleCoords = ConvertAbsTLWH2CV2Rectangle(coord)\n",
    "   \n",
    "            # make from x1, y1, x2, y2 -> x, y, w, h\n",
    "            CV2CircleCoords = ConvertCV2Rectangle2CenterXYWH(CV2RectangleCoords)\n",
    "            \n",
    "            # make x, y, w, h -> relative x, y, w, h\n",
    "            rel_instance = MakeRel(CV2CircleCoords, origW, origH)\n",
    "            rel_coord.append(rel_instance)\n",
    "            \n",
    "        if i % 100 == 0:\n",
    "            printProgressEnum(i, full_gt_unique_filenames_size)\n",
    "        i += 1\n",
    "\n",
    "        formated_full_gt_list.append([str(filepath), rel_coord, [origW, origH]])\n",
    "\n",
    "    formated_full_gt_df = pd.DataFrame(formated_full_gt_list, columns=['filepath', 'coords', 'size'])\n",
    "    formated_full_gt_df.to_csv(\"formated_full_gt.csv\", index=False)\n",
    "\n",
    "if 'set' in formated_full_gt_df.columns:\n",
    "    print('SET ALREADY EXIST')\n",
    "else:\n",
    "    print('SET DOESNT EXIST. LETS CREATE IT')\n",
    "    formated_full_gt_df_index_count = len(formated_full_gt_df.index)\n",
    "    TRAIN_SIZE = round(0.7 * formated_full_gt_df_index_count)\n",
    "    VALID_SIZE = round(0.2 * formated_full_gt_df_index_count)\n",
    "    TEST_SIZE = round(formated_full_gt_df_index_count - TRAIN_SIZE - VALID_SIZE)\n",
    "    \n",
    "    # print('assert:', TRAIN_SIZE + VALID_SIZE + TEST_SIZE, '==', formated_full_gt_df_index_count)\n",
    "    \n",
    "    assert TRAIN_SIZE + VALID_SIZE + TEST_SIZE == formated_full_gt_df_index_count, 'wrong split'\n",
    "    set_series = pd.Series('test', index=range(TEST_SIZE)).append(\n",
    "        pd.Series('train', index=range(TRAIN_SIZE)).append(\n",
    "            pd.Series('valid', index=range(VALID_SIZE))\n",
    "        )\n",
    "    ).sample(frac=1).reset_index(drop=True)\n",
    "    formated_full_gt_df['set'] = set_series\n",
    "    display(formated_full_gt_df)\n",
    "    formated_full_gt_df.to_csv(\"formated_full_gt.csv\", index=False)\n",
    "    \n",
    "display(formated_full_gt_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effc891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COPY_DIR = DATA_DIR / \"USER_FULL_FRAMES\"\n",
    "\n",
    "if not TARGET_COPY_DIR.is_dir():\n",
    "    TARGET_COPY_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    formated_full_gt_df.apply(lambda x: \n",
    "                          shutil.copy2(x['filepath'], TARGET_COPY_DIR / str(x['filepath']).split('\\\\')[-1]\n",
    "                                      ), \n",
    "                          axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55329d19",
   "metadata": {},
   "source": [
    "# Minor help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4f79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printProgressEnum(index, length, label=None):\n",
    "    print('\\r{}Progress: {}/{} ({:.2f}%)'.\n",
    "                  format(label if label != None else '', index + 1, length, 100 * (index + 1) / length), flush=True, end='')\n",
    "    \n",
    "def showTensorPicture(tensor_image, label=None):\n",
    "    # img = tensor_image.permute(1, 2, 0)\n",
    "    img = cv2.cvtColor(tensor_image.permute(1, 2, 0).numpy(), cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    if label:\n",
    "        plt.title(label)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def UnmakeRel(coords, w, h):\n",
    "    return list(map(int,\n",
    "                    [coords[0] * w, coords[1] * h, coords[2] * w, coords[3] * h]\n",
    "                   ))\n",
    "\n",
    "def MakeRel(coords, w, h):\n",
    "    return list(map(float,\n",
    "                    [coords[0] / w, coords[1] / h, coords[2] / w, coords[3] / h]\n",
    "                   ))\n",
    "\n",
    "def ConvertAbsTLWH2CV2Rectangle(coords):\n",
    "    return list(map(int, \n",
    "                    [coords[0], coords[1] , coords[0] + coords[2], coords[1] + coords[3]]\n",
    "                   )\n",
    "               )\n",
    "\n",
    "def ConvertCenterXYWH2CV2Rectangle(coords):\n",
    "    return list(map(int, \n",
    "                    [coords[0] - coords[2] / 2, coords[1] - coords[3] / 2, coords[0] + coords[2] / 2, coords[1] + coords[3] / 2]\n",
    "                   )\n",
    "               )\n",
    "\n",
    "def ConvertCV2Rectangle2CenterXYWH(coords):\n",
    "    return list(map(int,\n",
    "                    [(coords[2] + coords[0]) / 2, \n",
    "                     (coords[3] + coords[1]) / 2,\n",
    "                     coords[2] - coords[0],\n",
    "                     coords[3] - coords[1],\n",
    "                    ]\n",
    "                   ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069a9d08",
   "metadata": {},
   "source": [
    "# Learn specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61555f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, loss_op, optim, device):\n",
    "    loss_ = []\n",
    "    torch.set_grad_enabled(True)\n",
    "    \n",
    "    # Таким образом переводим модель в режим обучения\n",
    "    # В этом режиме вычисляются градиенты, нужные для обучения\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    for batch_idx, (imgs_batch, labels_batch) in enumerate(loader):\n",
    "        # print(imgs_batch.shape)\n",
    "        imgs_batch = imgs_batch.to(device)\n",
    "        # print(labels_batch)\n",
    "        labels_batch = labels_batch.to(device)\n",
    "\n",
    "        pred = model(imgs_batch)\n",
    "\n",
    "        loss = loss_op(pred, labels_batch)\n",
    "        # Сохраним в историю эпохи\n",
    "        l_ = loss.item()\n",
    "        loss_.append(l_)\n",
    "        # model.addValidHistoryAcc(l_)\n",
    "        # optim.zero_grad()\n",
    "        for param in model.parameters(): # https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html\n",
    "            param.grad = None\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        if batch_idx % 20 == 0:\n",
    "            print('\\rTrain Epoch: {} [{}/{} ({:.2f}%)]'.\n",
    "                  format(epoch, batch_idx * len(imgs_batch), len(loader.dataset),\n",
    "                 100 * batch_idx * len(imgs_batch) / len(loader.dataset)), flush=True, end='')\n",
    "        \n",
    "    print('\\rTrain Epoch: {} [{}/{} (100%)]     \\n'.\n",
    "                  format(epoch, len(loader.dataset), len(loader.dataset)), flush=True, end='')\n",
    "    \n",
    "    return np.mean(loss_)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_batch_accuracy(y_pred, y_true):\n",
    "    '''\n",
    "    Оценка точности предсказания (accuracy)\n",
    "\n",
    "    y_pred:\n",
    "        батч сырых степеней уверенности, размер (N, K)\n",
    "    y_true:\n",
    "        вектор истинных значений, размер (N)\n",
    "    '''\n",
    "    y_pred = y_pred.detach().numpy()\n",
    "    y_true = y_true.detach().numpy()\n",
    "    # print(y_true)\n",
    "    # print(y_pred)\n",
    "    accuracy = 0\n",
    "    for i in range(len(y_true)):\n",
    "        index_max = max(range(len(y_pred[i, :])), key=y_pred[i].__getitem__)\n",
    "        # print(index_max)\n",
    "        if (index_max == y_true[i]):\n",
    "            accuracy += 1\n",
    "    accuracy /= len(y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def valid_epoch(model, loader, device):\n",
    "    acc_ = []\n",
    "    torch.set_grad_enabled(False)\n",
    "    # Таким образом переводим модель в режим исполнения (inference)\n",
    "    # В этом режиме отключены градиенты, он быстрее, \n",
    "    #   но в нём нельзя обучать модель\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    for batch_idx, (imgs_batch, labels_batch) in enumerate(loader):\n",
    "        imgs_batch = imgs_batch.to(device)\n",
    "        #print(labels_batch)\n",
    "        labels_batch = labels_batch.to(device)\n",
    "        \n",
    "        pred = model(imgs_batch)\n",
    "        \n",
    "        local_acc = evaluate_batch_accuracy(pred.cpu(), labels_batch.cpu())\n",
    "        acc_.append(local_acc)\n",
    "        \n",
    "        # model.addValidHistoryAcc(local_acc)\n",
    "        \n",
    "        if batch_idx % 20 == 0:\n",
    "            print('\\rValid Epoch: {} [{}/{} ({:.2f}%)]'.\n",
    "                  format(epoch, batch_idx * len(imgs_batch), len(loader.dataset),\n",
    "                 100 * batch_idx * len(imgs_batch) / len(loader.dataset)), flush=True, end='')\n",
    "        \n",
    "    print('\\rValid Epoch: {} [{}/{} (100%)]     \\n'.\n",
    "                  format(epoch, len(loader.dataset), len(loader.dataset)), flush=True, end='')\n",
    "    \n",
    "    return np.mean(acc_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d9c35a",
   "metadata": {},
   "source": [
    "# Verify specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def getRandomFromDataset(gt: pd.DataFrame, label='test'):\n",
    "    gt = gt[gt['is_present'] == 1]\n",
    "    random_instance = gt[gt['set']==label].sample(1)\n",
    "    img_path = DATA_DIR / 'merged-rtsd' / random_instance['filename'].values[0]\n",
    "    sign_class = random_instance['sign_class'].values[0]\n",
    "    # print(img_path)\n",
    "    img = cv2.imread(str(img_path))\n",
    "    # print(img)\n",
    "    img_NT = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    img = cv2.resize(img, (160, 160))\n",
    "    img_T = torch.Tensor.permute(torch.Tensor(img), [2, 0, 1]).div(255)\n",
    "\n",
    "        \n",
    "    return img_NT, img_T.cuda(), sign_class, img_path\n",
    "\n",
    "def getMaxIndex(t_arr):\n",
    "    t_arr = t_arr.cpu().detach().numpy()\n",
    "    return np.argmax(t_arr)\n",
    "\n",
    "def getLabelFromModelOutput(t_arr):\n",
    "    max_arg = getMaxIndex(t_arr)\n",
    "    # print(max_arg)\n",
    "    return MODEL_CLASS_UNMAP[max_arg]\n",
    "\n",
    "def showImg(img, label=None):\n",
    "    plt.imshow(img)\n",
    "    if label:\n",
    "        plt.title(label)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e036b9",
   "metadata": {},
   "source": [
    "# YOLO format converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9592e45f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
