{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgZKi4UDtiDt"
   },
   "source": [
    "# датасет должен быть или скачен или сделан с помощью ноутбука RTSD-R_MERGED\n",
    "Объединенный датасет доступен по [ссылке](https://drive.google.com/drive/folders/1jmxG2zfi-Fs3m2KrMGmjD347aYiT8YFM?usp=sharing).\n",
    "\n",
    "Положить в папку data содержимое так, чтобы были следующие пути:  \n",
    "* \\$(ROOT_DIR)/data/merged-rtsd/...\n",
    "* \\$(ROOT_DIR)/data/gt.csv\n",
    "\n",
    "> *gt_Set_NaN.csv - содержит тот же датасет, но значения колонки Set обнулено*\n",
    "\n",
    "gt - датафрейм содержащий:  \n",
    "* имена файлов - поле filename\n",
    "* класс знака - поле sign_class\n",
    "* флаг присутствия знака при работе с датасетом - IsPresent. Предполагается, что вместо удаления записи, будет устанавливатся этот флаг, включающий/не влючающий знак в выборку\n",
    "* в какой набор включен знак - поле Set $\\in$ $\\{train, valid, test\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4F3G3CsMuscG",
    "outputId": "907d3f75-5486-4b78-f2a0-9e5f62908bba"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import cv2\n",
    "import PIL\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "%cd adas_system/notebooks\n",
    "\n",
    "IN_COLAB = False\n",
    "USE_COLAB_GPU = False\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    USE_COLAB_GPU = True\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    if not os.path.isfile('1_ClassifierResearch.ipynb'):\n",
    "        !git clone --branch 9_SignDetector https://github.com/lsd-maddrive/adas_system.git\n",
    "\n",
    "    !gdown --id 1-K3ee1NbMmx_0T5uwMesStmKnZO_6mWi\n",
    "    %cd adas_system/notebooks\n",
    "    !mkdir ../data/R_MERGED\n",
    "    !unzip -q -o /content/R_MERGED.zip -d ./../data/\n",
    "\n",
    "except:\n",
    "    if IN_COLAB:\n",
    "        print('[!]YOU ARE IN COLAB, BUT DIDNT MOUND A DRIVE. Model wont be synced[!]')\n",
    "\n",
    "        if not os.path.isfile('1_ClassifierResearch.ipynb'):\n",
    "            !git clone --branch 9_SignDetector https://github.com/lsd-maddrive/adas_system.git\n",
    "            !gdown --id 1-K3ee1NbMmx_0T5uwMesStmKnZO_6mWi\n",
    "            %cd adas_system/notebooks\n",
    "            !mkdir ../data/R_MERGED\n",
    "            !unzip -q -o /content/R_MERGED.zip -d ./../data/\n",
    "\n",
    "        IN_COLAB = False\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "###\n",
    "import nt_helper\n",
    "from nt_helper.helper_utils import *\n",
    "###\n",
    "\n",
    "TEXT_COLOR = 'black'\n",
    "\n",
    "# Зафиксируем состояние случайных чисел\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (17,10)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEVqwKlEvGbN"
   },
   "source": [
    "Init dirs, init main vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 991
    },
    "id": "jIdFu3ebuhn2",
    "outputId": "ee106d7b-08ed-459f-cb1a-b8dd5105312f"
   },
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    PROJECT_ROOT = pathlib.Path(os.path.join(os.curdir, os.pardir))\n",
    "else:\n",
    "    PROJECT_ROOT = pathlib.Path('..')\n",
    "    \n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "NOTEBOOKS_DIR = PROJECT_ROOT / 'notebooks'\n",
    "\n",
    "gt = pd.read_csv(DATA_DIR / 'RTDS_DATASET.csv')\n",
    "\n",
    "SIGN_TO_NUMBER = pd.read_csv(DATA_DIR / 'sign_to_number.csv', index_col=0).T.to_dict('records')[0]\n",
    "NUMBER_TO_SIGN = pd.read_csv(DATA_DIR / 'number_to_sign.csv', index_col=0).T.to_dict('records')[0]\n",
    "\n",
    "gt['filepath'] = gt['filepath'].apply(lambda x: DATA_DIR / x)\n",
    "GT_SRC_LEN = len(gt.index)\n",
    "display(gt)\n",
    "\n",
    "_, ax = plt.subplots(nrows=3, ncols=1, figsize=(21, 8))\n",
    "LABELS = ['train', 'valid', 'test']\n",
    "\n",
    "for i in range(len(LABELS)):\n",
    "    g = sns.countplot(x='SIGN', \n",
    "                      data=gt[gt['SET']==LABELS[i]],  \n",
    "                      ax=ax[i], \n",
    "                      order=sorted(gt['SIGN'].value_counts().index.tolist())\n",
    "                     )\n",
    "    ax[i].tick_params(labelrotation=90)\n",
    "    ax[i].set_title(LABELS[i])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестим обучалку: возьмем из трейна по N представителей каждого класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "\n",
    "gt = gt[gt[\"SET\"]=='train']\n",
    "SIGN_SET = set(gt['SIGN'])\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "LE_LOCATION = DATA_DIR / 'le.npy'\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "if os.path.isfile(LE_LOCATION):\n",
    "    le.classes_ = np.load(LE_LOCATION)\n",
    "else:\n",
    "    le.fit_transform(gt['SIGN'])\n",
    "    np.save(LE_LOCATION, le.classes_)\n",
    "    \n",
    "gt['ENCODED_LABELS'] = le.transform(gt['SIGN'])    \n",
    "\n",
    "nrows, ncols = 7, 6\n",
    "fig = plt.figure(figsize = (16,16))\n",
    "\n",
    "new_mini_df = pd.DataFrame(columns=gt.columns)\n",
    "\n",
    "for idx, sign_class in enumerate(SIGN_SET):\n",
    "    \n",
    "    instances = gt[gt['SIGN'] == sign_class].sample(N)\n",
    "    # print(instances)\n",
    "    new_mini_df = new_mini_df.append(instances)\n",
    "    # new_mini_df.loc[len(new_mini_df)] = instance.iloc[0]\n",
    "    path = str(instances['filepath'].sample(1).values[0])\n",
    "    # print(path)\n",
    "    sign = instances['SIGN'].sample(1).values[0]\n",
    "    img = cv2.imread(path)\n",
    "    ax = fig.add_subplot(nrows, ncols, idx+1)\n",
    "    \n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), aspect=1)\n",
    "    ax.set_title('ENCODED: ' + str(le.transform([sign_class])[0]) + '\\nDECODED: ' + str(sign_class) + '\\nSIGN: ' + str(NUMBER_TO_SIGN[sign_class]))\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mini_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_mini_df хранит только по единственному представителю знаков. Задача: обучить и провеить на этих данных\n",
    "\n",
    "Создадим загрузчик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "zBVIaE6pTQV7",
    "outputId": "31650200-64cc-402d-9fc4-c546bd7ed326"
   },
   "outputs": [],
   "source": [
    "class SignDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, set_label, img_size=64, transform=None, le=None):\n",
    "        \n",
    "        if isinstance(img_size, int):\n",
    "            img_size = (img_size, img_size)\n",
    "        \n",
    "        self.img_size = img_size\n",
    "        self.df = df[df['SET']==set_label]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "    \n",
    "    def __getitem__(self, index): \n",
    "        label = int(self.df.iloc[index]['ENCODED_LABELS'])\n",
    "        path = str(self.df.iloc[index]['filepath'])\n",
    "\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, self.img_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "        img_tnsr = torch.Tensor.permute(torch.Tensor(img), [2, 0, 1]).div(255)\n",
    "        return img_tnsr, label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IT1astLanm9u"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_epoch(model, loader, loss_op, optim, device, it_limit=99000):\n",
    "\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    accur = []\n",
    "    loss_val = []\n",
    "    \n",
    "    pbar = tqdm(enumerate(loader),\n",
    "                total=len(loader), \n",
    "                position=0,\n",
    "                leave=False)\n",
    "    \n",
    "    for idx, (data, target) in pbar:\n",
    "        \n",
    "        if it_limit and idx > it_limit:\n",
    "            break\n",
    "            \n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        pred = model(data)\n",
    "        \n",
    "        local_acc = evaluate_batch_accuracy(pred.cpu(), target.cpu())\n",
    "        accur.append(local_acc)\n",
    "        \n",
    "        # print(pred)\n",
    "        loss = loss_op(pred, target)\n",
    "        loss_val.append(loss.item())\n",
    "        \n",
    "        # Gradient descent\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "    return np.mean(loss_val)\n",
    "\n",
    "def evaluate_batch_accuracy(y_pred, y_true):\n",
    "    y_pred = y_pred.detach().numpy()\n",
    "    y_true = y_true.detach().numpy()\n",
    "    accuracy = 0\n",
    "    for i in range(len(y_true)):\n",
    "        index_max = max(range(len(y_pred[i, :])), key=y_pred[i].__getitem__)\n",
    "\n",
    "        if (index_max == y_true[i]):\n",
    "            accuracy += 1\n",
    "    accuracy /= len(y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def valid_epoch(model, loader, device, it_limit=9999):\n",
    "    \n",
    "    torch.no_grad()\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    accur = []\n",
    "    pbar = tqdm(enumerate(loader),\n",
    "                total=len(loader),\n",
    "                position=0,\n",
    "                leave=False)\n",
    "        \n",
    "    for idx, (imgs_batch, labels_batch) in pbar:\n",
    "        imgs_batch = imgs_batch.to(device)\n",
    "\n",
    "        if it_limit and idx > it_limit:\n",
    "            break\n",
    "            \n",
    "        labels_batch = labels_batch.to(device)\n",
    "        # print(labels_batch)\n",
    "        pred = model(imgs_batch)\n",
    "        # print('-\\n', pred)\n",
    "        local_acc = evaluate_batch_accuracy(pred.cpu(), labels_batch.cpu())\n",
    "        accur.append(local_acc)\n",
    "        \n",
    "    return np.mean(accur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431,
     "referenced_widgets": [
      "cf5a789839554b369239f83d5dc6cae6",
      "5ea93dc83fa8446f998e97991da45601",
      "ebca474f1cfd4965b22707c0799d523a",
      "c016f835ab2d4e60b8fea866679f6bb2",
      "f7f034ff92854ef19271ce3f37dda03b",
      "347110ddffa3444db30bf934f09ed416",
      "8442282f4b6347559713d427cbccfd56",
      "ef84701c47ac4aee98ca2c328c765924",
      "5f75ef8cf2e844f288c1b2d534ad2472",
      "e1d8b76728b449ba94337f54fdd6c4e0",
      "561cc61c1be44335b9b971f5f2801066"
     ]
    },
    "id": "OboAl3B5TQV8",
    "outputId": "3d1f1f5d-2de2-49b8-dac4-c895c447660d"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'lr': 0.1,\n",
    "    'epochs': 15,\n",
    "    'it_limit': None\n",
    "}\n",
    "\n",
    "DEFAULT_MODEL_LOCATION = DATA_DIR / 'resnet18_classifier'\n",
    "\n",
    "from torchvision import models\n",
    "model = models.resnet18(pretrained=True)\n",
    "MODEL_CLASSES = len(set(new_mini_df['SIGN']))\n",
    "model.fc = nn.Linear(512, MODEL_CLASSES)\n",
    "\n",
    "if os.path.isfile(DEFAULT_MODEL_LOCATION):\n",
    "    print('[+] Model restored from', DEFAULT_MODEL_LOCATION)\n",
    "    # model.load_state_dict(torch.load(DEFAULT_MODEL_LOCATION))\n",
    "\n",
    "loss_op = nn.CrossEntropyLoss().cuda()\n",
    "optim = torch.optim.Adadelta(model.parameters(), lr=config['lr'])\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "SHOULD_I_TRAIN = True\n",
    "\n",
    "img_size = 64\n",
    "train_dataset = SignDataset(new_mini_df, 'train', img_size)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=80,\n",
    "        pin_memory=True,\n",
    "        shuffle=True)\n",
    "\n",
    "if SHOULD_I_TRAIN:\n",
    "    pbar = tqdm(range(config['epochs']),\n",
    "                total=config['epochs'],\n",
    "                position=0,\n",
    "                leave=True,\n",
    "                desc='per epoch valid accuracy 0.0')\n",
    "    \n",
    "    for epoch in pbar:\n",
    "\n",
    "        train_res = train_epoch(model, train_loader, loss_op, optim, device, config['it_limit']) # \n",
    "        # print('t:', train_res)\n",
    "\n",
    "        valid_res = valid_epoch(model, train_loader, device, config['it_limit'])\n",
    "        # print('v:', valid_res)\n",
    "        \n",
    "        now = datetime.now()\n",
    "        torch.save(model.state_dict(), DEFAULT_MODEL_LOCATION)\n",
    "           \n",
    "        pbar.set_description(\"per epoch valid accuracy %f\" % valid_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_ = gt[gt[\"SET\"]=='train']\n",
    "SIGN_SET = set(gt_['SIGN'])\n",
    "\n",
    "nrows, ncols = 70, 6\n",
    "fig = plt.figure(figsize = (16,200))\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "for idx, (img, encoded_label) in enumerate(train_dataset):\n",
    "    \n",
    "    pred = model(img[None, ...].to('cuda')).cpu()\n",
    "    \n",
    "    argmax = np.argmax(pred.detach().numpy())\n",
    "    model_pred_decoded = le.inverse_transform([argmax])[0]\n",
    "    model_pred_sign = NUMBER_TO_SIGN[model_pred_decoded]\n",
    "    # make img from tensor\n",
    "    img = torch.Tensor.permute(img, [1, 2, 0]).numpy()\n",
    "    \n",
    "    # get decoded_label\n",
    "    decoded_label = le.inverse_transform([encoded_label])[0]\n",
    "    \n",
    "    # translate decoded to sign\n",
    "    sign = NUMBER_TO_SIGN[decoded_label]\n",
    "     \n",
    "    ax = fig.add_subplot(nrows, ncols, idx+1)\n",
    "    ax.patch.set_linewidth('15')\n",
    "    MATCH = None\n",
    "    if argmax == encoded_label:\n",
    "        MATCH = '!+++++!\\n'\n",
    "        ax.patch.set_edgecolor('green')    \n",
    "    else:\n",
    "        print('mismatch for', [(idx+1) // ncols , (idx+1) % ncols])\n",
    "        ax.patch.set_edgecolor('red')\n",
    "        \n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), aspect=1)\n",
    "    ax.set_title((MATCH if MATCH else '') + 'FACT:' + str(sign) + '\\nPRED:' + str(model_pred_sign))\n",
    "    \n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1_ClassifierResearch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
