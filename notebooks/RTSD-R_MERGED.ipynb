{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9820b704",
   "metadata": {},
   "source": [
    "# Ноутбук требует работы ручками :("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d71e17d",
   "metadata": {},
   "source": [
    "* R_MERGED_STAGE1: имеет флаги SRC in {R1_TRAIN, ..., R3_TEST} , FILENAME, SIGN \n",
    "* R_MERGED_STAGE2: имеет filepath, NUMBER \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc24bea",
   "metadata": {},
   "source": [
    "## Задача ноутбука: объеденить 2 пака датасета в 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d81825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "RTSD_PUBLIC_ROOT = pathlib.Path('D:\\\\Downloads\\\\rtsd-public\\\\classification')\n",
    "\n",
    "PATH_TO_RTDS_R1 = RTSD_PUBLIC_ROOT / 'rtsd-r1.tar/rtsd-r1'\n",
    "PATH_TO_RTDS_R3 = RTSD_PUBLIC_ROOT / 'rtsd-r3.tar/rtsd-r3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b27ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = pathlib.Path(os.path.join(os.curdir, os.pardir))\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "NOTEBOOKS_DIR = PROJECT_ROOT / 'notebooks'\n",
    "\n",
    "RTSD_MERGE_OUT_DIR = DATA_DIR / 'RTSD_CLASSIFIER_DATASET'\n",
    "RTSD_MERGE_OUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a88077",
   "metadata": {},
   "source": [
    "## Сравним number_to_classes в каждой и частей паков датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e731bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "RTDS_R1_N2C = pd.read_csv(PATH_TO_RTDS_R1 / 'numbers_to_classes.csv')\n",
    "RTDS_R1_N2C_DICT = RTDS_R1_N2C.set_index('class_number').to_dict()['sign_class']\n",
    "display(RTDS_R1_N2C.head())\n",
    "\n",
    "RTDS_R3_N2C = pd.read_csv(PATH_TO_RTDS_R3 / 'numbers_to_classes.csv')\n",
    "RTDS_R3_N2C_DICT = RTDS_R3_N2C.set_index('class_number').to_dict()['sign_class']\n",
    "display(RTDS_R3_N2C.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a121aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in RTDS_R1_N2C_DICT:\n",
    "    R1_ITEM = RTDS_R1_N2C_DICT[key]\n",
    "    R3_ITEM = RTDS_R3_N2C_DICT[key]\n",
    "    if R1_ITEM != R3_ITEM:\n",
    "        print('1 MISMATCH FOR', key)\n",
    "        break;\n",
    "        \n",
    "for key in RTDS_R3_N2C_DICT:\n",
    "    R1_ITEM = RTDS_R1_N2C_DICT[key]\n",
    "    R3_ITEM = RTDS_R3_N2C_DICT[key]\n",
    "    if R1_ITEM != R3_ITEM:\n",
    "        print('2 MISMATCH FOR', key)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62181ce",
   "metadata": {},
   "source": [
    "### Таблица трансляции 'number_to_classes' не совпадают. Будем использовать соответсвующие таблицы для каждого пака, чтобы привести все к единому ДатаФрейму вида \n",
    "|INDEX| FILEPATH | SIGN_CLASS | SET | \n",
    "| --- | --- | --- | --- |\n",
    "|1| ../data/FOLDER1/0001.jp | 1_11 | 'train' | \n",
    "| --- | --- | --- | --- | \n",
    "...\n",
    "| --- | --- | --- | --- |\n",
    "|973| ../data/FOLDER2/000714.jp | 1_31 | 'test' | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43fad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RTDS_R1_N2C_DICT)\n",
    "print(RTDS_R3_N2C_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1515214",
   "metadata": {},
   "source": [
    "## Рассмотрим распределения TEST/TRAIN для обоих паков"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b5d637",
   "metadata": {},
   "source": [
    "### R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c778a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "R1_TEST = pd.read_csv(PATH_TO_RTDS_R1 / 'gt_test.csv')\n",
    "# display(R1_TEST)\n",
    "R1_TRAIN = pd.read_csv(PATH_TO_RTDS_R1 / 'gt_train.csv')\n",
    "# display(R1_TRAIN)\n",
    "\n",
    "_, ax = plt.subplots(nrows=2, ncols=1, figsize=(21, 7))\n",
    "ax[0].tick_params(labelrotation=90)\n",
    "ax[1].tick_params(labelrotation=90)\n",
    "\n",
    "g = sns.countplot(ax=ax[0], x='class_number', data=R1_TEST,  order=sorted(R1_TEST['class_number'].value_counts().index.tolist()));\n",
    "# g.set_yscale(\"log\")\n",
    "ax[0].set_title('TEST R1 DISTRIBUTION')\n",
    "\n",
    "g = sns.countplot(ax=ax[1], x='class_number', data=R1_TRAIN,  order=sorted(R1_TRAIN['class_number'].value_counts().index.tolist()));\n",
    "# g.set_yscale(\"log\")\n",
    "ax[1].set_title('TRAIN R1 DISTRIBUTION')\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b506c",
   "metadata": {},
   "source": [
    "### R3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f34664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "R3_TEST = pd.read_csv(PATH_TO_RTDS_R3 / 'gt_test.csv')\n",
    "R3_TRAIN = pd.read_csv(PATH_TO_RTDS_R3 / 'gt_train.csv')\n",
    "\n",
    "\n",
    "_, ax = plt.subplots(nrows=2, ncols=1, figsize=(21, 7))\n",
    "ax[0].tick_params(labelrotation=90)\n",
    "ax[1].tick_params(labelrotation=90)\n",
    "\n",
    "g = sns.countplot(ax=ax[0], x='class_number', data=R3_TEST,  order=sorted(R3_TEST['class_number'].value_counts().index.tolist()));\n",
    "ax[0].set_title('TEST R3 DISTRIBUTION')\n",
    "\n",
    "g = sns.countplot(ax=ax[1], x='class_number', data=R3_TRAIN,  order=sorted(R3_TRAIN['class_number'].value_counts().index.tolist()));\n",
    "ax[1].set_title('TRAIN R3 DISTRIBUTION')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06811c01",
   "metadata": {},
   "source": [
    "## В обоих частях датасета, как в тестовой, так и в тренировочной частях есть сильно преобладающий класс. Необходимо избавится от трендов, однако прежде - объеденим R3 и R1 ДатаФрейми в один, избавившись от деления на тестовую и тренировочную выборки. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e1a4f3",
   "metadata": {},
   "source": [
    "Перейдем от номера класса к знаку в соответствии со словарями "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fdc45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "R1_TRAIN['class_number'] = R1_TRAIN['class_number'].apply(lambda x: RTDS_R1_N2C_DICT[x])\n",
    "R1_TEST['class_number'] = R1_TEST['class_number'].apply(lambda x: RTDS_R1_N2C_DICT[x])\n",
    "R3_TRAIN['class_number'] = R3_TRAIN['class_number'].apply(lambda x: RTDS_R3_N2C_DICT[x])\n",
    "R3_TEST['class_number'] = R3_TEST['class_number'].apply(lambda x: RTDS_R3_N2C_DICT[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b3b2a0",
   "metadata": {},
   "source": [
    "Сдеюущая операция может занять много времени. Для выполнения, установить MAKE_ONCE_FLAG равным False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc8428",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_MERGED_FILE = DATA_DIR / 'R_MERGED_STAGE1.csv'\n",
    "R_MERGED = pd.DataFrame(columns=['SRC', 'FILENAME', 'SIGN'])\n",
    "\n",
    "MAKE_ONCE_FLAG = True \n",
    "\n",
    "if os.path.isfile(R_MERGED_FILE):\n",
    "    R_MERGED = pd.read_csv(R_MERGED_FILE)\n",
    "else:\n",
    "    MAKE_ONCE_FLAG = False\n",
    "    \n",
    "if not MAKE_ONCE_FLAG:\n",
    "    \n",
    "    for row in R1_TRAIN.itertuples():\n",
    "        R_MERGED.loc[len(R_MERGED)] = ['R1_TRAIN', row.filename, row.class_number]\n",
    "    \n",
    "    print('R1_TRAIN COMPLETED. Current R_MERGED size', len(R_MERGED.index), 'R1_TRAIN size', len(R1_TRAIN.index))\n",
    "    \n",
    "    for row in R1_TEST.itertuples():\n",
    "        R_MERGED.loc[len(R_MERGED)] = ['R1_TEST', row.filename, row.class_number]\n",
    "\n",
    "    print('R1_TEST COMPLETED. Current R_MERGED size', len(R_MERGED.index), 'R1_TRAIN size', len(R1_TEST.index))\n",
    "    \n",
    "    for row in R3_TRAIN.itertuples():\n",
    "        R_MERGED.loc[len(R_MERGED)] = ['R3_TRAIN', row.filename, row.class_number]\n",
    "    \n",
    "    print('R3_TRAIN COMPLETED. Current R_MERGED size', len(R_MERGED.index), 'R3_TRAIN size', len(R3_TRAIN.index))\n",
    "    \n",
    "    for row in R3_TEST.itertuples():\n",
    "        R_MERGED.loc[len(R_MERGED)] = ['R3_TEST', row.filename, row.class_number]\n",
    "    \n",
    "    print('R3_TEST COMPLETED. Current R_MERGED size', len(R_MERGED.index), 'R3_TEST size', len(R3_TEST.index))\n",
    "    \n",
    "    MAKE_ONCE_FLAG = True\n",
    "    R_MERGED.to_csv(R_MERGED_FILE, index=False)\n",
    "\n",
    "R_MERGED_SIZE = len(R_MERGED.index)\n",
    "OTHER_DFs_SIZE = len(R1_TRAIN.index) + len(R1_TEST.index) + len(R3_TRAIN.index) + len(R3_TEST.index)\n",
    "assert R_MERGED_SIZE==OTHER_DFs_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203692b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_MERGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f269abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(nrows=1, ncols=1, figsize=(21, 7))\n",
    "ax.tick_params(labelrotation=90)\n",
    "\n",
    "g = sns.countplot(x='SIGN', data=R_MERGED,  order=sorted(R_MERGED['SIGN'].value_counts().index.tolist()));\n",
    "ax.set_title('R_MERGED')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7af9ae",
   "metadata": {},
   "source": [
    "Делаем табличку перевода цифорки в знак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab72083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "SignEncoder = le.fit_transform(R_MERGED['SIGN'])\n",
    "\n",
    "NUMBER_TO_SIGN_DF_DATA = dict(zip(SignEncoder, R_MERGED['SIGN']))\n",
    "NUMBER_TO_SIGN_DF = pd.DataFrame(data=NUMBER_TO_SIGN_DF_DATA.items(), columns=['NUMBER', 'SIGN'])\n",
    "\n",
    "NUMBER_TO_SIGN_DF_DIR = DATA_DIR / 'number_to_sign.csv'\n",
    "NUMBER_TO_SIGN_DF.to_csv(NUMBER_TO_SIGN_DF_DIR, index=False)\n",
    "\n",
    "SIGN_TO_NUMBER_DF_DATA = dict(zip(R_MERGED['SIGN'], SignEncoder))\n",
    "SIGN_TO_NUMBER_DF = pd.DataFrame(data=SIGN_TO_NUMBER_DF_DATA.items(), columns=['SIGN', 'NUMBER'])\n",
    "SIGN_TO_NUMBER_DF_DIR = DATA_DIR / 'sign_to_number.csv'\n",
    "SIGN_TO_NUMBER_DF.to_csv(SIGN_TO_NUMBER_DF_DIR, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef11ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_MERGED['SIGN'] = R_MERGED['SIGN'].apply(lambda x: SIGN_TO_NUMBER_DF_DATA[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6685370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_MERGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93375ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_TO_SIGN_DF_DATA[R_MERGED.loc[4]['SIGN']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d2e46",
   "metadata": {},
   "source": [
    "### Имеем 2 таблички: Знак -> Число, Число -> Знак. Будем дальше использовать их как словарь. \n",
    "### Удалим ненужные знаки. Список используемых ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2499e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SIGNS = [\n",
    "        '1_1', '1_6', '1_8', '1_22', '1_31', '1_33', '2_1', '2_2', \n",
    "        # ~2_3_1\n",
    "        '2_3', \\\n",
    "        # /~2_3_1\n",
    "        '2_4', '2_5', '3_1', \n",
    "        # ~3_18_1\n",
    "        '3_18', \n",
    "        # /~3_18_1\n",
    "        '3_20', '3_21', '3_22', '3_23', \\\n",
    "        # all speed limits\n",
    "        '3_24_n10', '3_24_n20', '3_24_n30', '3_24_n40', '3_24_n50', '3_24_n60', \\\n",
    "        '3_24_n70', '3_24_n80', '3_24_n90', '3_24_n100', '3_24_n110', '3_24_n120', '3_24_n130', \\\n",
    "        # /all speed limits\n",
    "        '3_25', '3_27', '3_28', '3_31', '4_1_1', '4_3', '5_5', '5_6', '5_16', \n",
    "        '5_19_1',  \n",
    "        #'5_19_2', \\ ~ '5_19_1'\n",
    "        '5_20', '6_3_2', '6_4', '7_3', '7_4'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d5d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_NUMBERS = []\n",
    "nilen = 0\n",
    "for TARGET_SIGN in TARGET_SIGNS:\n",
    "    if TARGET_SIGN in SIGN_TO_NUMBER_DF_DATA:\n",
    "        TARGET_NUMBERS.append(SIGN_TO_NUMBER_DF_DATA[TARGET_SIGN])\n",
    "    else:\n",
    "        print(TARGET_SIGN, 'not found in dict')\n",
    "        nilen += 1\n",
    "\n",
    "print('not included count:', nilen)\n",
    "print('\\nTarget numbers:', TARGET_NUMBERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e16e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH_DICT = {\n",
    "    'R1_TRAIN': 'R_MERGED/rtsd-r1/train/',\n",
    "    'R1_TEST': 'R_MERGED/rtsd-r1/test/',\n",
    "    'R3_TRAIN': 'R_MERGED/rtsd-r3/train/',\n",
    "    'R3_TEST': 'R_MERGED/rtsd-r3/test/',\n",
    "                }\n",
    "\n",
    "R_MERGED_FILE = DATA_DIR / 'R_MERGED_STAGE2.csv'\n",
    "\n",
    "#if os.path.isfile(R_MERGED_FILE):\n",
    "#    R_MERGED = pd.read_csv(R_MERGED_FILE)\n",
    "\n",
    "if 'SRC' in R_MERGED.columns:\n",
    "    R_MERGED.rename(columns={'FILENAME': 'filepath'}, inplace=True)\n",
    "\n",
    "    for key in FILEPATH_DICT:\n",
    "        R_MERGED.loc[R_MERGED['SRC']==key, 'filepath'] = R_MERGED[R_MERGED['SRC']==key]['filepath'].apply(lambda x: FILEPATH_DICT[key] + x)\n",
    "\n",
    "    R_MERGED.drop('SRC', inplace=True, axis=1)\n",
    "    \n",
    "\n",
    "    R_MERGED.to_csv(R_MERGED_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d7e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_MERGED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd4a4b",
   "metadata": {},
   "source": [
    "### Осталось разделить датасет на test, train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ade2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(nrows=1, ncols=1, figsize=(21, 7))\n",
    "ax.tick_params(labelrotation=90)\n",
    "\n",
    "R_MERGED = R_MERGED[R_MERGED['SIGN'].isin(TARGET_NUMBERS)].reset_index(drop=True)\n",
    "\n",
    "g = sns.countplot(x='SIGN', data=R_MERGED,  order=sorted(R_MERGED['SIGN'].value_counts().index.tolist()))\n",
    "ax.set_title('R_MERGED')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5704c6",
   "metadata": {},
   "source": [
    "Неприятное распределение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926e6943",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_MERGED.groupby(['SIGN']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e66a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_MERGED_GROUPED = R_MERGED.groupby('SIGN', axis=0)\n",
    "MEAN_BY_GROUPS = int(np.floor(R_MERGED_GROUPED.size().mean()))\n",
    "R_MERGED['SET'] = np.nan\n",
    "print(MEAN_BY_GROUPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efe8fa5",
   "metadata": {},
   "source": [
    "Undersampling: в каждом знаке проверем, привосходит ли число его представителей среднего (MEAN_BY_GROUPS). \n",
    "    \n",
    "    Если превосходит: берем MEAN_BY_GROUPS элементов, 60% закидываем в тренировку, 20% в валидацию, 20% в тест. Все что выше закидываем в тест.\n",
    "    Если не превосходит: берем все доступные элементов, 60% закидываем в тренировку, 20% в валидацию, 20% в тест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e01294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "SET_COLUMN_INDEX = R_MERGED.columns.get_loc(\"SET\")\n",
    "\n",
    "for key, items in R_MERGED_GROUPED.groups.items():\n",
    "        # print(items)\n",
    "        items = list(items)     # явно приведем к списку для душевного спокойствия\n",
    "        random.shuffle(items)   # перемешаем\n",
    "\n",
    "        # print(key)\n",
    "\n",
    "        if len(items) > MEAN_BY_GROUPS:\n",
    "            # выбираем рандомные значения из этой группы в колличестве MEAN_BY_GROUPS*0.6 для train\n",
    "            # MEAN_BY_GROUPS*0.2 для valid, остальное кинем в test\n",
    "            # print(int(MEAN_BY_GROUPS*0.8))\n",
    "            \n",
    "            TEMP_ITEMS_INCLUDED = items[0:MEAN_BY_GROUPS]\n",
    "            TEMP_ITEMS_EXCLUDED = items[MEAN_BY_GROUPS::]\n",
    "            \n",
    "            TRAIN_GROUP, VALID_GROUP, TEST_GPOUP = np.split(\n",
    "                TEMP_ITEMS_INCLUDED, \n",
    "                [int(len(TEMP_ITEMS_INCLUDED)*0.6), \n",
    "                 int(len(TEMP_ITEMS_INCLUDED)*0.8)]\n",
    "            )\n",
    "            \n",
    "            TEST_GPOUP = np.append(TEST_GPOUP, TEMP_ITEMS_EXCLUDED)\n",
    "            #if key == '3_24_n40':\n",
    "            #    print('TRAIN', sorted(TRAIN_GROUP), '\\nVALID', sorted(VALID_GROUP), '\\nTEST', sorted(TEST_GPOUP))\n",
    "            #    # print('t', len(TRAIN_GROUP), 'v', len(VALID_GROUP), 't', len(TEST_GPOUP))\n",
    "        else:\n",
    "            TRAIN_GROUP, VALID_GROUP, TEST_GPOUP = np.split(items, [int(len(items)*0.6), int(len(items)*0.8)])\n",
    "            # print('t', len(TRAIN_GROUP), 'v', len(VALID_GROUP), 't', len(TEST_GPOUP), '\\n')\n",
    "            # print('t', TRAIN_GROUP, 'v', VALID_GROUP, 't', TEST_GPOUP, '\\n')    \n",
    "\n",
    "\n",
    "        R_MERGED.iloc[TRAIN_GROUP, SET_COLUMN_INDEX] = 'train'\n",
    "        R_MERGED.iloc[VALID_GROUP, SET_COLUMN_INDEX] = 'valid'\n",
    "        R_MERGED.iloc[TEST_GPOUP, SET_COLUMN_INDEX] = 'test'\n",
    "\n",
    "R_MERGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f788b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(nrows=3, ncols=1, figsize=(21, 14))\n",
    "\n",
    "LABELS = ['train', 'valid', 'test']\n",
    "for i in range(len(LABELS)):\n",
    "    g = sns.countplot(x='SIGN', \n",
    "                      data=R_MERGED[R_MERGED['SET']==LABELS[i]],  \n",
    "                      ax=ax[i], \n",
    "                      order=sorted(R_MERGED['SIGN'].value_counts().index.tolist())\n",
    "                     )\n",
    "    ax[i].tick_params(labelrotation=90)\n",
    "    ax[i].set_title(LABELS[i])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68631c6",
   "metadata": {},
   "source": [
    "OVERSAMPLING: каждый класс, который не дотягивает до MEAN_BY_GROUPS в обучающей выборке вставляем в обучающую выборку снова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959fbbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_MERGED_TRAIN = R_MERGED[R_MERGED['SET']=='train']\n",
    "R_MERGED_TRAIN_GROUPED = R_MERGED_TRAIN.groupby('SIGN', axis=0)\n",
    "\n",
    "for key, items in R_MERGED_TRAIN_GROUPED.groups.items():\n",
    "\n",
    "    items = list(items)     # явно приведем к списку для душевного спокойствия\n",
    "    random.shuffle(items)   # перемешаем\n",
    "\n",
    "    if len(items) < MEAN_BY_GROUPS:\n",
    "        ROWS_TO_FILL_COUNT = int(MEAN_BY_GROUPS*0.6) - len(items)\n",
    "        ROWS_TO_APPEND = R_MERGED.iloc[items].sample(ROWS_TO_FILL_COUNT, replace=True)\n",
    "        # print(ROWS_TO_APPEND)\n",
    "        #print(len(gt.index))\n",
    "        R_MERGED = R_MERGED.append(ROWS_TO_APPEND, ignore_index=True)\n",
    "        #print(len(gt.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cca98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_MERGED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b8148",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(nrows=3, ncols=1, figsize=(21, 14))\n",
    "\n",
    "LABELS = ['train', 'valid', 'test']\n",
    "\n",
    "for i in range(len(LABELS)):\n",
    "    g = sns.countplot(x='SIGN', \n",
    "                      data=R_MERGED[R_MERGED['SET']==LABELS[i]],  \n",
    "                      ax=ax[i], \n",
    "                      order=sorted(R_MERGED['SIGN'].value_counts().index.tolist())\n",
    "                     )\n",
    "    ax[i].tick_params(labelrotation=90)\n",
    "    ax[i].set_title(LABELS[i])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17412f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_MERGED_FILE = DATA_DIR / 'RTDS_DATASET.csv'\n",
    "R_MERGED.to_csv(R_MERGED_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c108695",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, 'BREAKPOINT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d14634",
   "metadata": {},
   "source": [
    "### Работа ручками: объеденить папки исходные rtsd-r1 и rtsd-r3 в одну папку R_MERGED. Около папки должен дежать RTDS_DATASET.csv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0fb09fe",
   "metadata": {},
   "source": [
    ".\n",
    "└── R_MERGED/\n",
    "    ├── rtsd-r1/\n",
    "    │   ├── train/\n",
    "    │   └── test/\n",
    "    └── rtsd-r3/\n",
    "        ├── train/\n",
    "        └── test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e84e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_MERGED_FILE = DATA_DIR / 'RTDS_DATASET.csv'\n",
    "R_MERGED = pd.read_csv(R_MERGED_FILE)\n",
    "\n",
    "_, ax = plt.subplots(nrows=3, ncols=1, figsize=(21, 14))\n",
    "\n",
    "LABELS = ['train', 'valid', 'test']\n",
    "\n",
    "for i in range(len(LABELS)):\n",
    "    g = sns.countplot(x='SIGN', \n",
    "                      data=R_MERGED[R_MERGED['SET']==LABELS[i]],  \n",
    "                      ax=ax[i], \n",
    "                      order=sorted(R_MERGED['SIGN'].value_counts().index.tolist())\n",
    "                     )\n",
    "    ax[i].tick_params(labelrotation=90)\n",
    "    ax[i].set_title(LABELS[i])\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
