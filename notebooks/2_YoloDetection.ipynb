{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef5ffffc",
   "metadata": {},
   "source": [
    "Объединенный датасет [FIX MEне доступен по ссылке](*).\n",
    "\n",
    "Положить в папку data содержимое так, чтобы были следующие пути:  \n",
    "* \\$(ROOT_DIR)/data/full-rtsd/...\n",
    "* \\$(ROOT_DIR)/data/full-gt.csv\n",
    "\n",
    "> *gt_Set_NaN.csv - содержит тот же датасет, но значения колонки Set обнулено*\n",
    "\n",
    "gt - датафрейм содержащий:  \n",
    "* имена файлов - поле filename\n",
    "* класс знака - поле sign_class\n",
    "* координаты знаков\n",
    "* в какой набор включен знак - поле Set $\\in$ $\\{train, valid, test\\}$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6560301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (25,8)\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import cv2\n",
    "import PIL\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "TEXT_COLOR = 'black'\n",
    "\n",
    "# Зафиксируем состояние случайных чисел\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8974552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    %run utils.ipynb\n",
    "    PROJECT_ROOT = pathlib.Path(os.path.join(os.curdir, os.pardir))\n",
    "else:\n",
    "    PROJECT_ROOT = pathlib.Path('')\n",
    "    \n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "NOTEBOOKS_DIR = PROJECT_ROOT / 'notebooks'\n",
    "\n",
    "if (NOTEBOOKS_DIR / 'full-gt.csv').is_file():\n",
    "    full_gt = pd.read_csv(NOTEBOOKS_DIR / 'full-gt.csv')\n",
    "else:\n",
    "    full_gt = pd.read_csv(DATA_DIR / 'full-gt.csv')\n",
    "\n",
    "FORMATED_GT_PATH = \"formated_full_gt.csv\"\n",
    "FULL_GT_SRC_LEN = len(full_gt.index)\n",
    "display(full_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edbb41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_gt_unique_filenames = set(full_gt['filename'])\n",
    "full_gt_unique_filenames_size = len(full_gt_unique_filenames)\n",
    "%run utils.ipynb\n",
    "import ast\n",
    "import re\n",
    "\n",
    "i = 0;\n",
    "\n",
    "if os.path.isfile(FORMATED_GT_PATH):\n",
    "    print(\"FORMATED GT EXIST. LOAD IT\")\n",
    "    formated_full_gt_df = pd.read_csv(FORMATED_GT_PATH, dtype=object)\n",
    "    # display(formated_full_gt_df)\n",
    "    formated_full_gt_df['coords'].replace({'\\n ':',', ' \\s+': ' ', '\\[ ': '['}, regex=True, inplace=True)\n",
    "    # display(formated_full_gt_df)\n",
    "    formated_full_gt_df['coords'] = formated_full_gt_df['coords'].apply(\n",
    "        lambda x: ast.literal_eval(x)\n",
    "    )\n",
    "    \n",
    "    formated_full_gt_df['size'] = formated_full_gt_df['size'].apply(\n",
    "        lambda x: ast.literal_eval(x)\n",
    "    )\n",
    "else:\n",
    "    print(\"FORMATED GT DOESNT EXIST. CREATE IT\")\n",
    "    # get all original filenames\n",
    "    full_gt_unique_filenames = set(full_gt['filename'])\n",
    "    # gb = full_gt.groupby('filename', axis=0)\n",
    "    # gb = gb[['x_from', 'y_from', 'width', 'height']].agg(list)\n",
    "    # display(gb)\n",
    "    # create dict\n",
    "    formated_full_gt_list = []\n",
    "\n",
    "    import imagesize\n",
    "\n",
    "    \n",
    "    for src_filename_iterator in list(full_gt_unique_filenames):\n",
    "\n",
    "        mask = np.in1d(full_gt['filename'], [src_filename_iterator])\n",
    "        coord_data_arr = full_gt[mask][['x_from', 'y_from', 'width', 'height']].to_numpy()\n",
    "        \n",
    "        filepath = DATA_DIR / \"rtsd-frames\" / src_filename_iterator\n",
    "        origW, origH = imagesize.get(filepath)\n",
    "                \n",
    "        rel_coord = []\n",
    "        for coord in coord_data_arr:\n",
    "            # make from x, y, dx, dx -> x1, y1, x2, y2\n",
    "            CV2RectangleCoords = ConvertAbsTLWH2CV2Rectangle(coord)\n",
    "\n",
    "                \n",
    "            # make from x1, y1, x2, y2 -> x, y, w, h\n",
    "            CV2CircleCoords = ConvertCV2Rectangle2CenterXYWH(CV2RectangleCoords)\n",
    "            \n",
    "            # make x, y, w, h -> relative x, y, w, h\n",
    "            rel_instance = MakeRel(CV2CircleCoords, origW, origH)\n",
    "\n",
    "            rel_coord.append(rel_instance)\n",
    "            \n",
    "        if i % 100 == 0:\n",
    "            printProgressEnum(i, full_gt_unique_filenames_size)\n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        formated_full_gt_list.append([str(filepath), rel_coord, [origW, origH]])\n",
    "        \n",
    "    #    formated_full_gt_dict_.append([src_filename_iterator, coord_data])\n",
    "    #    for coord in coord_data:\n",
    "    #        origW, origH = imagesize.get(DATA_DIR / \"rtsd-frames\" / src_filename_iterator)\n",
    "    #        \n",
    "    #        relX, relY = (coord[0] + coord[2]) / origW, (coord[1] + coord[3]) / origH \n",
    "    #        relW, relH = coord[2] / origW, coord[3] / origH \n",
    "    #        \n",
    "    #        relative_coords = [relX, relY, relW, relH], [origW, origH]\n",
    "\n",
    "    formated_full_gt_df = pd.DataFrame(formated_full_gt_list, columns=['filepath', 'coords', 'size'])\n",
    "    formated_full_gt_df.to_csv(\"formated_full_gt.csv\", index=False)\n",
    "\n",
    "formated_full_gt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33148d2",
   "metadata": {},
   "source": [
    "# simple test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = formated_full_gt_df.iloc[1]\n",
    "print(instance)\n",
    "img = cv2.imread(str(instance['filepath']))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "h, w = img.shape[0], img.shape[1]\n",
    "print('Shape:', w, h)\n",
    "\n",
    "\n",
    "for i in instance['coords']:\n",
    "    \n",
    "    xywh = UnmakeRel(i, w, h)\n",
    "    x1y1x2y2 = ConvertCenterXYWH2CV2Rectangle(xywh)\n",
    "    print('+', MakeRel(x1y1x2y2, w, h))\n",
    "    print('xywh', xywh)\n",
    "    print('x1y1x2y2', x1y1x2y2)\n",
    "    \n",
    "    \n",
    "    img = cv2.rectangle(img, (x1y1x2y2[0], x1y1x2y2[1]), \n",
    "                        (x1y1x2y2[2], x1y1x2y2[3]), \n",
    "                        (255, 0, 0), \n",
    "                        3)\n",
    "    \n",
    "    img = cv2.circle(img, \n",
    "                     (xywh[0], xywh[1]), \n",
    "                     xywh[2] // 2, \n",
    "                     (255, 255, 0), \n",
    "                     3)\n",
    "\n",
    "    \n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628d20fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'set' in formated_full_gt_df.columns:\n",
    "    print('SET ALREADY EXIST')\n",
    "else:\n",
    "    print('SET DOESNT EXIST. LETS CREATE IT')\n",
    "    formated_full_gt_df_index_count = len(formated_full_gt_df.index)\n",
    "    TRAIN_SIZE = round(0.7 * formated_full_gt_df_index_count)\n",
    "    VALID_SIZE = round(0.2 * formated_full_gt_df_index_count)\n",
    "    TEST_SIZE = round(formated_full_gt_df_index_count - TRAIN_SIZE - VALID_SIZE)\n",
    "    \n",
    "    # print('assert:', TRAIN_SIZE + VALID_SIZE + TEST_SIZE, '==', formated_full_gt_df_index_count)\n",
    "    \n",
    "    assert TRAIN_SIZE + VALID_SIZE + TEST_SIZE == formated_full_gt_df_index_count, 'wrong split'\n",
    "    set_series = pd.Series('test', index=range(TEST_SIZE)).append(\n",
    "        pd.Series('train', index=range(TRAIN_SIZE)).append(\n",
    "            pd.Series('valid', index=range(VALID_SIZE))\n",
    "        )\n",
    "    ).sample(frac=1).reset_index(drop=True)\n",
    "    formated_full_gt_df['set'] = set_series\n",
    "    display(formated_full_gt_df)\n",
    "    formated_full_gt_df.to_csv(\"formated_full_gt.csv\", index=False)\n",
    "    \n",
    "display(formated_full_gt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a67aff",
   "metadata": {},
   "source": [
    "Now we have pd.DataFrame that contains filenames, list of relative coordinates, corresponding photo resoulutions and marks for set. \n",
    "\n",
    "Let's make DataSets for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8843a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils.ipynb\n",
    "\n",
    "class createDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, set_label, img_size=640, batch_size=16, augment=False, hyp=None, rect=False, image_weights=False,\n",
    "                 cache_images=False, single_cls=False, stride=32, pad=0.0, prefix=''):\n",
    "        \n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "        self.hyp = hyp\n",
    "        self.image_weights = image_weights\n",
    "        self.rect = False if image_weights else rect\n",
    "        self.mosaic = self.augment and not self.rect  # load 4 images at a time into a mosaic (only during training)\n",
    "        self.mosaic_border = [-img_size // 2, -img_size // 2]\n",
    "        self.stride = stride\n",
    "        self.df = df[df['set']==set_label]\n",
    "        self.albumentations = Albumentations() if augment else None\n",
    "        \n",
    "    def loadImage(self, instance):\n",
    "        path, (w0, h0) = instance['filepath'], instance['size']\n",
    "        im = cv2.imread(path)\n",
    "        assert im is not None, f'Image Not Found {path}'\n",
    "        \n",
    "        r = self.img_size / max(h0, w0)  # ratio\n",
    "        if r != 1:  # if sizes are not equal\n",
    "            im = cv2.resize(im, (int(w0 * r), int(h0 * r)),\n",
    "                            interpolation=cv2.INTER_AREA if r < 1 and not self.augment else cv2.INTER_LINEAR)\n",
    "        return im, (h0, w0), im.shape[:2]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # locate img info from DataFrame\n",
    "        instance = self.df.iloc[index]\n",
    "        \n",
    "        # get Img, src height, width and resized height, width\n",
    "        img, (h0, w0), (h, w) = self.loadImage(instance)\n",
    "        \n",
    "        shape = self.img_size\n",
    "        \n",
    "        # make img square\n",
    "        img, ratio, pad = letterbox(img, shape, auto=False, scaleup=self.augment)\n",
    "        # print(pad)\n",
    "        # ?\n",
    "        shapes = (h0, w0), ((h / h0, w / w0), pad)  # for COCO mAP rescaling\n",
    "        \n",
    "        # add class to labels. We have 1 class, so just add zeros into first column\n",
    "        labels = np.array(instance['coords'])\n",
    "        labels = np.c_[np.zeros(labels.shape[0]), labels]\n",
    "        # print(labels)\n",
    "        \n",
    "        # fix labels location caused by letterbox\n",
    "        labels[:, 1:] = xywhn2xyxy(labels[:, 1:], ratio[0] * w, ratio[1] * h, padw=pad[0], padh=pad[1])\n",
    "        labels[:, 1:5] = xyxy2xywhn(labels[:, 1:5], w=img.shape[1], h=img.shape[0], clip=True, eps=1E-3)\n",
    "\n",
    "        \n",
    "        nl = len(labels)  # number of labels\n",
    "        # if nl:\n",
    "        #    labels = xyxy2xywhn(labels, w=img.shape[1], h=img.shape[0], clip=True, eps=1E-3)\n",
    "        \n",
    "        # why out size (?, 6)?? \n",
    "        labels_out = torch.zeros((nl, 6))\n",
    "        if nl:\n",
    "            labels_out[:, 1:] = torch.from_numpy(labels)   \n",
    "        \n",
    "        # img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "        img = np.ascontiguousarray(img)\n",
    "        img = torch.Tensor.permute(torch.Tensor(img), [2, 0, 1]).div(255)\n",
    "        \n",
    "        return img, labels_out, instance['filepath'], shapes\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "\n",
    "\n",
    "IMG_SIZE = 640\n",
    "train_dataset = createDataSet(formated_full_gt_df,'train', img_size=IMG_SIZE)\n",
    "\n",
    "img, labels_out, filepath, shapes = train_dataset[1]\n",
    "print('label_out', labels_out)\n",
    "print('filepath', filepath)\n",
    "print('shapes', shapes)\n",
    "\n",
    "imgNT = cv2.cvtColor(img.permute(1, 2, 0).numpy(), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "for coord in labels_out[:, 2:]:\n",
    "    print(coord)\n",
    "    h, w = shapes[0]\n",
    "    xywh = UnmakeRel(coord, IMG_SIZE, IMG_SIZE)\n",
    "    x1y1x2y2 = ConvertCenterXYWH2CV2Rectangle(xywh)\n",
    "    print(x1y1x2y2)\n",
    "    imgNT = cv2.rectangle(imgNT, (x1y1x2y2[0], x1y1x2y2[1]), \n",
    "                        (x1y1x2y2[2], x1y1x2y2[3]), \n",
    "                        (255, 0, 0), \n",
    "                        3)\n",
    "    \n",
    "plt.imshow(imgNT)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f59f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, labels_out, filepath, shapes = train_dataset[1]\n",
    "print(labels_out, filepath, shapes)\n",
    "cv_img = cv2.cvtColor(img.permute(1, 2, 0).numpy(), cv2.COLOR_BGR2RGB)\n",
    "print(labels_out[0].numpy())\n",
    "cv_img = cv2.rectangle(cv_img, )\n",
    "showImg(cv_img)\n",
    "shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f8ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataLoaderAndDataSet(df, set_label, imgsz, batch_size, stride, hyp=None, augment=False,\n",
    "                      rect=False, rank=-1, workers=0, image_weights=False, quad=False, prefix='', shuffle=True):\n",
    "    \n",
    "    \n",
    "    \n",
    "    dataset = CreateDataSet()\n",
    "    batch_size = min(batch_size, len(dataset))\n",
    "    \n",
    "    loader = DataLoader(dataset, # InfiniteDataLoader ?\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=shuffle and sampler is None,\n",
    "                        # num_workers=nw,  # doesnt work in Windows\n",
    "                        sampler=sampler,\n",
    "                        pin_memory=True,\n",
    "                        collate_fn=LoadImagesAndLabels.collate_fn4 if quad else LoadImagesAndLabels.collate_fn)\n",
    "\n",
    "    \n",
    "    return loader, dataset\n",
    "    \n",
    "train_dataset = SignDataset(formated_full_gt_df, 'train')\n",
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aa976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# valid_dataset = SignDataset(formated_full_gt_df, 'valid')\n",
    "# test_dataset = SignDataset(formated_full_gt_df, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920bfa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_full_gt_df['set'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a165a34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c88108",
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_full_gt_df['coords'].iloc[-1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80a88c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# print(formated_full_gt_df['coords'].iloc[-1].replace('\\n', ','))\n",
    "temp1 = formated_full_gt_df['coords'].iloc[-1].replace('\\n ', ',').replace('[ ', '[')\n",
    "print(temp1)\n",
    "temp = re.sub(' \\s+',' ', temp1).replace(' ', ',')\n",
    "print(temp)\n",
    "print(ast.literal_eval(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef80c278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23649c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_full_gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5l', pretrained=True, classes=1, autoshape=False) #, force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d109d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model.model[-1]\n",
    "# 7,12,  10,17,  13,24,  26,20,  17,32,  23,41,  31,54,  41,72,  58,100 # custom anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613d7e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b4130",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2613475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSignCoordinates(path=None, filename=None):\n",
    "    if path == None and filename == None:\n",
    "        assert 1 != 0, 'cannot identify picture'\n",
    "    if path:\n",
    "        filename = str(path).split(sep='\\\\')[-1]\n",
    "    located_data = full_gt.loc[full_gt['filename'] == filename]\n",
    "    return located_data[['x_from', 'y_from', 'width', 'height', 'sign_class']].to_numpy()\n",
    "\n",
    "import imagesize\n",
    "\n",
    "def convertFF2YOLO(df, input_dir_abs_path, output_dir_abs_path):\n",
    "    # print(str(input_dir_abs_path))\n",
    "    input_files = os.listdir(input_dir_abs_path)\n",
    "    # print(input_files)\n",
    "    print(1)\n",
    "    p = pathlib.Path(output_dir_abs_path)\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for filename in input_files:\n",
    "        \n",
    "        origW, origH = imagesize.get(input_dir_abs_path / filename)\n",
    "        coord_data = getSignCoordinates(filename=filename)\n",
    "        print(filename, coord_data)\n",
    "        if len(coord_data):\n",
    "            #coord_data = coord_data[0]\n",
    "            pass\n",
    "        else:\n",
    "            # print('Skipped file', filename)\n",
    "            # continue\n",
    "            pass\n",
    "        \n",
    "        outfilename = output_dir_abs_path / (str(filename).split('.')[-2] + '.txt')\n",
    "        \n",
    "        f = open(outfilename, 'wb')\n",
    "        \n",
    "        for coord in coord_data:\n",
    "            # print(coord)\n",
    "            relX, relY = (coord[0] + coord[2]) / origW, (coord[1] + coord[3]) / origH \n",
    "            relW, relH = coord[2] / origW, coord[3] / origH \n",
    "            \n",
    "            str_ = '0 ' + str(relX) + ' ' + str(relY) + ' ' + str(relW) + ' ' + str(relH) + '\\n'\n",
    "            f.write(str_.encode())\n",
    "        \n",
    "        f.close()\n",
    "\n",
    "            \n",
    "convertFF2YOLO(full_gt, DATA_DIR / 'full-frames/rtsd-frames', DATA_DIR / 'full-frames/rtsd-frames-labels')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
